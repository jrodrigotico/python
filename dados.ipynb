{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pacotes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "import seaborn as sn\n",
    "from itertools import permutations, product\n",
    "import matplotlib.pyplot as mplt\n",
    "import scipy.stats as stats\n",
    "from tabulate import tabulate\n",
    "from scipy.stats import chi2_contingency \n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tools as smt\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Computadores Gamer\\\\OneDrive\\\\Área de Trabalho\\\\dados gradilene\\\\dados'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setar diretorio dos cadernos (codigo caso puxe os arquivos com todas as colunas originais do ibge)\n",
    "diretorio = r'C:\\Users\\Computadores Gamer\\OneDrive\\Área de Trabalho\\dados gradilene\\dados'\n",
    "diretorio = diretorio.replace('\\\\', '/')\n",
    "\n",
    "os.chdir(diretorio)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UF  ESTRATO_POF  TIPO_SITUACAO_REG    COD_UPA  NUM_DOM  V0201  V0202  \\\n",
      "0  11         1103                  1  110005400        1      1      1   \n",
      "1  11         1103                  1  110005400        2      1      1   \n",
      "2  11         1103                  1  110005400        4      1      4   \n",
      "3  11         1103                  1  110005400        5      1      4   \n",
      "4  11         1103                  1  110005400        6      1      1   \n",
      "\n",
      "   V0203  V0204  V0205  ...  V02162  V02163  V02164  V0217  V0219  V0220  \\\n",
      "0      1      1     10  ...       2       1       2      1    NaN      1   \n",
      "1      1      1      5  ...       2       1       2      3    1.0      1   \n",
      "2      1      1      5  ...       2       2       2      1    NaN      1   \n",
      "3      1      1      7  ...       2       2       2      1    NaN      2   \n",
      "4      1      1      6  ...       2       2       2      1    NaN      1   \n",
      "\n",
      "   V0221        PESO  PESO_FINAL  V6199  \n",
      "0      1  272.806669  372.984516      1  \n",
      "1      1  272.806669  372.984516      1  \n",
      "2      1  272.806669  372.984516      1  \n",
      "3      1  272.806669  372.984516      1  \n",
      "4      1  272.806669  372.984516      1  \n",
      "\n",
      "[5 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "#### DOMICILIO\n",
    "# largura do txt\n",
    "larguras = [2,4,1,9,2,1,1,1,1,2,1,1,1,1,1,1,1,1,1,2,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,14,14,1]\n",
    "\n",
    "# nome das colunas\n",
    "colunas = [\"UF\", \"ESTRATO_POF\", \"TIPO_SITUACAO_REG\",\n",
    "            \"COD_UPA\", \"NUM_DOM\", \"V0201\", \"V0202\",\n",
    "            \"V0203\", \"V0204\", \"V0205\", \"V0206\", \"V0207\",\n",
    "            \"V0208\", \"V0209\", \"V02101\", \"V02102\",\n",
    "            \"V02103\", \"V02104\", \"V02105\", \"V02111\",\n",
    "            \"V02112\", \"V02113\", \"V0212\", \"V0213\",\n",
    "            \"V02141\", \"V02142\", \"V0215\", \"V02161\",\n",
    "            \"V02162\", \"V02163\", \"V02164\", \"V0217\",\n",
    "            \"V0219\", \"V0220\", \"V0221\", \"PESO\",\n",
    "            \"PESO_FINAL\", \"V6199\"]\n",
    "\n",
    "# leitura dos dados\n",
    "DOMICILIO = pd.read_fwf(\n",
    "    os.path.join(diretorio, \"DOMICILIO.txt\"),\n",
    "    widths=larguras,\n",
    "    na_values=[\" \"],\n",
    "    names=colunas,\n",
    "    decimal=\".\"\n",
    ")\n",
    "\n",
    "print(DOMICILIO.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UF  ESTRATO_POF  TIPO_SITUACAO_REG    COD_UPA  NUM_DOM  NUM_UC  \\\n",
      "0  11         1103                  1  110005400        1       1   \n",
      "1  11         1103                  1  110005400        2       1   \n",
      "2  11         1103                  1  110005400        4       1   \n",
      "3  11         1103                  1  110005400        5       1   \n",
      "4  11         1103                  1  110005400        6       1   \n",
      "\n",
      "   COD_INFORMANTE  V6101  V6102  V6103  ...  V6115  V6116  V6117  V6118  \\\n",
      "0               1      5   4000   1500  ...    NaN    NaN    NaN    NaN   \n",
      "1               1      3   3500   1000  ...    NaN    NaN    NaN    NaN   \n",
      "2               1      5   5000   1200  ...    NaN    NaN    NaN    NaN   \n",
      "3               1      3   1800    800  ...    NaN    NaN    NaN    NaN   \n",
      "4               1      5   6000   1500  ...    NaN    NaN    NaN    NaN   \n",
      "\n",
      "   V6119  V6120  V6121        PESO  PESO_FINAL  RENDA_TOTAL  \n",
      "0    NaN    NaN    NaN  272.806669  372.984516     11254.75  \n",
      "1    NaN    NaN    NaN  272.806669  372.984516     10828.07  \n",
      "2    NaN    NaN    NaN  272.806669  372.984516      4769.13  \n",
      "3    NaN    NaN    NaN  272.806669  372.984516      2313.61  \n",
      "4    NaN    NaN    NaN  272.806669  372.984516      6596.90  \n",
      "\n",
      "[5 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "##### CONDICOES_VIDA\n",
    "# largura do txt\n",
    "larguras = [2,4,1,9,2,1,2,1,6,5,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,14,14,10]\n",
    "\n",
    "# nome das colunas\n",
    "colunas = [\"UF\", \"ESTRATO_POF\", \"TIPO_SITUACAO_REG\",\n",
    "            \"COD_UPA\", \"NUM_DOM\", \"NUM_UC\", \"COD_INFORMANTE\",\n",
    "            \"V6101\", \"V6102\", \"V6103\", \"V61041\", \"V61042\",\n",
    "            \"V61043\", \"V61044\", \"V61045\", \"V61046\",\n",
    "            \"V61051\", \"V61052\", \"V61053\", \"V61054\",\n",
    "            \"V61055\", \"V61056\", \"V61057\", \"V61058\",\n",
    "            \"V61061\", \"V61062\", \"V61063\", \"V61064\",\n",
    "            \"V61065\", \"V61066\", \"V61067\", \"V61068\",\n",
    "            \"V61069\", \"V610610\", \"V610611\", \"V61071\",\n",
    "            \"V61072\", \"V61073\", \"V6108\", \"V6109\",\n",
    "            \"V6110\", \"V6111\", \"V6112\", \"V6113\", \"V6114\",\n",
    "            \"V6115\", \"V6116\", \"V6117\", \"V6118\", \"V6119\",\n",
    "            \"V6120\", \"V6121\", \"PESO\", \"PESO_FINAL\",\n",
    "            \"RENDA_TOTAL\"]\n",
    "\n",
    "# leitura dos dados\n",
    "CONDICOES_VIDA = pd.read_fwf(\n",
    "    os.path.join(diretorio, \"CONDICOES_VIDA.txt\"),\n",
    "    widths=larguras,\n",
    "    na_values=[\" \"],\n",
    "    names=colunas,\n",
    "    decimal=\".\"\n",
    ")\n",
    "\n",
    "print(CONDICOES_VIDA.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### MORADOR_QUALI_VIDA\n",
    "# largura do txt\n",
    "larguras = [2,4,1,9,2,1,2,20,20,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,2,20,20,14,14]\n",
    "\n",
    "# nome das colunas\n",
    "colunas = [\"UF\",\"ESTRATO_POF\",\"TIPO_SITUACAO_REG\",\"COD_UPA\",\n",
    "            \"NUM_DOM\",\"NUM_UC\",\"COD_INFORMANTE\",\"CONTAGEM_PONDERADA\",\n",
    "            \"FUNCAO_PERDA\",\"V201\",\"V202\",\"V204\",\"V205\",\"V206\",\n",
    "            \"V207\",\"V208\",\"V209\",\"V210\",\"V211\",\"V212\",\"V214\",\"V215\",\n",
    "            \"V216\",\"V217\",\"V301\",\"V302\",\"V303\",\"V304\",\"V305\",\"V306\",\n",
    "            \"V307\",\"V308\",\"V401\",\"V402\",\"V403\",\"V501\",\"V502\",\"V503\",\n",
    "            \"V504\",\"V505\",\"V506\",\"V601\",\"V602\",\"V603\",\"V604\",\"V605\",\n",
    "            \"V606\",\"V607\",\"V608\",\"V609\",\"V610\",\"V611\",\"V701\",\"V702\",\n",
    "            \"V703\",\"V704\",\"V801\",\"V802\",\"V901\",\"V902\",\"GRANDE_REGIAO\",\n",
    "            \"C1\",\"C2\",\"C3\",\"C4\",\"C5\",\"C6\",\"C7\",\"RENDA_DISP_PC\",\n",
    "            \"RENDA_DISP_PC_SS\",\"PESO\",\"PESO_FINAL\"]\n",
    "\n",
    "# leitura dos dados\n",
    "MORADOR_QUALI_VIDA = pd.read_fwf(\n",
    "    os.path.join(diretorio, \"MORADOR_QUALI_VIDA.txt\"),\n",
    "    widths=larguras,\n",
    "    na_values=[\" \"],\n",
    "    names=colunas,\n",
    "    decimal=\".\"\n",
    ")\n",
    "\n",
    "print(MORADOR_QUALI_VIDA.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UF  ESTRATO_POF  TIPO_SITUACAO_REG    COD_UPA  NUM_DOM  NUM_UC  \\\n",
      "0  11         1101                  1  110000016        2       1   \n",
      "1  11         1101                  1  110000016        2       1   \n",
      "2  11         1101                  1  110000016        2       1   \n",
      "3  11         1101                  1  110000016        3       1   \n",
      "4  11         1101                  1  110000016        3       1   \n",
      "\n",
      "   COD_INFORMANTE  V0306  V0401  V04021  ...  V0430  ANOS_ESTUDO        PESO  \\\n",
      "0               1      1      1      15  ...    2.0            5  449.911506   \n",
      "1               2      2      1       1  ...    2.0            6  449.911506   \n",
      "2               3      6      1      16  ...    1.0           12  449.911506   \n",
      "3               1      1      1       4  ...    1.0           12  449.911506   \n",
      "4               2      2      1       7  ...    2.0            6  449.911506   \n",
      "\n",
      "   PESO_FINAL  RENDA_TOTAL  NIVEL_INSTRUCAO  RENDA_DISP_PC  RENDA_MONET_PC  \\\n",
      "0  690.883738      3855.34                2    1237.183056     1285.114167   \n",
      "1  690.883738      3855.34                2    1237.183056     1285.114167   \n",
      "2  690.883738      3855.34                5    1237.183056     1285.114167   \n",
      "3  690.883738      4242.48                5    1265.644167      826.780000   \n",
      "4  690.883738      4242.48                2    1265.644167      826.780000   \n",
      "\n",
      "   RENDA_NAO_MONET_PC  DEDUCAO_PC  \n",
      "0            0.000000   47.931111  \n",
      "1            0.000000   47.931111  \n",
      "2            0.000000   47.931111  \n",
      "3          446.340417    7.476250  \n",
      "4          446.340417    7.476250  \n",
      "\n",
      "[5 rows x 56 columns]\n"
     ]
    }
   ],
   "source": [
    "#### MORADOR\n",
    "# largura do txt\n",
    "larguras = [2,4,1,9,2,1,2,2,1,2,2,4,3,1,1,\n",
    "            1,1,1,2,1,2,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,2,1,1,2,1,1,2,1,1,1,\n",
    "            2,1,2,14,14,10,1,20,20,20,20]\n",
    "\n",
    "# nome das colunas\n",
    "colunas = [\"UF\", \"ESTRATO_POF\", \"TIPO_SITUACAO_REG\",\n",
    "            \"COD_UPA\", \"NUM_DOM\", \"NUM_UC\", \"COD_INFORMANTE\",\n",
    "            \"V0306\", \"V0401\", \"V04021\", \"V04022\", \"V04023\",\n",
    "            \"V0403\", \"V0404\", \"V0405\", \"V0406\", \"V0407\",\n",
    "            \"V0408\", \"V0409\", \"V0410\", \"V0411\", \"V0412\",\n",
    "            \"V0413\", \"V0414\", \"V0415\", \"V0416\",\n",
    "            \"V041711\", \"V041712\", \"V041721\", \"V041722\",\n",
    "            \"V041731\", \"V041732\", \"V041741\", \"V041742\",\n",
    "            \"V0418\", \"V0419\", \"V0420\", \"V0421\", \"V0422\",\n",
    "            \"V0423\", \"V0424\", \"V0425\", \"V0426\", \"V0427\",\n",
    "            \"V0428\", \"V0429\", \"V0430\", \"ANOS_ESTUDO\",\n",
    "            \"PESO\", \"PESO_FINAL\", \"RENDA_TOTAL\",\n",
    "            \"NIVEL_INSTRUCAO\", \"RENDA_DISP_PC\",\"RENDA_MONET_PC\",\n",
    "            \"RENDA_NAO_MONET_PC\",\"DEDUCAO_PC\" ]\n",
    "\n",
    "# leitura dos dados\n",
    "MORADOR = pd.read_fwf(\n",
    "    os.path.join(diretorio, \"MORADOR.txt\"),\n",
    "    widths=larguras,\n",
    "    na_values=[\" \"],\n",
    "    names=colunas,\n",
    "    decimal=\".\"\n",
    ")\n",
    "\n",
    "print(MORADOR.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deu a mesma coisa que o codigo dos big data\n",
    "# inicial = DOMICILIO.merge(MORADOR, on = ['UF', 'ESTRATO_POF', 'TIPO_SITUACAO_REG','COD_UPA', 'NUM_DOM'], how = 'left')\n",
    "# inicial2 = inicial.merge(CONDICOES_VIDA, on = ['UF', 'ESTRATO_POF', 'TIPO_SITUACAO_REG','COD_UPA', 'NUM_DOM'], how='left')\n",
    "# base = inicial2.merge(MORADOR_QUALI_VIDA, on = ['UF', 'ESTRATO_POF', 'TIPO_SITUACAO_REG','COD_UPA', 'NUM_DOM'], how = 'left')\n",
    "\n",
    "\n",
    "# inicial = DOMICILIO.merge(MORADOR, how = 'left')\n",
    "# inicial2 = inicial.merge(CONDICOES_VIDA,  how='left')\n",
    "# base = inicial2.merge(MORADOR_QUALI_VIDA,  how = 'left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando merge, juntando as colunas chaves de cada caderno para formar chave primária\n",
    "# DOMICILIO['chave_primaria'] = DOMICILIO['UF'].astype(str) + '-' + DOMICILIO['ESTRATO_POF'].astype(str) + '-' + DOMICILIO['TIPO_SITUACAO_REG'].astype(str) + '-' + DOMICILIO['COD_UPA'].astype(str)\n",
    "# MORADOR['chave_primaria'] = MORADOR['UF'].astype(str) + '-' + MORADOR['ESTRATO_POF'].astype(str) + '-' + MORADOR['TIPO_SITUACAO_REG'].astype(str) + '-' + MORADOR['COD_UPA'].astype(str)\n",
    "# CONDICOES_VIDA['chave_primaria'] = CONDICOES_VIDA['UF'].astype(str) + '-' + CONDICOES_VIDA['ESTRATO_POF'].astype(str) + '-' + CONDICOES_VIDA['TIPO_SITUACAO_REG'].astype(str) + '-' + CONDICOES_VIDA['COD_UPA'].astype(str)\n",
    "# MORADOR_QUALI_VIDA['chave_primaria'] = MORADOR_QUALI_VIDA['UF'].astype(str) + '-' + MORADOR_QUALI_VIDA['ESTRATO_POF'].astype(str) + '-' + MORADOR_QUALI_VIDA['TIPO_SITUACAO_REG'].astype(str) + '-' + MORADOR_QUALI_VIDA['COD_UPA'].astype(str)\n",
    "\n",
    "\n",
    "# a = DOMICILIO.merge(MORADOR, on = ['chave_primaria'], how='left')\n",
    "# b = CONDICOES_VIDA.merge(a, on = ['chave_primaria'], how='left')\n",
    "# c = MORADOR_QUALI_VIDA.merge(b, on = ['chave_primaria'], how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Computadores Gamer\\AppData\\Local\\Temp\\ipykernel_8408\\2397746311.py:4: FutureWarning: Passing 'suffixes' which cause duplicate columns {'PESO_FINAL_y', 'PESO_y'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  base = pd.merge(MORADOR_QUALI_VIDA, bigdata2, on = ['UF', 'ESTRATO_POF', 'TIPO_SITUACAO_REG','COD_UPA', 'NUM_DOM'], how='right')\n"
     ]
    }
   ],
   "source": [
    "# #### Merges\n",
    "bigdata = pd.merge(DOMICILIO, MORADOR, on = ['UF', 'ESTRATO_POF', 'TIPO_SITUACAO_REG','COD_UPA', 'NUM_DOM'], how= 'left')\n",
    "bigdata2 = pd.merge(CONDICOES_VIDA, bigdata, on = ['UF', 'ESTRATO_POF', 'TIPO_SITUACAO_REG','COD_UPA', 'NUM_DOM'], how='right')\n",
    "base = pd.merge(MORADOR_QUALI_VIDA, bigdata2, on = ['UF', 'ESTRATO_POF', 'TIPO_SITUACAO_REG','COD_UPA', 'NUM_DOM'], how='right')\n",
    "\n",
    "\n",
    "# removendo colunas duplicadas, ou seja, com sufixo '_x' e '_y'\n",
    "# '$' indica trecho no final da palavra\n",
    "colunas_del_x = base.filter(regex=f'_x$').columns\n",
    "base = base.drop(colunas_del_x, axis=1)\n",
    "\n",
    "colunas_del_y = base.filter(regex=f'_y$').columns\n",
    "base = base.drop(colunas_del_y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Computadores Gamer\\AppData\\Local\\Temp\\ipykernel_8408\\4055891676.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base['RENDA_MONET_PC'][i]=float(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Computadores Gamer\\AppData\\Local\\Temp\\ipykernel_8408\\4055891676.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base['V0212'][i]='teste'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False]\n",
      "[False]\n",
      "[False]\n"
     ]
    }
   ],
   "source": [
    "# tratamento da 'base'\n",
    "\n",
    "# testando o metodo dropna(how = 'all')\n",
    "# df_teste = pd.DataFrame({'a': [np.nan,2,3],\n",
    "#                          'b': [np.nan,np.nan,7],\n",
    "#                          'c':[np.nan,np.nan,np.nan],\n",
    "#                          'd':[4,5,6]})\n",
    "# print(df_teste)\n",
    "# df = df_teste.dropna()\n",
    "# print(df)\n",
    "\n",
    "# excluindo todas as linhas que possuem tudo 'nan'\n",
    "base = base.dropna(how = 'all') \n",
    "\n",
    "\n",
    "# tratando valores nan em RENDA_MONET_PC como zero\n",
    "for i in range(len(base['UF'])):\n",
    "    if pd.isna(base['RENDA_MONET_PC'][i]):\n",
    "       base['RENDA_MONET_PC'][i]=float(0) \n",
    "\n",
    "print(base['RENDA_MONET_PC'].unique())\n",
    "\n",
    "\n",
    "for i in range(len(base['UF'])):\n",
    "    if pd.isna(base['V6199'][i]):\n",
    "       base['V6199'][i]='teste' \n",
    "\n",
    "print(base['V6199'].unique())\n",
    "\n",
    "\n",
    "for i in range(len(base['UF'])):\n",
    "    if pd.isna(base['V6101'][i]):\n",
    "       base['V6101'][i]='teste'\n",
    "\n",
    "print(base['V6101'].unique())\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(base['UF'])):\n",
    "    if pd.isna(base['V61041'][i]):\n",
    "       base['V61041'][i]='teste' \n",
    "\n",
    "print(base['V61041'].unique())\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(base['UF'])):\n",
    "    if pd.isna(base['V0212'][i]):\n",
    "       base['V0212'][i]='teste' \n",
    "\n",
    "print(base['V0212'].unique())\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(base['UF'])):\n",
    "    if pd.isna(base['V0213'][i]):\n",
    "       base['V0213'][i]='teste' \n",
    "\n",
    "print(base['V0213'].unique())\n",
    "\n",
    "\n",
    "for i in range(len(base['UF'])):\n",
    "    if pd.isna(base['V0220'][i]):\n",
    "       base['V0220'][i]='fudeu' \n",
    "\n",
    "print(base['V0220'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Computadores Gamer\\AppData\\Local\\Temp\\ipykernel_8408\\3767683258.py:10: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  base['rdpc'] = pd.Series()\n",
      "C:\\Users\\Computadores Gamer\\AppData\\Local\\Temp\\ipykernel_8408\\3767683258.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base['rdpc'][i] = 0\n",
      "C:\\Users\\Computadores Gamer\\AppData\\Local\\Temp\\ipykernel_8408\\3767683258.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base['rdpc'][i] = 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Computadores Gamer\\OneDrive\\Documentos\\codigos importantes\\python\\dados.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Computadores%20Gamer/OneDrive/Documentos/codigos%20importantes/python/dados.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         base[\u001b[39m'\u001b[39m\u001b[39mrdpc\u001b[39m\u001b[39m'\u001b[39m][i] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Computadores%20Gamer/OneDrive/Documentos/codigos%20importantes/python/dados.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Computadores%20Gamer/OneDrive/Documentos/codigos%20importantes/python/dados.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         base[\u001b[39m'\u001b[39;49m\u001b[39mrdpc\u001b[39;49m\u001b[39m'\u001b[39;49m][i] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Computadores%20Gamer/OneDrive/Documentos/codigos%20importantes/python/dados.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# grafico1 = sn.countplot(base, x='var_depend1')\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Computadores%20Gamer/OneDrive/Documentos/codigos%20importantes/python/dados.ipynb#X12sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# porcentagem_pobre = base['var_depend1'].value_counts()['pobre']/len(base['var_depend1'])\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Computadores%20Gamer/OneDrive/Documentos/codigos%20importantes/python/dados.ipynb#X12sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# porcentagem_naopobre = 1 - porcentagem_pobre\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Computadores%20Gamer/OneDrive/Documentos/codigos%20importantes/python/dados.ipynb#X12sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# print(base['var_depend1'].value_counts(), f'% pobre:{porcentagem_pobre}', f'% nao pobre:{porcentagem_naopobre}') \u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Computadores Gamer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:1095\u001b[0m, in \u001b[0;36mSeries.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   1093\u001b[0m check_deprecated_indexers(key)\n\u001b[0;32m   1094\u001b[0m key \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m)\n\u001b[1;32m-> 1095\u001b[0m cacher_needs_updating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_is_chained_assignment_possible()\n\u001b[0;32m   1097\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39mis\u001b[39;00m \u001b[39mEllipsis\u001b[39m:\n\u001b[0;32m   1098\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mslice\u001b[39m(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Computadores Gamer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:1284\u001b[0m, in \u001b[0;36mSeries._check_is_chained_assignment_possible\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1282\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_view \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_cached:\n\u001b[0;32m   1283\u001b[0m     ref \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_cacher()\n\u001b[1;32m-> 1284\u001b[0m     \u001b[39mif\u001b[39;00m ref \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m ref\u001b[39m.\u001b[39;49m_is_mixed_type:\n\u001b[0;32m   1285\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_setitem_copy(t\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mreferent\u001b[39m\u001b[39m\"\u001b[39m, force\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1286\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Computadores Gamer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:6007\u001b[0m, in \u001b[0;36mNDFrame._is_mixed_type\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   6002\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39many_extension_types:\n\u001b[0;32m   6003\u001b[0m     \u001b[39m# Even if they have the same dtype, we can't consolidate them,\u001b[39;00m\n\u001b[0;32m   6004\u001b[0m     \u001b[39m#  so we pretend this is \"mixed'\"\u001b[39;00m\n\u001b[0;32m   6005\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m-> 6007\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtypes\u001b[39m.\u001b[39mnunique() \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Computadores Gamer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:6073\u001b[0m, in \u001b[0;36mNDFrame.dtypes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   6045\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m   6046\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdtypes\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   6047\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   6048\u001b[0m \u001b[39m    Return the dtypes in the DataFrame.\u001b[39;00m\n\u001b[0;32m   6049\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6071\u001b[0m \u001b[39m    dtype: object\u001b[39;00m\n\u001b[0;32m   6072\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 6073\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mget_dtypes()\n\u001b[0;32m   6074\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor_sliced(data, index\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mobject_)\n",
      "File \u001b[1;32mc:\\Users\\Computadores Gamer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:273\u001b[0m, in \u001b[0;36mBaseBlockManager.get_dtypes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_dtypes\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    272\u001b[0m     dtypes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([blk\u001b[39m.\u001b[39mdtype \u001b[39mfor\u001b[39;00m blk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks])\n\u001b[1;32m--> 273\u001b[0m     \u001b[39mreturn\u001b[39;00m dtypes\u001b[39m.\u001b[39mtake(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblknos)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# var_depend1\n",
    "# MORADOR['RENDA_MONET_PC']\n",
    "# menor ou igual a 1/4 de SM = pobre\n",
    "# acima de 1/4 de SM = não pobre\n",
    "# SM (2017) = 937 \n",
    "\n",
    "\n",
    "corte_sm = 937/4\n",
    "\n",
    "base['rdpc'] = pd.Series()\n",
    "\n",
    "for i in range(len(base['RENDA_MONET_PC'])):\n",
    "    if base['RENDA_MONET_PC'][i] <= corte_sm:\n",
    "        base['rdpc'][i] = 1\n",
    "    else:\n",
    "        base['rdpc'][i] = 0\n",
    "        \n",
    "\n",
    "# grafico1 = sn.countplot(base, x='var_depend1')\n",
    "# porcentagem_pobre = base['var_depend1'].value_counts()['pobre']/len(base['var_depend1'])\n",
    "# porcentagem_naopobre = 1 - porcentagem_pobre\n",
    "# print(base['var_depend1'].value_counts(), f'% pobre:{porcentagem_pobre}', f'% nao pobre:{porcentagem_naopobre}') \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_depend2 \n",
    "# DOMICILIO['V6199']\n",
    "# 1 – Segurança = não pobre\n",
    "# 2 – Insegurança leve = pobre\n",
    "# 3 – Insegurança moderada = pobre\n",
    "# 4 – Insegurança grave = pobre\n",
    "\n",
    "\n",
    "base['seg_alimentar'] = pd.Series()\n",
    "\n",
    "for i in range(len(base['V6199'])):\n",
    "    if base['V6199'][i] == 1:\n",
    "        base['seg_alimentar'][i] = 0\n",
    "    elif base['V6199'][i]==2:\n",
    "        base['seg_alimentar'][i] = 1\n",
    "    elif base['V6199'][i]==3:\n",
    "        base['seg_alimentar'][i] = 1\n",
    "    elif base['V6199'][i]==4:\n",
    "        base['seg_alimentar'][i] = 1\n",
    "    \n",
    "\n",
    "# grafico2 = sn.countplot(base, x='var_depend2')\n",
    "# porcentagem_pobre = base['var_depend2'].value_counts()['pobre']/len(base['var_depend2'])\n",
    "# porcentagem_naopobre = 1 - porcentagem_pobre\n",
    "# print(base['var_depend2'].value_counts(), f'% pobre:{porcentagem_pobre}', f'% nao pobre:{porcentagem_naopobre}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_depend3.1_inicial\n",
    "# CONDICOES_VIDA['V6101']\n",
    "# 1 – Muita dificuldade = pobre\n",
    "# 2 – Dificuldade = pobre\n",
    "# 3 – Alguma dificuldade = não pobre\n",
    "# 4 – Alguma facilidade = não pobre\n",
    "# 5 – Facilidade = não pobre\n",
    "# 6 – Muita facilidade = não pobre\n",
    "\n",
    "\n",
    "base['var_depend3.1_inicial'] = pd.Series()\n",
    "\n",
    "for i in range(len(base['UF'])):\n",
    "    if base['V6101'][i] == 1:\n",
    "        base['var_depend3.1_inicial'][i] = 'pobre'\n",
    "    elif base['V6101'][i]==2:\n",
    "        base['var_depend3.1_inicial'][i]  = 'pobre'\n",
    "    elif base['V6101'][i]==3:\n",
    "        base['var_depend3.1_inicial'][i]  = 'não pobre'\n",
    "    elif base['V6101'][i]==4:\n",
    "        base['var_depend3.1_inicial'][i]  = 'não pobre'\n",
    "    elif base['V6101'][i]==5:\n",
    "        base['var_depend3.1_inicial'][i]  = 'não pobre'\n",
    "    elif base['V6101'][i]==6:\n",
    "        base['var_depend3.1_inicial'][i]  = 'não pobre'\n",
    "    \n",
    " \n",
    "# sn.countplot(CONDICOES_VIDA, x='var_depend3.1_inicial')\n",
    "# print(CONDICOES_VIDA['var_depend3.1_inicial'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_depend3.2_inicial\n",
    "# CONDICOES_VIDA['V61041']\n",
    "# 1 - Bom = não pobre\n",
    "# 2 - Satisfatório = não pobre\n",
    "# 3 - Ruim = pobre\n",
    "\n",
    "\n",
    "\n",
    "base['var_depend3.2_inicial'] = pd.Series()\n",
    "\n",
    "for i in range(len(base['UF'])):\n",
    "    if base['V61041'][i] == 1:\n",
    "        base['var_depend3.2_inicial'][i] = 'não pobre'\n",
    "    elif base['V61041'][i]==2:\n",
    "        base['var_depend3.2_inicial'][i]  = 'não pobre'\n",
    "    elif base['V61041'][i]==3:\n",
    "        base['var_depend3.2_inicial'][i]  = 'pobre'\n",
    "\n",
    "    \n",
    " \n",
    "# sn.countplot(base, x='var_depend3.2_inicial')\n",
    "# print(base['var_depend3.2_inicial'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_depend4.1_inicial\n",
    "# DOMICILIO['V0212']\n",
    "# 1 – Rede geral, rede pluvial ou fossa ligada à rede = não pobre\n",
    "# 2 – Fossa não ligada à rede = pobre\n",
    "# 3 – Vala = pobre\n",
    "# 4 – Rio, lago ou mar = pobre\n",
    "# 5 – Outra forma = pobre\n",
    "\n",
    "base['var_depend4.1_inicial'] = pd.Series()\n",
    "\n",
    "for i in range(len(base['UF'])):\n",
    "    if base['V0212'][i] == 1:\n",
    "        base['var_depend4.1_inicial'][i] = 'não pobre'\n",
    "    elif base['V0212'][i]==2:\n",
    "        base['var_depend4.1_inicial'][i]  = 'pobre'\n",
    "    elif base['V0212'][i]==3:\n",
    "        base['var_depend4.1_inicial'][i]  = 'pobre'\n",
    "    elif base['V0212'][i]==4:\n",
    "        base['var_depend4.1_inicial'][i]  = 'pobre'\n",
    "    elif base['V0212'][i]==5:\n",
    "        base['var_depend4.1_inicial'][i]  = 'pobre'\n",
    "\n",
    "  \n",
    " \n",
    "# sn.countplot(DOMICILIO, x='var_depend4.1_inicial')\n",
    "# print(DOMICILIO['var_depend4.1_inicial'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_depend4.2_inicial\n",
    "# DOMICILIO['V0213']\n",
    "# 1 – Coletado diretamente por serviço de limpeza = não pobre\n",
    "# 2 – Coletado em caçamba de serviço de limpeza = não pobre\n",
    "# 3 – Queimado (na propriedade) = pobre\n",
    "# 4 – Enterrado (na propriedade) = pobre\n",
    "# 5 – Jogado em terreno baldio ou logradouro = pobre\n",
    "# 6 – Outro destino = pobre\n",
    "\n",
    "\n",
    "base['var_depend4.2_inicial'] = pd.Series()\n",
    "\n",
    "for i in range(len(base['V6199'])):\n",
    "    if base['V0213'][i] == 1:\n",
    "        base['var_depend4.2_inicial'][i] = 'não pobre'\n",
    "    elif base['V0213'][i]==2:\n",
    "        base['var_depend4.2_inicial'][i]  = 'pobre'\n",
    "    elif base['V0213'][i]==3:\n",
    "        base['var_depend4.2_inicial'][i]  = 'pobre'\n",
    "    elif base['V0213'][i]==4:\n",
    "        base['var_depend4.2_inicial'][i]  = 'pobre'\n",
    "    elif base['V0213'][i]==5:\n",
    "        base['var_depend4.2_inicial'][i]  = 'pobre'\n",
    "    elif base['V0213'][i]==6:\n",
    "        base['var_depend4.2_inicial'][i]  = 'pobre'\n",
    "\n",
    "    \n",
    " \n",
    "# sn.countplot(DOMICILIO, x='var_depend4.2_inicial')\n",
    "# print(DOMICILIO['var_depend4.2_inicial'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_depend4.3_inicial\n",
    "# DOMICILIO['V0220']\n",
    "# 1 – Sim = não pobre\n",
    "# 2 – Não = pobre\n",
    "\n",
    "base['var_depend4.3_inicial'] = pd.Series()\n",
    "\n",
    "for i in range(len(base['V6199'])):\n",
    "    if base['V0220'][i] == 1:\n",
    "        base['var_depend4.3_inicial'][i] = 'não pobre'\n",
    "    elif base['V0220'][i]==2:\n",
    "        base['var_depend4.3_inicial'][i]  = 'pobre'\n",
    "    \n",
    " \n",
    "# sn.countplot(DOMICILIO, x='var_depend4.3_inicial')\n",
    "# print(DOMICILIO['var_depend4.3_inicial'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score variavel dependente do grupo 3\n",
    "# 3\n",
    "# Pontuação:\n",
    "# 0 - não pobre\n",
    "# 1 - pobre\n",
    "# 2 - pobre\n",
    "\n",
    "\n",
    "# gerando permutações 3\n",
    "lista = ['não pobre', 'pobre']\n",
    "permutas_3 = []\n",
    "\n",
    "for i in product(lista, repeat=2):\n",
    "    permutas_3.append(i)\n",
    "print(permutas_3)\n",
    "\n",
    "# [('não pobre', 'não pobre') = 0\n",
    "# ('não pobre', 'pobre') = 1\n",
    "# ('pobre', 'não pobre') = 1\n",
    "# ('pobre', 'pobre')] = 2\n",
    "\n",
    "   \n",
    "base['subjetividade'] = pd.Series()\n",
    "for i in range(len(base['UF'])):\n",
    "    if base['var_depend3.1_inicial'][i] =='não pobre' and base['var_depend3.2_inicial'][i] == 'não pobre':\n",
    "        base['subjetividade'][i] = 0\n",
    "        \n",
    "    elif base['var_depend3.1_inicial'][i] =='pobre' and base['var_depend3.2_inicial'][i] == 'pobre':\n",
    "        base['subjetividade'][i]  = 1\n",
    "    \n",
    "    else:\n",
    "        base['subjetividade'][i]  = 1\n",
    "\n",
    " \n",
    "# grafico3 = sn.countplot(base, x='var_depend3')\n",
    "# print(base['subjetividade'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score variavel dependente do grupo 4\n",
    "# Pontuação:\n",
    "# 0 - não pobre\n",
    "# 1 - não pobre\n",
    "# 2 - pobre\n",
    "# 3 - pobre\n",
    "\n",
    "\n",
    "# gerando permutações 4    \n",
    "lista = ['não pobre', 'pobre']\n",
    "permutas_4 = []\n",
    "\n",
    "for i in product(lista, repeat=3):\n",
    "    permutas_4.append(i)\n",
    "print(permutas_4)\n",
    "    \n",
    "# ('não pobre', 'não pobre', 'não pobre') = não pobre\n",
    "# ('não pobre', 'não pobre', 'pobre') = não pobre\n",
    "# ('não pobre', 'pobre', 'não pobre') = não pobre\n",
    "# ('não pobre', 'pobre', 'pobre') = pobre\n",
    "# ('pobre', 'não pobre', 'não pobre') = não pobre\n",
    "# ('pobre', 'não pobre', 'pobre') = pobre\n",
    "# ('pobre', 'pobre', 'não pobre') = pobre\n",
    "# ('pobre', 'pobre', 'pobre') = pobre\n",
    "\n",
    "\n",
    "base['serv_essenciais'] = pd.Series()\n",
    "\n",
    "for i in range(len(base['V6199'])):\n",
    "    if base['var_depend4.1_inicial'][i]=='não pobre' and base['var_depend4.2_inicial'][i]=='não pobre' and base['var_depend4.3_inicial'][i]=='não pobre':\n",
    "        base['serv_essenciais'][i]=0\n",
    "        \n",
    "    elif base['var_depend4.1_inicial'][i]=='não pobre' and base['var_depend4.2_inicial'][i]=='não pobre' and base['var_depend4.3_inicial'][i]=='pobre':\n",
    "        base['serv_essenciais'][i]=0\n",
    "    \n",
    "    elif base['var_depend4.1_inicial'][i]=='não pobre' and base['var_depend4.2_inicial'][i]=='pobre' and base['var_depend4.3_inicial'][i]=='não pobre':\n",
    "        base['serv_essenciais'][i]=0\n",
    "        \n",
    "    elif base['var_depend4.1_inicial'][i]=='não pobre' and base['var_depend4.2_inicial'][i]=='pobre' and base['var_depend4.3_inicial'][i]=='pobre':\n",
    "        base['serv_essenciais'][i]=1\n",
    "        \n",
    "    elif base['var_depend4.1_inicial'][i]=='pobre' and base['var_depend4.2_inicial'][i]=='não pobre' and base['var_depend4.3_inicial'][i]=='não pobre':\n",
    "        base['serv_essenciais'][i]=0\n",
    "        \n",
    "    elif base['var_depend4.1_inicial'][i]=='pobre' and base['var_depend4.2_inicial'][i]=='não pobre' and base['var_depend4.3_inicial'][i]=='pobre':\n",
    "        base['serv_essenciais'][i]=1\n",
    "        \n",
    "    elif base['var_depend4.1_inicial'][i]=='pobre' and base['var_depend4.2_inicial'][i]=='pobre' and base['var_depend4.3_inicial'][i]=='não pobre':\n",
    "        base['serv_essenciais'][i]=1\n",
    "        \n",
    "    elif base['var_depend4.1_inicial'][i]=='pobre' and base['var_depend4.2_inicial'][i]=='pobre' and base['var_depend4.3_inicial'][i]=='pobre':\n",
    "        base['serv_essenciais'][i]=1\n",
    "        \n",
    "\n",
    "    \n",
    "# grafico4 = sn.countplot(DOMICILIO, x = 'var_depend4')\n",
    "# print(DOMICILIO['var_depend4'].value_counts())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # verificacao NAs nas variaveis que participam do processo de criacao das variaveis dependentes 1,2,3,4\n",
    "var = ['rdpc','seg_alimentar','var_depend3.1_inicial','var_depend3.2_inicial','subjetividade','var_depend4.1_inicial','var_depend4.2_inicial','serv_essenciais' ]\n",
    "for i in var:\n",
    "    j = base[i].unique()\n",
    "    print(f'{i}:', j)\n",
    "    \n",
    "    \n",
    "# # deletando linhas que possuem 'nan' na variavel dependente\n",
    "# # linhas antes da remoção = 693760\n",
    "# # linhas depois da remoção = 682767\n",
    "base = base.dropna(subset = ['serv_essenciais'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid das 4 variaveis\n",
    "# plano\n",
    "fig, eixos = mplt.subplots (2, 2, figsize=(10,10) )\n",
    "\n",
    "# grafico1 = sn.countplot(MORADOR, x = 'var_depend1')\n",
    "sn.countplot(base, x='rdpc', ax=eixos[0,0])\n",
    "eixos[0,0].set_title('RENDA_MONET_PC')\n",
    "eixos[0,0].set_xlabel('')\n",
    "eixos[0,0].set_ylabel('')\n",
    "\n",
    "# grafico2 = sn.countplot(DOMICILIO, x = 'var_depend2')\n",
    "sn.countplot(base, x = 'seg_alimentar', ax=eixos[0,1])\n",
    "eixos[0,1].set_title('V6199')\n",
    "eixos[0,1].set_xlabel('')\n",
    "eixos[0,1].set_ylabel('')\n",
    "\n",
    "# grafico3 = sn.countplot(CONDICOES_VIDA, x = 'var_depend3')\n",
    "sn.countplot(base, x = 'subjetividade', ax= eixos[1,0])\n",
    "eixos[1,0].set_title('V6101 e V61041')\n",
    "eixos[1,0].set_xlabel('')\n",
    "eixos[1,0].set_ylabel('')\n",
    "\n",
    "# grafico4 = sn.countplot(DOMICILIO, x = 'var_depend4')\n",
    "sn.countplot(base, x = 'serv_essenciais', ax= eixos[1,1])\n",
    "eixos[1,1].set_title('V0212, V0213 e V0220')\n",
    "eixos[1,1].set_xlabel('')\n",
    "eixos[1,1].set_ylabel('')\n",
    "\n",
    "mplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variaveis indepentendes que serão usadas para estatisticas descritivas\n",
    "# MORADOR = UF, RENDA_MONET_PC\n",
    "# DOMICILIO = UF, V0212,V0213,V0220,V6199\n",
    "# CONDICOES_VIDA = UF, V6101, V61041\n",
    "# MORADOR_QUALI_VIDA = UF, TIPO_SITUACAO_REG,GRANDE_REGIAO,C1,C2,C3,C4\n",
    "\n",
    "estat_morador = base[['RENDA_MONET_PC']].describe().round(2)\n",
    "# estat_domicilio = DOMICILIO[['V0212','V0213','V0220','V6199']].value_counts()\n",
    "# estat_condicoes_vida = CONDICOES_VIDA[['V6101','V61041']].describe().round(2)\n",
    "# estat_morador_quali = MORADOR_QUALI_VIDA[['C1','C2','C3','C4']].describe().round(2)\n",
    "\n",
    "\n",
    "tabela_estat = tabulate({\n",
    "    \"MORADOR (base)\": [estat_morador.to_string()],\n",
    "    # \"DOMICILIO\": [estat_domicilio.to_string()],\n",
    "    # \"CONDICOES_VIDA\": [estat_condicoes_vida.to_string()],\n",
    "    # \"MORADOR_QUALI_VIDA\": [estat_morador_quali.to_string()]\n",
    "}, headers=\"keys\", tablefmt=\"grid\")\n",
    "\n",
    "\n",
    "print(tabela_estat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modificando nome dos UF\n",
    "base['UF'] = base['UF'].map({11 : 'RO',\n",
    "                               12 : 'AC',\n",
    "                                13 : 'AM',\n",
    "                                14 : 'RR',\n",
    "                                15 : 'PR',\n",
    "                                16 : 'AM',\n",
    "                                17 : 'TO',\n",
    "                                21 : 'MA',\n",
    "                                22 : 'PI',\n",
    "                                23 : 'CE',\n",
    "                                24 : 'RN',\n",
    "                                25 : 'PB',\n",
    "                                26 : 'PE',\n",
    "                                27 : 'AL',\n",
    "                                28 : 'SE',\n",
    "                                29 : 'BA',\n",
    "                                31 : 'MG',\n",
    "                                32 : 'ES',\n",
    "                                33 : 'RJ',\n",
    "                                35 : 'SP',\n",
    "                                41 : 'PR',\n",
    "                                42 : 'SC',\n",
    "                                43 : 'RS',\n",
    "                                50 : 'MS',\n",
    "                                51 : 'MT',\n",
    "                                52 : 'GO',\n",
    "                                53 : 'DF'}) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# media salarial por estado\n",
    "media_renda_uf = base.groupby('UF')['RENDA_MONET_PC'].mean().sort_values()\n",
    "print(media_renda_uf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analise das variaveis independentes escolhidas de cada caderno por UF\n",
    "# RENDA_MONET_PC\n",
    "fig, ax1 = mplt.subplots(figsize=(10,5))\n",
    "sn.barplot(x = 'UF' , y = 'RENDA_MONET_PC' , data = base, ax = ax1, palette='dark' )\n",
    "mplt.xlabel('Estado')\n",
    "mplt.ylabel('Renda Monetária Per Capita')\n",
    "mplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlacao de pearson entre variaveis dependentes e RENDA_MONET_PC\n",
    "\n",
    "# rdpc e RENDA_MONET_PC\n",
    "# Removendo valores infinitos e ausentes\n",
    "valid_indexes1 = np.isfinite(base['rdpc']) & np.isfinite(base['RENDA_MONET_PC'])\n",
    "filtered_rdpc = base['rdpc'][valid_indexes1]\n",
    "filtered_renda1 = base['RENDA_MONET_PC'][valid_indexes1]\n",
    "\n",
    "# Cálculo da correlação de Pearson\n",
    "correlacao1, p_valor1 = stats.pearsonr(filtered_rdpc, filtered_renda1)\n",
    "print('rdpc: ',correlacao1)\n",
    "\n",
    "\n",
    "# seg_alimentar e RENDA_MONET_PC\n",
    "# Removendo valores infinitos e ausentes\n",
    "valid_indexes2 = np.isfinite(base['seg_alimentar']) & np.isfinite(base['RENDA_MONET_PC'])\n",
    "filtered_seg_alimentar = base['seg_alimentar'][valid_indexes2]\n",
    "filtered_renda2 = base['RENDA_MONET_PC'][valid_indexes2]\n",
    "\n",
    "# Cálculo da correlação de Pearson\n",
    "correlacao2, p_valor2 = stats.pearsonr(filtered_seg_alimentar, filtered_renda2)\n",
    "print('seg_alimentar: ',correlacao2)\n",
    "\n",
    "\n",
    "# subjetividade e RENDA_MONET_PC\n",
    "# Removendo valores infinitos e ausentes\n",
    "valid_indexes3 = np.isfinite(base['subjetividade']) & np.isfinite(base['RENDA_MONET_PC'])\n",
    "filtered_subjetividade = base['subjetividade'][valid_indexes3]\n",
    "filtered_renda3 = base['RENDA_MONET_PC'][valid_indexes3]\n",
    "\n",
    "# Cálculo da correlação de Pearson\n",
    "correlacao3, p_valor3 = stats.pearsonr(filtered_subjetividade, filtered_renda3)\n",
    "print('subjetividade: ',correlacao3)\n",
    "\n",
    "\n",
    "# serv_essenciais e RENDA_MONET_PC\n",
    "# Removendo valores infinitos e serv_essenciais\n",
    "valid_indexes4 = np.isfinite(base['serv_essenciais']) & np.isfinite(base['RENDA_MONET_PC'])\n",
    "filtered_serv_essenciais = base['serv_essenciais'][valid_indexes4]\n",
    "filtered_renda4 = base['RENDA_MONET_PC'][valid_indexes4]\n",
    "\n",
    "# Cálculo da correlação de Pearson\n",
    "correlacao4, p_valor4 = stats.pearsonr(filtered_serv_essenciais, filtered_renda4)\n",
    "print('serv_essenciais: ',correlacao4)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIÁVEIS INDEPENDENTES\n",
    "# C4 - Nível de Instrução da pessoa (perfil do chefe)\n",
    "    # 1 – Sem instrução\n",
    "    # 2 – Ensino Fundamental Incompleto\n",
    "    # 3 – Ensino Fundamental Completo \n",
    "    # 4 – Ensino Médio Incompleto\n",
    "    # 5 – Ensino Médio Completo \n",
    "    # 6 – Ensino Superior Incompleto\n",
    "    # 7 – Ensino Superior Completo\n",
    "\n",
    "# C3 - Sexo (PERFIL DO CHEFE)\n",
    "    # 1- Masculino\n",
    "    # 2- Feminino\n",
    "\n",
    "# C2 - Cor ou raça (PERFI DO CHEFE)\n",
    "    # 1 – Brancos\n",
    "    # 2 – Pretos e Pardos\n",
    "    # 3 – Outros\n",
    "\n",
    "# C1 - IDADE - PERFIL DO CHEFE\n",
    "    # 1 – Até 24 anos\n",
    "    # 2 – 25 a 49 anos\n",
    "    # 3 – 50 a 64 anos\n",
    "    # 4 – 65 anos ou mais\n",
    "\n",
    "# GRANDE_REGIAO - REGIÃO (DUMY) - referência é o sudeste\n",
    "    # 1- Norte\n",
    "    # 2- Nordeste\n",
    "    # 3- Sudeste\n",
    "    # 4- Sul\n",
    "    # 5- Centro-Oeste\n",
    "    \n",
    "# TIPO_SITUACAO_REG urbano (1) x rural (2)\n",
    "    # 1 - Urbano\n",
    "    # 2 - Rural\n",
    "\n",
    "\n",
    "# VARIÁVEIS DEPENDENTES\n",
    "# rdpc\n",
    "# seg_alimentar\n",
    "# subjetividade\n",
    "# serv_essenciais\n",
    "\n",
    "base_final = base[['rdpc','seg_alimentar','subjetividade','serv_essenciais', 'TIPO_SITUACAO_REG','GRANDE_REGIAO', 'C1', 'C2', 'C3', 'C4', 'RENDA_MONET_PC']]\n",
    "\n",
    "# mapeamento das variaveis\n",
    "# base_final['TIPO_SITUACAO_REG'] = base_final['TIPO_SITUACAO_REG'].map({1:'Urbano', 2:'Rural'}).astype('category')      \n",
    "# base_final['GRANDE_REGIAO'] = base_final['GRANDE_REGIAO'].map({1:'Não sudeste', 2:'Não sudeste', 3:'Sudeste', 4:'Não sudeste', 5:'Não sudeste'}).astype('category')   \n",
    "# base_final['C1'] = base_final['C1'].map({1:'Até 24 anos', 2:'25 a 49 anos', 3:'50 a 64 anos', 4:'65 anos ou mais'}).astype('category')         \n",
    "# base_final['C2'] = base_final['C2'].map({1:'Brancos', 2:'Pretos e Pardos', 3:'Outros'}).astype('category')   \n",
    "# base_final['C3'] = base_final['C3'].map({1:'Masculino', 2:'Feminino'}).astype('category')   \n",
    "# base_final['C4'] = base_final['C4'].map({1:'Sem instrução', 2:'Ensino Fundamental Incompleto', 3:'Ensino Fundamental Completo ', 4:'Ensino Médio Incompleto', 5:'Ensino Médio Completo ',6:'Ensino Superior Incompleto', 7:'Ensino Superior Completo' }).astype('category')    \n",
    "\n",
    "# base_final.to_excel('base_final.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MQO \n",
    "# https://nathaliatito.medium.com/scikit-learn-ou-statsmodels-avaliando-meu-modelo-de-regressão-f4c04b361fa7\n",
    "# variaveis x (serão iguais para todos os modelos)\n",
    "var_x = base_final[['TIPO_SITUACAO_REG','GRANDE_REGIAO', 'C1', 'C2','C3','C4','RENDA_MONET_PC']]\n",
    "\n",
    "# rdpv\n",
    "var_y = base_final[['rdpc']]\n",
    "var_x = sm.add_constant(var_x)\n",
    "modelo_rdpc = sm.OLS(var_y, var_x ).fit()\n",
    "modelo_rdpc.summary() # Teste t de significância individual = H0 indica irrelevância da variavel, portanto :. p_valor < 0.05 aceita H1 e mantém a variavel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teste de homocedasticidade usando Goldfeld-Quandt, p-valor < 0.05 indica que os dados não são homocedásticos\n",
    "# homocedasticidade = variação dos resíduos é constante\n",
    "\n",
    "\n",
    "###############\n",
    "# O resultado do teste de Goldfeld-Quandt que você obteve é o seguinte: (0.4761528626243073, 0.9999999999999999, 'increasing'). Vamos interpretar cada um desses valores:\n",
    "\n",
    "# O primeiro valor, 0.4761528626243073, é o valor estatístico calculado pelo teste de Goldfeld-Quandt. Esse valor é usado para avaliar a presença de heteroscedasticidade nos resíduos do modelo de regressão.\n",
    "\n",
    "# Em geral, se o valor estiver próximo de 1, isso sugere que não há evidência significativa de heteroscedasticidade nos resíduos. No seu caso, o valor obtido é menor que 1, o que indica que há indícios de heteroscedasticidade nos resíduos do modelo.\n",
    "\n",
    "# O segundo valor, 0.9999999999999999, é o valor p (p-value) associado ao valor estatístico. O valor p é usado para determinar se o valor estatístico é estatisticamente significativo. Nesse caso, o valor p é muito próximo de 1, o que sugere que não há evidência significativa para rejeitar a hipótese nula de ausência de heteroscedasticidade. Em outras palavras, não há evidência estatística para afirmar que a heteroscedasticidade está presente nos resíduos.\n",
    "\n",
    "# O terceiro valor, 'increasing', indica o padrão observado na heteroscedasticidade. O termo \"increasing\" significa que a variância dos resíduos aumenta conforme os valores previstos (variável independente) do modelo aumentam. Isso implica que a dispersão dos erros é maior à medida que os valores previstos aumentam.\n",
    "###############\n",
    "\n",
    "teste_homo1 = sms.het_goldfeldquandt(modelo_rdpc.resid, modelo_rdpc.model.exog)  # exog indica variaveis exógenas, ou seja, faz uma matriz das variaveis independentes do modelo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vif - rdpc\n",
    "# teste de multicolinearidade, usando VIF (Variance Inflation Factor)\n",
    "# caso o valor seja maior que 10, indica multicolinearidade, é preciso excluir essas variáveis\n",
    "vif= [ variance_inflation_factor(var_x.values, i ) for i in range(var_x.shape[1])]\n",
    "tabela_vif = pd.DataFrame({'vif':vif[1:]}, index = var_x.columns.drop('const'))\n",
    "print(tabela_vif)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # transferir para excel caso nao exceda o numero de linhas\n",
    "# # limite de linhas excel = 1.048.576 linhas e 16.384 colunas\n",
    "# # ex: CARACTERISTICAS_DIETA.to_excel('caracteristicas_dieta.xlsx', index=False)\n",
    "# # os itens de 'tabelas' e 'nome_tabelas' precisam estar alinhados\n",
    "\n",
    "# # x\n",
    "# tabelas = [ CARACTERISTICAS_DIETA,\n",
    "#             CONDICOES_VIDA,\n",
    "#             CONSUMO_ALIMENTAR,\n",
    "#             DOMICILIO,\n",
    "#             MORADOR,\n",
    "#             MORADOR_QUALI_VIDA ]\n",
    "\n",
    "# # i \n",
    "# nomes_tabelas = [   'CARACTERISTICAS_DIETA',\n",
    "#                     'CONDICOES_VIDA',\n",
    "#                     'CONSUMO_ALIMENTAR',\n",
    "#                     'DOMICILIO',\n",
    "#                     'MORADOR',\n",
    "#                     'MORADOR_QUALI_VIDA' ]\n",
    "\n",
    "\n",
    "# # zip serve para fazer o loop ao mesmo tempo nas minhas duas listas\n",
    "# for x, i in zip(tabelas, nomes_tabelas):\n",
    "    \n",
    "#     if len(x) < 1048576:\n",
    "#         print(f'{len(x)} , baixar: {i}')\n",
    "        \n",
    "#         dados = pd.DataFrame(x)\n",
    "#         nome_arquivo = i +'.xlsx'\n",
    "#         dados.to_excel(nome_arquivo, index=False)\n",
    "        \n",
    "#         print(f'arquivo {i} baixado com sucesso')\n",
    "                    \n",
    "#     else:\n",
    "#         print(f'{len(x)} , nao baixar: {i}')\n",
    "        \n",
    "       \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variaveis de cada tabela\n",
    "# for x , i in zip(tabelas, nomes_tabelas):\n",
    "#     dados_desc = pd.DataFrame(x).describe()\n",
    "#     arquivo = pd.ExcelWriter('arquivo_estatisticas_descritivas.xlsx', engine = 'xlsxwriter')\n",
    "#     dados_desc.to_excel(arquivo, sheet_name='{}'.format(i), index=True)\n",
    "#     arquivo.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arquivos de dicionarios das variaveis\n",
    "# diretorio_dic = r'C:\\Users\\Computadores Gamer\\OneDrive\\Área de Trabalho\\dados gradilene\\dados'\n",
    "# diretorio_dic = diretorio_dic.replace('\\\\', '/')\n",
    "# os.chdir(diretorio_dic)\n",
    "\n",
    "# os.listdir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sheets do arquivo dicionario\n",
    "# from openpyxl import load_workbook\n",
    "# dicionario = load_workbook('dicvar1718.xlsx')\n",
    "# sheets = dicionario.sheetnames\n",
    "# print(sheets) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lendo sheet 'Morador' e mantendo apenas as variaveis 'V....'\n",
    "# necessario generalizar esse codigo para cada sheet do arquivo\n",
    "\n",
    "\n",
    "# morador = pd.read_excel('dicvar1718.xlsx', sheet_name='Morador')\n",
    "\n",
    "# # cabecalho \n",
    "# morador.columns = morador.iloc[2,]\n",
    "\n",
    "# # preenchendo elementos NAs da coluna 'Código da variável', senao a função 'startswith' nao funciona\n",
    "# morador['Código da variável'].fillna('',inplace=True)\n",
    "\n",
    "# # filtrar apenas linhas em que em 'Código da variável' o elemento começa com 'V'\n",
    "# # lembrar que 'startswith' só funciona com o '.str'\n",
    "# morador = morador[morador['Código da variável'].str.startswith('V')]        # filtrando apenas as linhas de codigos 'V....'\n",
    "# print(morador)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generalizando codigo de ler cada sheet e filtrar apenas os codigos das variaveis\n",
    "# lista_tabelas_codigos = []\n",
    "\n",
    "# for i in sheets:\n",
    "#     caderno = pd.read_excel('dicvar1718.xlsx', sheet_name=i)\n",
    "#     caderno.columns = caderno.iloc[2,]\n",
    "#     caderno['Código da variável'].fillna('', inplace=True)\n",
    "#     caderno = caderno[caderno['Código da variável'].str.startswith('V')]\n",
    "#     lista_tabelas_codigos.append(caderno)\n",
    "\n",
    "\n",
    "# codigos_site = pd.concat(lista_tabelas_codigos, axis=0)\n",
    "# codigos_site = codigos_site[['Código da variável', 'Descrição']]\n",
    "# print(codigos_site)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vendo quantas variaveis de codigo tem em cada caderno para depois fazer o merge com a tabela 'codigos'\n",
    "# lista_cadernos = [CONSUMO_ALIMENTAR, CARACTERISTICAS_DIETA, DOMICILIO, CONDICOES_VIDA, MORADOR_QUALI_VIDA , MORADOR]\n",
    "\n",
    "# # colunas = CONSUMO_ALIMENTAR.columns.str.startswith('V')\n",
    "# # CONSUMO_ALIMENTAR.columns[np.where(colunas==True)]\n",
    "\n",
    "# codigos_total = []\n",
    "# for i in lista_cadernos:\n",
    "#     colunas = i.columns.str.startswith('V')\n",
    "#     nome = i.columns[np.where(np.logical_and(colunas, i.columns.str.match('.*[0-9]$')))] # logical_and é pra unir as condicoes. '.*[0-9]$' é uma expressao regular\n",
    "#     print(len(nome.unique()),nome)\n",
    "#     codigos_total.extend(nome) # coloca na lista, parecido com append, porem append é para adicionar um unico elemento no final da lista, o extend ja adiciona tudo de uma vez\n",
    "    \n",
    "    \n",
    "# codigos_cadernos = pd.DataFrame({'codigo':codigos_total})\n",
    "# codigos_cadernos.columns = ['Código da variável']\n",
    "# # codigos_cadernos.to_excel('codigos_cadernos.xlsx', index=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fazendo merge dos codigos que achei com os 207 codigos que sao o total de codigos de todos cadernos\n",
    "# codigos_final = pd.merge(codigos_site, codigos_cadernos, on='Código da variável', how = 'outer')\n",
    "# codigos_final = codigos_final[['Código da variável','Descrição']]\n",
    "# print(codigos_final)\n",
    "\n",
    "# codigos_final.to_excel('codigos_final.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
