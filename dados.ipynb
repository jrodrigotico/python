{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pacotes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "import seaborn as sn\n",
    "from itertools import permutations, product\n",
    "import matplotlib.pyplot as mplt\n",
    "import scipy.stats as stats\n",
    "from tabulate import tabulate\n",
    "from scipy.stats import chi2_contingency \n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tools as smt\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setar diretorio dos cadernos (codigo caso puxe os arquivos com todas as colunas originais do ibge)\n",
    "diretorio = r'C:\\Users\\Computadores Gamer\\OneDrive\\√Årea de Trabalho\\dados gradilene\\dados'\n",
    "diretorio = diretorio.replace('\\\\', '/')\n",
    "\n",
    "os.chdir(diretorio)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Cadernos IBGE\n",
    "\n",
    "#### DOMICILIO\n",
    "# largura do txt\n",
    "larguras = [2,4,1,9,2,1,1,1,1,2,1,1,1,1,1,1,1,1,1,2,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,14,14,1]\n",
    "\n",
    "# nome das colunas\n",
    "colunas = [\"UF\", \"ESTRATO_POF\", \"TIPO_SITUACAO_REG\",\n",
    "            \"COD_UPA\", \"NUM_DOM\", \"V0201\", \"V0202\",\n",
    "            \"V0203\", \"V0204\", \"V0205\", \"V0206\", \"V0207\",\n",
    "            \"V0208\", \"V0209\", \"V02101\", \"V02102\",\n",
    "            \"V02103\", \"V02104\", \"V02105\", \"V02111\",\n",
    "            \"V02112\", \"V02113\", \"V0212\", \"V0213\",\n",
    "            \"V02141\", \"V02142\", \"V0215\", \"V02161\",\n",
    "            \"V02162\", \"V02163\", \"V02164\", \"V0217\",\n",
    "            \"V0219\", \"V0220\", \"V0221\", \"PESO\",\n",
    "            \"PESO_FINAL\", \"V6199\"]\n",
    "\n",
    "# leitura dos dados\n",
    "DOMICILIO = pd.read_fwf(\n",
    "    os.path.join(diretorio, \"DOMICILIO.txt\"), \n",
    "    widths=larguras,\n",
    "    na_values=[\" \"],\n",
    "    names=colunas,\n",
    "    decimal=\".\"\n",
    ")\n",
    "\n",
    "##### CONDICOES_VIDA\n",
    "# largura do txt\n",
    "larguras = [2,4,1,9,2,1,2,1,6,5,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,14,14,10]\n",
    "\n",
    "# nome das colunas\n",
    "colunas = [\"UF\", \"ESTRATO_POF\", \"TIPO_SITUACAO_REG\",\n",
    "            \"COD_UPA\", \"NUM_DOM\", \"NUM_UC\", \"COD_INFORMANTE\",\n",
    "            \"V6101\", \"V6102\", \"V6103\", \"V61041\", \"V61042\",\n",
    "            \"V61043\", \"V61044\", \"V61045\", \"V61046\",\n",
    "            \"V61051\", \"V61052\", \"V61053\", \"V61054\",\n",
    "            \"V61055\", \"V61056\", \"V61057\", \"V61058\",\n",
    "            \"V61061\", \"V61062\", \"V61063\", \"V61064\",\n",
    "            \"V61065\", \"V61066\", \"V61067\", \"V61068\",\n",
    "            \"V61069\", \"V610610\", \"V610611\", \"V61071\",\n",
    "            \"V61072\", \"V61073\", \"V6108\", \"V6109\",\n",
    "            \"V6110\", \"V6111\", \"V6112\", \"V6113\", \"V6114\",\n",
    "            \"V6115\", \"V6116\", \"V6117\", \"V6118\", \"V6119\",\n",
    "            \"V6120\", \"V6121\", \"PESO\", \"PESO_FINAL\",\n",
    "            \"RENDA_TOTAL\"]\n",
    "\n",
    "# leitura dos dados\n",
    "CONDICOES_VIDA = pd.read_fwf(\n",
    "    os.path.join(diretorio, \"CONDICOES_VIDA.txt\"),\n",
    "    widths=larguras,\n",
    "    na_values=[\" \"],\n",
    "    names=colunas,\n",
    "    decimal=\".\"\n",
    ")\n",
    "\n",
    "\n",
    "##### MORADOR_QUALI_VIDA\n",
    "# largura do txt\n",
    "larguras = [2,4,1,9,2,1,2,20,20,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,2,20,20,14,14]\n",
    "\n",
    "# nome das colunas\n",
    "colunas = [\"UF\",\"ESTRATO_POF\",\"TIPO_SITUACAO_REG\",\"COD_UPA\",\n",
    "            \"NUM_DOM\",\"NUM_UC\",\"COD_INFORMANTE\",\"CONTAGEM_PONDERADA\",\n",
    "            \"FUNCAO_PERDA\",\"V201\",\"V202\",\"V204\",\"V205\",\"V206\",\n",
    "            \"V207\",\"V208\",\"V209\",\"V210\",\"V211\",\"V212\",\"V214\",\"V215\",\n",
    "            \"V216\",\"V217\",\"V301\",\"V302\",\"V303\",\"V304\",\"V305\",\"V306\",\n",
    "            \"V307\",\"V308\",\"V401\",\"V402\",\"V403\",\"V501\",\"V502\",\"V503\",\n",
    "            \"V504\",\"V505\",\"V506\",\"V601\",\"V602\",\"V603\",\"V604\",\"V605\",\n",
    "            \"V606\",\"V607\",\"V608\",\"V609\",\"V610\",\"V611\",\"V701\",\"V702\",\n",
    "            \"V703\",\"V704\",\"V801\",\"V802\",\"V901\",\"V902\",\"GRANDE_REGIAO\",\n",
    "            \"C1\",\"C2\",\"C3\",\"C4\",\"C5\",\"C6\",\"C7\",\"RENDA_DISP_PC\",\n",
    "            \"RENDA_DISP_PC_SS\",\"PESO\",\"PESO_FINAL\"]\n",
    "\n",
    "# leitura dos dados\n",
    "MORADOR_QUALI_VIDA = pd.read_fwf(\n",
    "    os.path.join(diretorio, \"MORADOR_QUALI_VIDA.txt\"),\n",
    "    widths=larguras,\n",
    "    na_values=[\" \"],\n",
    "    names=colunas,\n",
    "    decimal=\".\"\n",
    ")\n",
    "\n",
    "\n",
    "#### MORADOR\n",
    "# largura do txt\n",
    "larguras = [2,4,1,9,2,1,2,2,1,2,2,4,3,1,1,\n",
    "            1,1,1,2,1,2,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,2,1,1,2,1,1,2,1,1,1,\n",
    "            2,1,2,14,14,10,1,20,20,20,20]\n",
    "\n",
    "# nome das colunas\n",
    "colunas = [\"UF\", \"ESTRATO_POF\", \"TIPO_SITUACAO_REG\",\n",
    "            \"COD_UPA\", \"NUM_DOM\", \"NUM_UC\", \"COD_INFORMANTE\",\n",
    "            \"V0306\", \"V0401\", \"V04021\", \"V04022\", \"V04023\",\n",
    "            \"V0403\", \"V0404\", \"V0405\", \"V0406\", \"V0407\",\n",
    "            \"V0408\", \"V0409\", \"V0410\", \"V0411\", \"V0412\",\n",
    "            \"V0413\", \"V0414\", \"V0415\", \"V0416\",\n",
    "            \"V041711\", \"V041712\", \"V041721\", \"V041722\",\n",
    "            \"V041731\", \"V041732\", \"V041741\", \"V041742\",\n",
    "            \"V0418\", \"V0419\", \"V0420\", \"V0421\", \"V0422\",\n",
    "            \"V0423\", \"V0424\", \"V0425\", \"V0426\", \"V0427\",\n",
    "            \"V0428\", \"V0429\", \"V0430\", \"ANOS_ESTUDO\",\n",
    "            \"PESO\", \"PESO_FINAL\", \"RENDA_TOTAL\",\n",
    "            \"NIVEL_INSTRUCAO\", \"RENDA_DISP_PC\",\"RENDA_MONET_PC\",\n",
    "            \"RENDA_NAO_MONET_PC\",\"DEDUCAO_PC\" ]\n",
    "\n",
    "# leitura dos dados\n",
    "MORADOR = pd.read_fwf(\n",
    "    os.path.join(diretorio, \"MORADOR.txt\"),\n",
    "    widths=larguras,\n",
    "    na_values=[\" \"],\n",
    "    names=colunas,\n",
    "    decimal=\".\"\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Computadores Gamer\\AppData\\Local\\Temp\\ipykernel_16656\\1938701892.py:5: FutureWarning: Passing 'suffixes' which cause duplicate columns {'PESO_FINAL_y', 'PESO_y'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  base = pd.merge(MORADOR_QUALI_VIDA, bigdata2, on = ['UF', 'ESTRATO_POF',\"TIPO_SITUACAO_REG\",\"COD_UPA\", \"NUM_DOM\"],how = 'right')\n"
     ]
    }
   ],
   "source": [
    "# #### Merges \n",
    "# pd.set_option('display.max_columns', 100)\n",
    "bigdata = pd.merge(DOMICILIO, MORADOR, on = ['UF', 'ESTRATO_POF',\"TIPO_SITUACAO_REG\",\"COD_UPA\", \"NUM_DOM\"], how='left')\n",
    "bigdata2 = pd.merge(CONDICOES_VIDA, bigdata, on = ['UF', 'ESTRATO_POF',\"TIPO_SITUACAO_REG\",\"COD_UPA\", \"NUM_DOM\"], how = 'right')\n",
    "base = pd.merge(MORADOR_QUALI_VIDA, bigdata2, on = ['UF', 'ESTRATO_POF',\"TIPO_SITUACAO_REG\",\"COD_UPA\", \"NUM_DOM\"],how = 'right')\n",
    "\n",
    "\n",
    "# removendo colunas duplicadas, ou seja, com sufixo '_x' e '_y'\n",
    "# '$' indica trecho no final da palavra\n",
    "# colunas_del_x = base.filter(regex=f'_x$').columns\n",
    "# base = base.drop(colunas_del_x, axis=1)\n",
    "\n",
    "# colunas_del_y = base.filter(regex=f'_y$').columns\n",
    "# base = base.drop(colunas_del_y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tratamento da 'base'\n",
    "# excluindo todas as linhas que possuem tudo 'nan'\n",
    "base = base.dropna(how = 'all') \n",
    "\n",
    "\n",
    "# tratando valores nan em RENDA_MONET_PC como zero\n",
    "for i in range(len(base['UF'])):\n",
    "    if pd.isna(base['RENDA_MONET_PC'][i]):\n",
    "       base['RENDA_MONET_PC'][i]=float(0) \n",
    "\n",
    "print(base['RENDA_MONET_PC'].isna().unique())\n",
    "\n",
    "\n",
    "for i in range(len(base['UF'])):\n",
    "    if pd.isna(base['V6199'][i]):\n",
    "       base['V6199'][i]='teste' \n",
    "\n",
    "print(base['V6199'].unique())\n",
    "\n",
    "\n",
    "for i in range(len(base['UF'])):\n",
    "    if pd.isna(base['V6101'][i]):\n",
    "       base['V6101'][i]='teste'\n",
    "\n",
    "print(base['V6101'].unique())\n",
    "\n",
    "\n",
    "for i in range(len(base['UF'])):\n",
    "    if pd.isna(base['V61041'][i]):\n",
    "       base['V61041'][i]='teste' \n",
    "\n",
    "print(base['V61041'].unique())\n",
    "\n",
    "\n",
    "# aqui tem na\n",
    "for i in range(len(base['UF'])):\n",
    "    if pd.isna(base['V0212'][i]):\n",
    "       base['V0212'][i]='existe na' \n",
    "\n",
    "print(base['V0212'].unique())\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(base['UF'])):\n",
    "    if pd.isna(base['V0213'][i]):\n",
    "       base['V0213'][i]='existe na' \n",
    "\n",
    "print(base['V0213'].unique())\n",
    "\n",
    "\n",
    "for i in range(len(base['UF'])):\n",
    "    if pd.isna(base['V0220'][i]):\n",
    "       base['V0220'][i]='existe na' \n",
    "\n",
    "print(base['V0220'].unique())\n",
    "\n",
    "\n",
    "# retirando linha da variavel 'V0212' que possui na\n",
    "base = base.loc[base['V0212'] != 'existe na']\n",
    "\n",
    "\n",
    "# reindexando a base\n",
    "# com as linhas deletadas os ind√≠ces ficam fora de ordem e isso pode dar problema nos loops seguintes\n",
    "base.reset_index(drop=True, inplace=True) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando 'na' nas colunas que ser√£o utilizadas no decorrer do c√≥digo\n",
    "# esse c√≥digo √© mais perform√°tico\n",
    "base = base[['UF', 'ESTRATO_POF','TIPO_SITUACAO_REG','COD_UPA', 'NUM_DOM','RENDA_MONET_PC','V6199','V6101','V61041','V0212','V0213','V0220', 'C1','C2','C3','C4','GRANDE_REGIAO','TIPO_SITUACAO_REG']]\n",
    "\n",
    "colunas_na = base.columns[base.isna().any()].tolist()\n",
    "print(colunas_na)\n",
    "\n",
    "base = base.dropna(subset=['RENDA_MONET_PC','V0212'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria√ß√£o vari√°veis dependentes - parte 1\n",
    "\n",
    "#rdpc\n",
    "# var_depend1\n",
    "# MORADOR['RENDA_MONET_PC']\n",
    "# menor ou igual a 1/4 de SM = pobre\n",
    "# acima de 1/4 de SM = n√£o pobre\n",
    "# SM (2017) = 937 \n",
    "def get_rdpc(z):\n",
    "    if z <= 937/4:\n",
    "        return 1\n",
    "    return 0\n",
    "base['rdpc'] = base['RENDA_MONET_PC'].apply(lambda z: get_rdpc(z))\n",
    "\n",
    "# seg_alimentar\n",
    "# var_depend2 \n",
    "# DOMICILIO['V6199']\n",
    "# 1 ‚Äì Seguran√ßa = n√£o pobre\n",
    "# 2 ‚Äì Inseguran√ßa leve = pobre\n",
    "# 3 ‚Äì Inseguran√ßa moderada = pobre\n",
    "# 4 ‚Äì Inseguran√ßa grave = pobre\n",
    "def get_seg_alimentar(z):\n",
    "    if z == 1:\n",
    "        return 0\n",
    "    return 1\n",
    "base['seg_alimentar'] = base['V6199'].apply( lambda z: get_seg_alimentar(z))\n",
    "\n",
    "\n",
    "# subjetividade 1\n",
    "# var_depend3.1_inicial\n",
    "# CONDICOES_VIDA['V6101']\n",
    "# 1 ‚Äì Muita dificuldade = pobre\n",
    "# 2 ‚Äì Dificuldade = pobre\n",
    "# 3 ‚Äì Alguma dificuldade = n√£o pobre\n",
    "# 4 ‚Äì Alguma facilidade = n√£o pobre\n",
    "# 5 ‚Äì Facilidade = n√£o pobre\n",
    "# 6 ‚Äì Muita facilidade = n√£o pobre\n",
    "def get_subjetividade_i(z):\n",
    "    if z == 1 or z==2:\n",
    "        return 1\n",
    "    return 0\n",
    "base['var_depend3.1_inicial'] = base['V6101'].apply(lambda z: get_subjetividade_i(z))\n",
    "\n",
    "\n",
    "# subjetividade 2\n",
    "# var_depend3.2_inicial\n",
    "# CONDICOES_VIDA['V61041']\n",
    "# 1 - Bom = n√£o pobre\n",
    "# 2 - Satisfat√≥rio = n√£o pobre\n",
    "# 3 - Ruim = pobre\n",
    "def get_subjetividade_i2(z):\n",
    "    if z == 3:\n",
    "        return 1\n",
    "    return 0\n",
    "base['var_depend3.2_inicial'] = base['V61041'].apply(lambda z: get_subjetividade_i2(z))\n",
    "\n",
    "\n",
    "# serv_essenciais1\n",
    "# var_depend4.1_inicial\n",
    "# DOMICILIO['V0212']\n",
    "# 1 ‚Äì Rede geral, rede pluvial ou fossa ligada √† rede = n√£o pobre\n",
    "# 2 ‚Äì Fossa n√£o ligada √† rede = pobre\n",
    "# 3 ‚Äì Vala = pobre\n",
    "# 4 ‚Äì Rio, lago ou mar = pobre\n",
    "# 5 ‚Äì Outra forma = pobre\n",
    "def get_serv_essenciais1(z):\n",
    "    if z == 1:\n",
    "        return 0\n",
    "    return 1\n",
    "base['var_depend4.1_inicial'] = base['V0212'].apply(lambda z: get_serv_essenciais1(z))\n",
    "\n",
    "\n",
    "# serv_essenciais2\n",
    "# var_depend4.2_inicial\n",
    "# DOMICILIO['V0213']\n",
    "# 1 ‚Äì Coletado diretamente por servi√ßo de limpeza = n√£o pobre\n",
    "# 2 ‚Äì Coletado em ca√ßamba de servi√ßo de limpeza = n√£o pobre\n",
    "# 3 ‚Äì Queimado (na propriedade) = pobre\n",
    "# 4 ‚Äì Enterrado (na propriedade) = pobre\n",
    "# 5 ‚Äì Jogado em terreno baldio ou logradouro = pobre\n",
    "# 6 ‚Äì Outro destino = pobre\n",
    "def get_serv_essenciais2(z):\n",
    "    if z == 1 or z==2:\n",
    "        return 0\n",
    "    return 1    \n",
    "base['var_depend4.2_inicial'] = base['V0213'].apply(lambda z: get_serv_essenciais2(z))\n",
    "\n",
    "\n",
    "\n",
    "# serv_essenciais3\n",
    "# var_depend4.3_inicial\n",
    "# DOMICILIO['V0220']\n",
    "# 1 ‚Äì Sim = n√£o pobre\n",
    "# 2 ‚Äì N√£o = pobre\n",
    "def get_serv_essenciais3(z):\n",
    "    if z == 1:\n",
    "        return 0\n",
    "    return 1    \n",
    "base['var_depend4.3_inicial'] = base['V0220'].apply(lambda z: get_serv_essenciais3(z))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('n√£o pobre', 'n√£o pobre'), ('n√£o pobre', 'pobre'), ('pobre', 'n√£o pobre'), ('pobre', 'pobre')]\n",
      "[('n√£o pobre', 'n√£o pobre', 'n√£o pobre'), ('n√£o pobre', 'n√£o pobre', 'pobre'), ('n√£o pobre', 'pobre', 'n√£o pobre'), ('n√£o pobre', 'pobre', 'pobre'), ('pobre', 'n√£o pobre', 'n√£o pobre'), ('pobre', 'n√£o pobre', 'pobre'), ('pobre', 'pobre', 'n√£o pobre'), ('pobre', 'pobre', 'pobre')]\n"
     ]
    }
   ],
   "source": [
    "#### Cria√ß√£o v√°riaveis dependentes - parte 2\n",
    "\n",
    "# score variavel dependente do grupo 3\n",
    "# 3\n",
    "# Pontua√ß√£o:\n",
    "# 0 - n√£o pobre\n",
    "# 1 - pobre\n",
    "# 2 - pobre\n",
    "\n",
    "# gerando permuta√ß√µes 3\n",
    "lista = ['n√£o pobre', 'pobre']\n",
    "permutas_3 = []\n",
    "\n",
    "for i in product(lista, repeat=2):\n",
    "    permutas_3.append(i)\n",
    "print(permutas_3)\n",
    "\n",
    "# [('n√£o pobre', 'n√£o pobre') = 0\n",
    "# ('n√£o pobre', 'pobre') = 1\n",
    "# ('pobre', 'n√£o pobre') = 1\n",
    "# ('pobre', 'pobre')] = 2\n",
    "\n",
    "def get_subjetividade_principal(z,w):\n",
    "    if z == 0  and w == 0:\n",
    "        return 0\n",
    "    return 1    \n",
    "base['subjetividade'] = base.apply(lambda row: get_subjetividade_principal(row['var_depend3.1_inicial'], row['var_depend3.2_inicial']), axis=1)\n",
    "\n",
    "\n",
    "# score variavel dependente do grupo 4\n",
    "# Pontua√ß√£o:\n",
    "# 0 - n√£o pobre\n",
    "# 1 - n√£o pobre\n",
    "# 2 -¬†pobre\n",
    "# 3¬†-¬†pobre\n",
    "\n",
    "\n",
    "# gerando permuta√ß√µes 4    \n",
    "lista = ['n√£o pobre', 'pobre']\n",
    "permutas_4 = []\n",
    "\n",
    "for i in product(lista, repeat=3):\n",
    "    permutas_4.append(i)\n",
    "print(permutas_4)\n",
    "    \n",
    "# ('n√£o pobre', 'n√£o pobre', 'n√£o pobre') = n√£o pobre\n",
    "# ('n√£o pobre', 'n√£o pobre', 'pobre') = n√£o pobre\n",
    "# ('n√£o pobre', 'pobre', 'n√£o pobre') = n√£o pobre\n",
    "# ('n√£o pobre', 'pobre', 'pobre') = pobre\n",
    "# ('pobre', 'n√£o pobre', 'n√£o pobre') = n√£o pobre\n",
    "# ('pobre', 'n√£o pobre', 'pobre') = pobre\n",
    "# ('pobre', 'pobre', 'n√£o pobre') = pobre\n",
    "# ('pobre', 'pobre', 'pobre') = pobre\n",
    "\n",
    "def get_serv_essenciais_principal(z,w,p):\n",
    "    if z == 0  and w == 0 and p==0:\n",
    "        return 0\n",
    "    elif z == 0  and w == 0 and p==1:\n",
    "        return 0\n",
    "    elif z == 0  and w == 1 and p==0:\n",
    "        return 0\n",
    "    elif z == 1  and w == 0 and p==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1       \n",
    "base['serv_essenciais'] = base.apply(lambda row: get_serv_essenciais_principal(row['var_depend4.1_inicial'], row['var_depend4.2_inicial'],row['var_depend4.3_inicial'] ), axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # verificacao NAs nas variaveis que participam do processo de criacao das variaveis dependentes 1,2,3,4\n",
    "var = ['rdpc','seg_alimentar','var_depend3.1_inicial','var_depend3.2_inicial','subjetividade','var_depend4.1_inicial','var_depend4.2_inicial','serv_essenciais' ]\n",
    "for i in var:\n",
    "    j = base[i].unique()\n",
    "    print(f'{i}:', j)\n",
    "    \n",
    "    \n",
    "# # deletando linhas que possuem 'nan' na variavel dependente\n",
    "# # linhas antes da remo√ß√£o = 693760\n",
    "# # linhas depois da remo√ß√£o = 682767\n",
    "# base = base.dropna(subset = ['serv_essenciais'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid das 4 variaveis\n",
    "# plano\n",
    "fig, eixos = mplt.subplots (2, 2, figsize=(10,10) )\n",
    "\n",
    "# grafico1 = sn.countplot(MORADOR, x = 'var_depend1')\n",
    "sn.countplot(base, x='rdpc', ax=eixos[0,0])\n",
    "eixos[0,0].set_title('RENDA_MONET_PC')\n",
    "eixos[0,0].set_xlabel('')\n",
    "eixos[0,0].set_ylabel('')\n",
    "\n",
    "# grafico2 = sn.countplot(DOMICILIO, x = 'var_depend2')\n",
    "sn.countplot(base, x = 'seg_alimentar', ax=eixos[0,1])\n",
    "eixos[0,1].set_title('V6199')\n",
    "eixos[0,1].set_xlabel('')\n",
    "eixos[0,1].set_ylabel('')\n",
    "\n",
    "# grafico3 = sn.countplot(CONDICOES_VIDA, x = 'var_depend3')\n",
    "sn.countplot(base, x = 'subjetividade', ax= eixos[1,0])\n",
    "eixos[1,0].set_title('V6101 e V61041')\n",
    "eixos[1,0].set_xlabel('')\n",
    "eixos[1,0].set_ylabel('')\n",
    "\n",
    "# grafico4 = sn.countplot(DOMICILIO, x = 'var_depend4')\n",
    "sn.countplot(base, x = 'serv_essenciais', ax= eixos[1,1])\n",
    "eixos[1,1].set_title('V0212, V0213 e V0220')\n",
    "eixos[1,1].set_xlabel('')\n",
    "eixos[1,1].set_ylabel('')\n",
    "\n",
    "mplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria√ß√£o das dummies\n",
    "# C4 - N√≠vel de Instru√ß√£o da pessoa (perfil do chefe)\n",
    "    # 1 ‚Äì Sem instru√ß√£o\n",
    "    # 2 ‚Äì Ensino Fundamental Incompleto\n",
    "    # 3 ‚Äì Ensino Fundamental Completo \n",
    "    # 4 ‚Äì Ensino M√©dio Incompleto\n",
    "    # 5 ‚Äì Ensino M√©dio Completo \n",
    "    # 6 ‚Äì Ensino Superior Incompleto\n",
    "    # 7 ‚Äì Ensino Superior Completo - dummy\n",
    "\n",
    "# C3 - Sexo (PERFIL DO CHEFE)\n",
    "    # 1- Masculino - dummy\n",
    "    # 2- Feminino\n",
    "\n",
    "# C2 - Cor ou ra√ßa (PERFI DO CHEFE)\n",
    "    # 1 ‚Äì Brancos - dummy\n",
    "    # 2 ‚Äì Pretos e Pardos\n",
    "    # 3 ‚Äì Outros\n",
    "\n",
    "# C1 - IDADE - PERFIL DO CHEFE\n",
    "    # 1 ‚Äì At√© 24 anos\n",
    "    # 2 ‚Äì 25 a 49 anos\n",
    "    # 3 ‚Äì 50 a 64 anos - dummy \n",
    "    # 4 ‚Äì 65 anos ou mais - dummy\n",
    "\n",
    "# GRANDE_REGIAO - REGI√ÉO (DUMY) - refer√™ncia √© o sudeste\n",
    "    # 1- Norte\n",
    "    # 2- Nordeste\n",
    "    # 3- Sudeste - dummy\n",
    "    # 4- Sul\n",
    "    # 5- Centro-Oeste\n",
    "    \n",
    "# TIPO_SITUACAO_REG¬†urbano (1)¬†x¬†rural (2)\n",
    "    # 1 - Urbano - dummy\n",
    "    # 2 - Rural\n",
    "\n",
    "\n",
    "# VARI√ÅVEIS DEPENDENTES\n",
    "# rdpc\n",
    "# seg_alimentar\n",
    "# subjetividade\n",
    "# serv_essenciais\n",
    "\n",
    "# base = base[['rdpc','seg_alimentar','subjetividade','serv_essenciais', 'TIPO_SITUACAO_REG','GRANDE_REGIAO', 'C1', 'C2', 'C3', 'C4']]\n",
    "\n",
    "# # criacao de dummies\n",
    "base = pd.get_dummies(base, columns=['TIPO_SITUACAO_REG', 'GRANDE_REGIAO','C1', 'C2', 'C3', 'C4'])\n",
    "\n",
    "# # considerando apenas as dummies de referencia\n",
    "base = base[['rdpc','seg_alimentar','subjetividade','serv_essenciais', 'C4_7', 'C3_1','C2_1', 'C1_3', 'C1_4', 'GRANDE_REGIAO_3', 'TIPO_SITUACAO_REG_1']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estatistica descritiva de 'base_final'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grafico renda media por estado\n",
    "media_renda_uf = base.groupby('UF')['RENDA_MONET_PC'].mean().sort_values()\n",
    "tabela = pd.DataFrame(media_renda_uf).reset_index()\n",
    "\n",
    "tabela['UF'] = tabela['UF'].map({11 : 'RO',\n",
    "                               12 : 'AC',\n",
    "                                13 : 'AM',\n",
    "                                14 : 'RR',\n",
    "                                15 : 'PR',\n",
    "                                16 : 'AM',\n",
    "                                17 : 'TO',\n",
    "                                21 : 'MA',\n",
    "                                22 : 'PI',\n",
    "                                23 : 'CE',\n",
    "                                24 : 'RN',\n",
    "                                25 : 'PB',\n",
    "                                26 : 'PE',\n",
    "                                27 : 'AL',\n",
    "                                28 : 'SE',\n",
    "                                29 : 'BA',\n",
    "                                31 : 'MG',\n",
    "                                32 : 'ES',\n",
    "                                33 : 'RJ',\n",
    "                                35 : 'SP',\n",
    "                                41 : 'PR',\n",
    "                                42 : 'SC',\n",
    "                                43 : 'RS',\n",
    "                                50 : 'MS',\n",
    "                                51 : 'MT',\n",
    "                                52 : 'GO',\n",
    "                                53 : 'DF'}) \n",
    "\n",
    "fig, ax = mplt.subplots(figsize = (10,10))\n",
    "sn.barplot(y='RENDA_MONET_PC', x='UF', data = tabela, ax=ax, palette='dark')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlacao de pearson entre variaveis dependentes e RENDA_MONET_PC\n",
    "\n",
    "# rdpc e RENDA_MONET_PC\n",
    "# Removendo valores infinitos e ausentes\n",
    "valid_indexes1 = np.isfinite(base['rdpc']) & np.isfinite(base['RENDA_MONET_PC'])\n",
    "filtered_rdpc = base['rdpc'][valid_indexes1]\n",
    "filtered_renda1 = base['RENDA_MONET_PC'][valid_indexes1]\n",
    "\n",
    "# C√°lculo da correla√ß√£o de Pearson\n",
    "correlacao1, p_valor1 = stats.pearsonr(filtered_rdpc, filtered_renda1)\n",
    "print('rdpc: ',correlacao1)\n",
    "\n",
    "\n",
    "# seg_alimentar e RENDA_MONET_PC\n",
    "# Removendo valores infinitos e ausentes\n",
    "valid_indexes2 = np.isfinite(base['seg_alimentar']) & np.isfinite(base['RENDA_MONET_PC'])\n",
    "filtered_seg_alimentar = base['seg_alimentar'][valid_indexes2]\n",
    "filtered_renda2 = base['RENDA_MONET_PC'][valid_indexes2]\n",
    "\n",
    "# C√°lculo da correla√ß√£o de Pearson\n",
    "correlacao2, p_valor2 = stats.pearsonr(filtered_seg_alimentar, filtered_renda2)\n",
    "print('seg_alimentar: ',correlacao2)\n",
    "\n",
    "\n",
    "# subjetividade e RENDA_MONET_PC\n",
    "# Removendo valores infinitos e ausentes\n",
    "valid_indexes3 = np.isfinite(base['subjetividade']) & np.isfinite(base['RENDA_MONET_PC'])\n",
    "filtered_subjetividade = base['subjetividade'][valid_indexes3]\n",
    "filtered_renda3 = base['RENDA_MONET_PC'][valid_indexes3]\n",
    "\n",
    "# C√°lculo da correla√ß√£o de Pearson\n",
    "correlacao3, p_valor3 = stats.pearsonr(filtered_subjetividade, filtered_renda3)\n",
    "print('subjetividade: ',correlacao3)\n",
    "\n",
    "\n",
    "# serv_essenciais e RENDA_MONET_PC\n",
    "# Removendo valores infinitos e serv_essenciais\n",
    "valid_indexes4 = np.isfinite(base['serv_essenciais']) & np.isfinite(base['RENDA_MONET_PC'])\n",
    "filtered_serv_essenciais = base['serv_essenciais'][valid_indexes4]\n",
    "filtered_renda4 = base['RENDA_MONET_PC'][valid_indexes4]\n",
    "\n",
    "# C√°lculo da correla√ß√£o de Pearson\n",
    "correlacao4, p_valor4 = stats.pearsonr(filtered_serv_essenciais, filtered_renda4)\n",
    "print('serv_essenciais: ',correlacao4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   rdpc   R-squared:                       0.091\n",
      "Model:                            OLS   Adj. R-squared:                  0.091\n",
      "Method:                 Least Squares   F-statistic:                     9968.\n",
      "Date:                Sun, 19 Nov 2023   Prob (F-statistic):               0.00\n",
      "Time:                        11:12:12   Log-Likelihood:            -2.9582e+05\n",
      "No. Observations:              693760   AIC:                         5.917e+05\n",
      "Df Residuals:                  693752   BIC:                         5.917e+05\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                   0.4236      0.001    352.120      0.000       0.421       0.426\n",
      "C4_7                   -0.1506      0.002    -98.350      0.000      -0.154      -0.148\n",
      "C3_1                   -0.0572      0.001    -62.119      0.000      -0.059      -0.055\n",
      "C2_1                   -0.0860      0.001    -88.989      0.000      -0.088      -0.084\n",
      "C1_3                   -0.0774      0.001    -75.511      0.000      -0.079      -0.075\n",
      "C1_4                   -0.1627      0.001   -120.989      0.000      -0.165      -0.160\n",
      "GRANDE_REGIAO_3        -0.0766      0.001    -71.328      0.000      -0.079      -0.074\n",
      "TIPO_SITUACAO_REG_1    -0.1328      0.001   -124.722      0.000      -0.135      -0.131\n",
      "==============================================================================\n",
      "Omnibus:                   132213.746   Durbin-Watson:                   0.101\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           223638.138\n",
      "Skew:                           1.376   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.399   Cond. No.                         5.46\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "(0.47545220226821655, 0.9999999999999999, 'increasing')\n",
      "                          vif\n",
      "C4_7                 1.038999\n",
      "C3_1                 1.032612\n",
      "C2_1                 1.032198\n",
      "C1_3                 1.067598\n",
      "C1_4                 1.071462\n",
      "GRANDE_REGIAO_3      1.020282\n",
      "TIPO_SITUACAO_REG_1  1.050207\n"
     ]
    }
   ],
   "source": [
    "# MQO - rdpc\n",
    "# https://nathaliatito.medium.com/scikit-learn-ou-statsmodels-avaliando-meu-modelo-de-regress√£o-f4c04b361fa7\n",
    "# variaveis x (ser√£o iguais para todos os modelos)\n",
    "var_x = base[['C4_7', 'C3_1','C2_1', 'C1_3', 'C1_4', 'GRANDE_REGIAO_3', 'TIPO_SITUACAO_REG_1']]\n",
    "\n",
    "# rdpc\n",
    "var_y = base[['rdpc']]\n",
    "var_x = sm.add_constant(var_x)\n",
    "modelo = sm.OLS(var_y, var_x ).fit()\n",
    "print(modelo.summary())# Teste t de signific√¢ncia individual = H0 indica irrelev√¢ncia da variavel, portanto :. p_valor < 0.05 aceita H1 e mant√©m a variavel\n",
    "\n",
    "\n",
    "# teste homocedasticidade\n",
    "teste_homo_rdpc = sms.het_goldfeldquandt(modelo.resid, modelo.model.exog)  # exog indica variaveis ex√≥genas, ou seja, faz uma matriz das variaveis independentes do modelo\n",
    "print(teste_homo_rdpc)\n",
    "\n",
    "# vif - rdpc\n",
    "# teste de multicolinearidade, usando VIF (Variance Inflation Factor)\n",
    "# caso o valor seja maior que 10, indica multicolinearidade, √© preciso excluir essas vari√°veis\n",
    "vif= [ variance_inflation_factor(var_x.values, i ) for i in range(var_x.shape[1])]\n",
    "tabela_vif = pd.DataFrame({'vif':vif[1:]}, index = var_x.columns.drop('const'))\n",
    "print(tabela_vif)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          seg_alimentar   R-squared:                       0.085\n",
      "Model:                            OLS   Adj. R-squared:                  0.085\n",
      "Method:                 Least Squares   F-statistic:                     9215.\n",
      "Date:                Sun, 19 Nov 2023   Prob (F-statistic):               0.00\n",
      "Time:                        11:12:24   Log-Likelihood:            -4.7264e+05\n",
      "No. Observations:              693760   AIC:                         9.453e+05\n",
      "Df Residuals:                  693752   BIC:                         9.454e+05\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                   0.7233      0.002    465.967      0.000       0.720       0.726\n",
      "C4_7                   -0.2513      0.002   -127.158      0.000      -0.255      -0.247\n",
      "C3_1                   -0.1022      0.001    -86.056      0.000      -0.104      -0.100\n",
      "C2_1                   -0.1700      0.001   -136.300      0.000      -0.172      -0.168\n",
      "C1_3                   -0.0501      0.001    -37.873      0.000      -0.053      -0.047\n",
      "C1_4                   -0.1036      0.002    -59.699      0.000      -0.107      -0.100\n",
      "GRANDE_REGIAO_3        -0.1013      0.001    -73.152      0.000      -0.104      -0.099\n",
      "TIPO_SITUACAO_REG_1    -0.0504      0.001    -36.660      0.000      -0.053      -0.048\n",
      "==============================================================================\n",
      "Omnibus:                  3030875.158   Durbin-Watson:                   0.140\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            82096.506\n",
      "Skew:                          -0.020   Prob(JB):                         0.00\n",
      "Kurtosis:                       1.315   Cond. No.                         5.46\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "(0.9690787630740043, 0.9999999999999999, 'increasing')\n",
      "                          vif\n",
      "C4_7                 1.038999\n",
      "C3_1                 1.032612\n",
      "C2_1                 1.032198\n",
      "C1_3                 1.067598\n",
      "C1_4                 1.071462\n",
      "GRANDE_REGIAO_3      1.020282\n",
      "TIPO_SITUACAO_REG_1  1.050207\n"
     ]
    }
   ],
   "source": [
    "# MQO - seg_alimentar\n",
    "var_y = base[['seg_alimentar']]\n",
    "var_x = sm.add_constant(var_x)\n",
    "modelo = sm.OLS(var_y, var_x ).fit()\n",
    "print(modelo.summary()) # Teste t de signific√¢ncia individual = H0 indica irrelev√¢ncia da variavel, portanto :. p_valor < 0.05 aceita H1 e mant√©m a variavel\n",
    "\n",
    "\n",
    "# teste homocedasticidade\n",
    "teste_homo_seg_alimentar = sms.het_goldfeldquandt(modelo.resid, modelo.model.exog)  # exog indica variaveis ex√≥genas, ou seja, faz uma matriz das variaveis independentes do modelo\n",
    "print(teste_homo_seg_alimentar)\n",
    "\n",
    "# vif - rdpc\n",
    "# teste de multicolinearidade, usando VIF (Variance Inflation Factor)\n",
    "# caso o valor seja maior que 10, indica multicolinearidade, √© preciso excluir essas vari√°veis\n",
    "vif= [ variance_inflation_factor(var_x.values, i ) for i in range(var_x.shape[1])]\n",
    "tabela_vif = pd.DataFrame({'vif':vif[1:]}, index = var_x.columns.drop('const'))\n",
    "print(tabela_vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          subjetividade   R-squared:                       0.039\n",
      "Model:                            OLS   Adj. R-squared:                  0.039\n",
      "Method:                 Least Squares   F-statistic:                     4046.\n",
      "Date:                Sun, 19 Nov 2023   Prob (F-statistic):               0.00\n",
      "Time:                        11:12:33   Log-Likelihood:            -4.7762e+05\n",
      "No. Observations:              693760   AIC:                         9.553e+05\n",
      "Df Residuals:                  693752   BIC:                         9.554e+05\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                   0.5246      0.002    335.521      0.000       0.522       0.528\n",
      "C4_7                   -0.1984      0.002    -99.702      0.000      -0.202      -0.195\n",
      "C3_1                   -0.0916      0.001    -76.630      0.000      -0.094      -0.089\n",
      "C2_1                   -0.1042      0.001    -82.987      0.000      -0.107      -0.102\n",
      "C1_3                    0.0264      0.001     19.818      0.000       0.024       0.029\n",
      "C1_4                   -0.0005      0.002     -0.310      0.756      -0.004       0.003\n",
      "GRANDE_REGIAO_3        -0.0482      0.001    -34.518      0.000      -0.051      -0.045\n",
      "TIPO_SITUACAO_REG_1    -0.0079      0.001     -5.728      0.000      -0.011      -0.005\n",
      "==============================================================================\n",
      "Omnibus:                  2881405.766   Durbin-Watson:                   0.151\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           100452.291\n",
      "Skew:                           0.339   Prob(JB):                         0.00\n",
      "Kurtosis:                       1.264   Cond. No.                         5.46\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "(0.8849449181393987, 0.9999999999999999, 'increasing')\n",
      "                          vif\n",
      "C4_7                 1.038999\n",
      "C3_1                 1.032612\n",
      "C2_1                 1.032198\n",
      "C1_3                 1.067598\n",
      "C1_4                 1.071462\n",
      "GRANDE_REGIAO_3      1.020282\n",
      "TIPO_SITUACAO_REG_1  1.050207\n"
     ]
    }
   ],
   "source": [
    "# MQO - subjetividade\n",
    "var_y = base[['subjetividade']]\n",
    "var_x = sm.add_constant(var_x)\n",
    "modelo = sm.OLS(var_y, var_x ).fit()\n",
    "print(modelo.summary()) # Teste t de signific√¢ncia individual = H0 indica irrelev√¢ncia da variavel, portanto :. p_valor < 0.05 aceita H1 e mant√©m a variavel\n",
    "\n",
    "\n",
    "# teste homocedasticidade\n",
    "teste_homo_subjetividade = sms.het_goldfeldquandt(modelo.resid, modelo.model.exog)  # exog indica variaveis ex√≥genas, ou seja, faz uma matriz das variaveis independentes do modelo\n",
    "print(teste_homo_subjetividade)\n",
    "\n",
    "# vif - rdpc\n",
    "# teste de multicolinearidade, usando VIF (Variance Inflation Factor)\n",
    "# caso o valor seja maior que 10, indica multicolinearidade, √© preciso excluir essas vari√°veis\n",
    "vif= [ variance_inflation_factor(var_x.values, i ) for i in range(var_x.shape[1])]\n",
    "tabela_vif = pd.DataFrame({'vif':vif[1:]}, index = var_x.columns.drop('const'))\n",
    "print(tabela_vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:        serv_essenciais   R-squared:                       0.482\n",
      "Model:                            OLS   Adj. R-squared:                  0.482\n",
      "Method:                 Least Squares   F-statistic:                 9.240e+04\n",
      "Date:                Sun, 19 Nov 2023   Prob (F-statistic):               0.00\n",
      "Time:                        11:12:43   Log-Likelihood:            -2.2846e+05\n",
      "No. Observations:              693760   AIC:                         4.569e+05\n",
      "Df Residuals:                  693752   BIC:                         4.570e+05\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                   0.9249      0.001    847.228      0.000       0.923       0.927\n",
      "C4_7                   -0.1061      0.001    -76.323      0.000      -0.109      -0.103\n",
      "C3_1                    0.0083      0.001      9.939      0.000       0.007       0.010\n",
      "C2_1                   -0.0391      0.001    -44.580      0.000      -0.041      -0.037\n",
      "C1_3                   -0.0224      0.001    -24.031      0.000      -0.024      -0.021\n",
      "C1_4                   -0.0442      0.001    -36.262      0.000      -0.047      -0.042\n",
      "GRANDE_REGIAO_3        -0.1191      0.001   -122.240      0.000      -0.121      -0.117\n",
      "TIPO_SITUACAO_REG_1    -0.7190      0.001   -744.229      0.000      -0.721      -0.717\n",
      "==============================================================================\n",
      "Omnibus:                   126195.188   Durbin-Watson:                   0.081\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           275514.105\n",
      "Skew:                           1.064   Prob(JB):                         0.00\n",
      "Kurtosis:                       5.237   Cond. No.                         5.46\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "(0.8849449181393987, 0.9999999999999999, 'increasing')\n",
      "                          vif\n",
      "C4_7                 1.038999\n",
      "C3_1                 1.032612\n",
      "C2_1                 1.032198\n",
      "C1_3                 1.067598\n",
      "C1_4                 1.071462\n",
      "GRANDE_REGIAO_3      1.020282\n",
      "TIPO_SITUACAO_REG_1  1.050207\n"
     ]
    }
   ],
   "source": [
    "# MQO - serv_essenciais\n",
    "var_y = base[['serv_essenciais']]\n",
    "var_x = sm.add_constant(var_x)\n",
    "modelo = sm.OLS(var_y, var_x ).fit()\n",
    "print(modelo.summary()) # Teste t de signific√¢ncia individual = H0 indica irrelev√¢ncia da variavel, portanto :. p_valor < 0.05 aceita H1 e mant√©m a variavel\n",
    "\n",
    "\n",
    "# teste homocedasticidade\n",
    "teste_homo_serv_essenciais = sms.het_goldfeldquandt(modelo.resid, modelo.model.exog)  # exog indica variaveis ex√≥genas, ou seja, faz uma matriz das variaveis independentes do modelo\n",
    "print(teste_homo_subjetividade)\n",
    "\n",
    "# vif - rdpc\n",
    "# teste de multicolinearidade, usando VIF (Variance Inflation Factor)\n",
    "# caso o valor seja maior que 10, indica multicolinearidade, √© preciso excluir essas vari√°veis\n",
    "vif= [ variance_inflation_factor(var_x.values, i ) for i in range(var_x.shape[1])]\n",
    "tabela_vif = pd.DataFrame({'vif':vif[1:]}, index = var_x.columns.drop('const'))\n",
    "print(tabela_vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # transferir para excel caso nao exceda o numero de linhas\n",
    "# # limite de linhas excel = 1.048.576 linhas e 16.384 colunas\n",
    "# # ex: CARACTERISTICAS_DIETA.to_excel('caracteristicas_dieta.xlsx', index=False)\n",
    "# # os itens de 'tabelas' e 'nome_tabelas' precisam estar alinhados\n",
    "\n",
    "# # x\n",
    "# tabelas = [ CARACTERISTICAS_DIETA,\n",
    "#             CONDICOES_VIDA,\n",
    "#             CONSUMO_ALIMENTAR,\n",
    "#             DOMICILIO,\n",
    "#             MORADOR,\n",
    "#             MORADOR_QUALI_VIDA ]\n",
    "\n",
    "# # i \n",
    "# nomes_tabelas = [   'CARACTERISTICAS_DIETA',\n",
    "#                     'CONDICOES_VIDA',\n",
    "#                     'CONSUMO_ALIMENTAR',\n",
    "#                     'DOMICILIO',\n",
    "#                     'MORADOR',\n",
    "#                     'MORADOR_QUALI_VIDA' ]\n",
    "\n",
    "\n",
    "# # zip serve para fazer o loop ao mesmo tempo nas minhas duas listas\n",
    "# for x, i in zip(tabelas, nomes_tabelas):\n",
    "    \n",
    "#     if len(x) < 1048576:\n",
    "#         print(f'{len(x)} , baixar: {i}')\n",
    "        \n",
    "#         dados = pd.DataFrame(x)\n",
    "#         nome_arquivo = i +'.xlsx'\n",
    "#         dados.to_excel(nome_arquivo, index=False)\n",
    "        \n",
    "#         print(f'arquivo {i} baixado com sucesso')\n",
    "                    \n",
    "#     else:\n",
    "#         print(f'{len(x)} , nao baixar: {i}')\n",
    "        \n",
    "       \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variaveis de cada tabela\n",
    "# for x , i in zip(tabelas, nomes_tabelas):\n",
    "#     dados_desc = pd.DataFrame(x).describe()\n",
    "#     arquivo = pd.ExcelWriter('arquivo_estatisticas_descritivas.xlsx', engine = 'xlsxwriter')\n",
    "#     dados_desc.to_excel(arquivo, sheet_name='{}'.format(i), index=True)\n",
    "#     arquivo.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arquivos de dicionarios das variaveis\n",
    "# diretorio_dic = r'C:\\Users\\Computadores Gamer\\OneDrive\\√Årea de Trabalho\\dados gradilene\\dados'\n",
    "# diretorio_dic = diretorio_dic.replace('\\\\', '/')\n",
    "# os.chdir(diretorio_dic)\n",
    "\n",
    "# os.listdir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sheets do arquivo dicionario\n",
    "# from openpyxl import load_workbook\n",
    "# dicionario = load_workbook('dicvar1718.xlsx')\n",
    "# sheets = dicionario.sheetnames\n",
    "# print(sheets) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lendo sheet 'Morador' e mantendo apenas as variaveis 'V....'\n",
    "# necessario generalizar esse codigo para cada sheet do arquivo\n",
    "\n",
    "\n",
    "# morador = pd.read_excel('dicvar1718.xlsx', sheet_name='Morador')\n",
    "\n",
    "# # cabecalho \n",
    "# morador.columns = morador.iloc[2,]\n",
    "\n",
    "# # preenchendo elementos NAs da coluna 'C√≥digo da vari√°vel', senao a fun√ß√£o 'startswith' nao funciona\n",
    "# morador['C√≥digo da vari√°vel'].fillna('',inplace=True)\n",
    "\n",
    "# # filtrar apenas linhas em que em 'C√≥digo da vari√°vel' o elemento come√ßa com 'V'\n",
    "# # lembrar que 'startswith' s√≥ funciona com o '.str'\n",
    "# morador = morador[morador['C√≥digo da vari√°vel'].str.startswith('V')]        # filtrando apenas as linhas de codigos 'V....'\n",
    "# print(morador)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generalizando codigo de ler cada sheet e filtrar apenas os codigos das variaveis\n",
    "# lista_tabelas_codigos = []\n",
    "\n",
    "# for i in sheets:\n",
    "#     caderno = pd.read_excel('dicvar1718.xlsx', sheet_name=i)\n",
    "#     caderno.columns = caderno.iloc[2,]\n",
    "#     caderno['C√≥digo da vari√°vel'].fillna('', inplace=True)\n",
    "#     caderno = caderno[caderno['C√≥digo da vari√°vel'].str.startswith('V')]\n",
    "#     lista_tabelas_codigos.append(caderno)\n",
    "\n",
    "\n",
    "# codigos_site = pd.concat(lista_tabelas_codigos, axis=0)\n",
    "# codigos_site = codigos_site[['C√≥digo da vari√°vel', 'Descri√ß√£o']]\n",
    "# print(codigos_site)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vendo quantas variaveis de codigo tem em cada caderno para depois fazer o merge com a tabela 'codigos'\n",
    "# lista_cadernos = [CONSUMO_ALIMENTAR, CARACTERISTICAS_DIETA, DOMICILIO, CONDICOES_VIDA, MORADOR_QUALI_VIDA , MORADOR]\n",
    "\n",
    "# # colunas = CONSUMO_ALIMENTAR.columns.str.startswith('V')\n",
    "# # CONSUMO_ALIMENTAR.columns[np.where(colunas==True)]\n",
    "\n",
    "# codigos_total = []\n",
    "# for i in lista_cadernos:\n",
    "#     colunas = i.columns.str.startswith('V')\n",
    "#     nome = i.columns[np.where(np.logical_and(colunas, i.columns.str.match('.*[0-9]$')))] # logical_and √© pra unir as condicoes. '.*[0-9]$' √© uma expressao regular\n",
    "#     print(len(nome.unique()),nome)\n",
    "#     codigos_total.extend(nome) # coloca na lista, parecido com append, porem append √© para adicionar um unico elemento no final da lista, o extend ja adiciona tudo de uma vez\n",
    "    \n",
    "    \n",
    "# codigos_cadernos = pd.DataFrame({'codigo':codigos_total})\n",
    "# codigos_cadernos.columns = ['C√≥digo da vari√°vel']\n",
    "# # codigos_cadernos.to_excel('codigos_cadernos.xlsx', index=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fazendo merge dos codigos que achei com os 207 codigos que sao o total de codigos de todos cadernos\n",
    "# codigos_final = pd.merge(codigos_site, codigos_cadernos, on='C√≥digo da vari√°vel', how = 'outer')\n",
    "# codigos_final = codigos_final[['C√≥digo da vari√°vel','Descri√ß√£o']]\n",
    "# print(codigos_final)\n",
    "\n",
    "# codigos_final.to_excel('codigos_final.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
