{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pacotes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "import seaborn as sn\n",
    "from itertools import permutations, product\n",
    "import matplotlib.pyplot as mplt\n",
    "import scipy.stats as stats\n",
    "from tabulate import tabulate\n",
    "from scipy.stats import chi2_contingency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Computadores Gamer\\\\OneDrive\\\\Área de Trabalho\\\\dados gradilene\\\\dados'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setar diretorio dos cadernos (codigo caso puxe os arquivos com todas as colunas originais do ibge)\n",
    "diretorio = r'C:\\Users\\Computadores Gamer\\OneDrive\\Área de Trabalho\\dados gradilene\\dados'\n",
    "diretorio = diretorio.replace('\\\\', '/')\n",
    "\n",
    "os.chdir(diretorio)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UF  ESTRATO_POF  TIPO_SITUACAO_REG    COD_UPA  NUM_DOM  V0201  V0202  \\\n",
      "0  11         1103                  1  110005400        1      1      1   \n",
      "1  11         1103                  1  110005400        2      1      1   \n",
      "2  11         1103                  1  110005400        4      1      4   \n",
      "3  11         1103                  1  110005400        5      1      4   \n",
      "4  11         1103                  1  110005400        6      1      1   \n",
      "\n",
      "   V0203  V0204  V0205  ...  V02162  V02163  V02164  V0217  V0219  V0220  \\\n",
      "0      1      1     10  ...       2       1       2      1    NaN      1   \n",
      "1      1      1      5  ...       2       1       2      3    1.0      1   \n",
      "2      1      1      5  ...       2       2       2      1    NaN      1   \n",
      "3      1      1      7  ...       2       2       2      1    NaN      2   \n",
      "4      1      1      6  ...       2       2       2      1    NaN      1   \n",
      "\n",
      "   V0221        PESO  PESO_FINAL  V6199  \n",
      "0      1  272.806669  372.984516      1  \n",
      "1      1  272.806669  372.984516      1  \n",
      "2      1  272.806669  372.984516      1  \n",
      "3      1  272.806669  372.984516      1  \n",
      "4      1  272.806669  372.984516      1  \n",
      "\n",
      "[5 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "#### DOMICILIO\n",
    "# largura do txt\n",
    "larguras = [2,4,1,9,2,1,1,1,1,2,1,1,1,1,1,1,1,1,1,2,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,14,14,1]\n",
    "\n",
    "# nome das colunas\n",
    "colunas = [\"UF\", \"ESTRATO_POF\", \"TIPO_SITUACAO_REG\",\n",
    "            \"COD_UPA\", \"NUM_DOM\", \"V0201\", \"V0202\",\n",
    "            \"V0203\", \"V0204\", \"V0205\", \"V0206\", \"V0207\",\n",
    "            \"V0208\", \"V0209\", \"V02101\", \"V02102\",\n",
    "            \"V02103\", \"V02104\", \"V02105\", \"V02111\",\n",
    "            \"V02112\", \"V02113\", \"V0212\", \"V0213\",\n",
    "            \"V02141\", \"V02142\", \"V0215\", \"V02161\",\n",
    "            \"V02162\", \"V02163\", \"V02164\", \"V0217\",\n",
    "            \"V0219\", \"V0220\", \"V0221\", \"PESO\",\n",
    "            \"PESO_FINAL\", \"V6199\"]\n",
    "\n",
    "# leitura dos dados\n",
    "DOMICILIO = pd.read_fwf(\n",
    "    os.path.join(diretorio, \"DOMICILIO.txt\"),\n",
    "    widths=larguras,\n",
    "    na_values=[\" \"],\n",
    "    names=colunas,\n",
    "    decimal=\".\"\n",
    ")\n",
    "\n",
    "print(DOMICILIO.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UF  ESTRATO_POF  TIPO_SITUACAO_REG    COD_UPA  NUM_DOM  NUM_UC  \\\n",
      "0  11         1103                  1  110005400        1       1   \n",
      "1  11         1103                  1  110005400        2       1   \n",
      "2  11         1103                  1  110005400        4       1   \n",
      "3  11         1103                  1  110005400        5       1   \n",
      "4  11         1103                  1  110005400        6       1   \n",
      "\n",
      "   COD_INFORMANTE  V6101  V6102  V6103  ...  V6115  V6116  V6117  V6118  \\\n",
      "0               1      5   4000   1500  ...    NaN    NaN    NaN    NaN   \n",
      "1               1      3   3500   1000  ...    NaN    NaN    NaN    NaN   \n",
      "2               1      5   5000   1200  ...    NaN    NaN    NaN    NaN   \n",
      "3               1      3   1800    800  ...    NaN    NaN    NaN    NaN   \n",
      "4               1      5   6000   1500  ...    NaN    NaN    NaN    NaN   \n",
      "\n",
      "   V6119  V6120  V6121        PESO  PESO_FINAL  RENDA_TOTAL  \n",
      "0    NaN    NaN    NaN  272.806669  372.984516     11254.75  \n",
      "1    NaN    NaN    NaN  272.806669  372.984516     10828.07  \n",
      "2    NaN    NaN    NaN  272.806669  372.984516      4769.13  \n",
      "3    NaN    NaN    NaN  272.806669  372.984516      2313.61  \n",
      "4    NaN    NaN    NaN  272.806669  372.984516      6596.90  \n",
      "\n",
      "[5 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "##### CONDICOES_VIDA\n",
    "# largura do txt\n",
    "larguras = [2,4,1,9,2,1,2,1,6,5,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,14,14,10]\n",
    "\n",
    "# nome das colunas\n",
    "colunas = [\"UF\", \"ESTRATO_POF\", \"TIPO_SITUACAO_REG\",\n",
    "            \"COD_UPA\", \"NUM_DOM\", \"NUM_UC\", \"COD_INFORMANTE\",\n",
    "            \"V6101\", \"V6102\", \"V6103\", \"V61041\", \"V61042\",\n",
    "            \"V61043\", \"V61044\", \"V61045\", \"V61046\",\n",
    "            \"V61051\", \"V61052\", \"V61053\", \"V61054\",\n",
    "            \"V61055\", \"V61056\", \"V61057\", \"V61058\",\n",
    "            \"V61061\", \"V61062\", \"V61063\", \"V61064\",\n",
    "            \"V61065\", \"V61066\", \"V61067\", \"V61068\",\n",
    "            \"V61069\", \"V610610\", \"V610611\", \"V61071\",\n",
    "            \"V61072\", \"V61073\", \"V6108\", \"V6109\",\n",
    "            \"V6110\", \"V6111\", \"V6112\", \"V6113\", \"V6114\",\n",
    "            \"V6115\", \"V6116\", \"V6117\", \"V6118\", \"V6119\",\n",
    "            \"V6120\", \"V6121\", \"PESO\", \"PESO_FINAL\",\n",
    "            \"RENDA_TOTAL\"]\n",
    "\n",
    "# leitura dos dados\n",
    "CONDICOES_VIDA = pd.read_fwf(\n",
    "    os.path.join(diretorio, \"CONDICOES_VIDA.txt\"),\n",
    "    widths=larguras,\n",
    "    na_values=[\" \"],\n",
    "    names=colunas,\n",
    "    decimal=\".\"\n",
    ")\n",
    "\n",
    "print(CONDICOES_VIDA.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UF  ESTRATO_POF  TIPO_SITUACAO_REG    COD_UPA  NUM_DOM  NUM_UC  \\\n",
      "0  11         1103                  1  110005400        1       1   \n",
      "1  11         1103                  1  110005400        1       1   \n",
      "2  11         1103                  1  110005400        1       1   \n",
      "3  11         1103                  1  110005400        1       1   \n",
      "4  11         1103                  1  110005400        2       1   \n",
      "\n",
      "   COD_INFORMANTE  CONTAGEM_PONDERADA  FUNCAO_PERDA  V201  ...  C2  C3  C4  \\\n",
      "0               1            0.177778      0.113229     0  ...   1   2   7   \n",
      "1               2            0.177778      0.113229     0  ...   1   2   7   \n",
      "2               3            0.177778      0.113229     0  ...   1   2   7   \n",
      "3               4            0.177778      0.113229     0  ...   1   2   7   \n",
      "4               1            0.300000      0.203610     0  ...   1   2   5   \n",
      "\n",
      "   C5  C6  C7  RENDA_DISP_PC  RENDA_DISP_PC_SS        PESO  PESO_FINAL  \n",
      "0   5   3   9    2488.984375       2383.936458  272.806669  372.984516  \n",
      "1   5   3   9    2488.984375       2383.936458  272.806669  372.984516  \n",
      "2   5   3   9    2488.984375       2383.936458  272.806669  372.984516  \n",
      "3   5   3   9    2488.984375       2383.936458  272.806669  372.984516  \n",
      "4   4   4  10    3474.625556       3373.902222  272.806669  372.984516  \n",
      "\n",
      "[5 rows x 72 columns]\n"
     ]
    }
   ],
   "source": [
    "##### MORADOR_QUALI_VIDA\n",
    "# largura do txt\n",
    "larguras = [2,4,1,9,2,1,2,20,20,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,2,20,20,14,14]\n",
    "\n",
    "# nome das colunas\n",
    "colunas = [\"UF\",\"ESTRATO_POF\",\"TIPO_SITUACAO_REG\",\"COD_UPA\",\n",
    "            \"NUM_DOM\",\"NUM_UC\",\"COD_INFORMANTE\",\"CONTAGEM_PONDERADA\",\n",
    "            \"FUNCAO_PERDA\",\"V201\",\"V202\",\"V204\",\"V205\",\"V206\",\n",
    "            \"V207\",\"V208\",\"V209\",\"V210\",\"V211\",\"V212\",\"V214\",\"V215\",\n",
    "            \"V216\",\"V217\",\"V301\",\"V302\",\"V303\",\"V304\",\"V305\",\"V306\",\n",
    "            \"V307\",\"V308\",\"V401\",\"V402\",\"V403\",\"V501\",\"V502\",\"V503\",\n",
    "            \"V504\",\"V505\",\"V506\",\"V601\",\"V602\",\"V603\",\"V604\",\"V605\",\n",
    "            \"V606\",\"V607\",\"V608\",\"V609\",\"V610\",\"V611\",\"V701\",\"V702\",\n",
    "            \"V703\",\"V704\",\"V801\",\"V802\",\"V901\",\"V902\",\"GRANDE_REGIAO\",\n",
    "            \"C1\",\"C2\",\"C3\",\"C4\",\"C5\",\"C6\",\"C7\",\"RENDA_DISP_PC\",\n",
    "            \"RENDA_DISP_PC_SS\",\"PESO\",\"PESO_FINAL\"]\n",
    "\n",
    "# leitura dos dados\n",
    "MORADOR_QUALI_VIDA = pd.read_fwf(\n",
    "    os.path.join(diretorio, \"MORADOR_QUALI_VIDA.txt\"),\n",
    "    widths=larguras,\n",
    "    na_values=[\" \"],\n",
    "    names=colunas,\n",
    "    decimal=\".\"\n",
    ")\n",
    "\n",
    "print(MORADOR_QUALI_VIDA.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UF  ESTRATO_POF  TIPO_SITUACAO_REG    COD_UPA  NUM_DOM  NUM_UC  \\\n",
      "0  11         1101                  1  110000016        2       1   \n",
      "1  11         1101                  1  110000016        2       1   \n",
      "2  11         1101                  1  110000016        2       1   \n",
      "3  11         1101                  1  110000016        3       1   \n",
      "4  11         1101                  1  110000016        3       1   \n",
      "\n",
      "   COD_INFORMANTE  V0306  V0401  V04021  ...  V0430  ANOS_ESTUDO        PESO  \\\n",
      "0               1      1      1      15  ...    2.0            5  449.911506   \n",
      "1               2      2      1       1  ...    2.0            6  449.911506   \n",
      "2               3      6      1      16  ...    1.0           12  449.911506   \n",
      "3               1      1      1       4  ...    1.0           12  449.911506   \n",
      "4               2      2      1       7  ...    2.0            6  449.911506   \n",
      "\n",
      "   PESO_FINAL  RENDA_TOTAL  NIVEL_INSTRUCAO  RENDA_DISP_PC  RENDA_MONET_PC  \\\n",
      "0  690.883738      3855.34                2    1237.183056     1285.114167   \n",
      "1  690.883738      3855.34                2    1237.183056     1285.114167   \n",
      "2  690.883738      3855.34                5    1237.183056     1285.114167   \n",
      "3  690.883738      4242.48                5    1265.644167      826.780000   \n",
      "4  690.883738      4242.48                2    1265.644167      826.780000   \n",
      "\n",
      "   RENDA_NAO_MONET_PC  DEDUCAO_PC  \n",
      "0            0.000000   47.931111  \n",
      "1            0.000000   47.931111  \n",
      "2            0.000000   47.931111  \n",
      "3          446.340417    7.476250  \n",
      "4          446.340417    7.476250  \n",
      "\n",
      "[5 rows x 56 columns]\n"
     ]
    }
   ],
   "source": [
    "#### MORADOR\n",
    "# largura do txt\n",
    "larguras = [2,4,1,9,2,1,2,2,1,2,2,4,3,1,1,\n",
    "            1,1,1,2,1,2,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,2,1,1,2,1,1,2,1,1,1,\n",
    "            2,1,2,14,14,10,1,20,20,20,20]\n",
    "\n",
    "# nome das colunas\n",
    "colunas = [\"UF\", \"ESTRATO_POF\", \"TIPO_SITUACAO_REG\",\n",
    "            \"COD_UPA\", \"NUM_DOM\", \"NUM_UC\", \"COD_INFORMANTE\",\n",
    "            \"V0306\", \"V0401\", \"V04021\", \"V04022\", \"V04023\",\n",
    "            \"V0403\", \"V0404\", \"V0405\", \"V0406\", \"V0407\",\n",
    "            \"V0408\", \"V0409\", \"V0410\", \"V0411\", \"V0412\",\n",
    "            \"V0413\", \"V0414\", \"V0415\", \"V0416\",\n",
    "            \"V041711\", \"V041712\", \"V041721\", \"V041722\",\n",
    "            \"V041731\", \"V041732\", \"V041741\", \"V041742\",\n",
    "            \"V0418\", \"V0419\", \"V0420\", \"V0421\", \"V0422\",\n",
    "            \"V0423\", \"V0424\", \"V0425\", \"V0426\", \"V0427\",\n",
    "            \"V0428\", \"V0429\", \"V0430\", \"ANOS_ESTUDO\",\n",
    "            \"PESO\", \"PESO_FINAL\", \"RENDA_TOTAL\",\n",
    "            \"NIVEL_INSTRUCAO\", \"RENDA_DISP_PC\",\"RENDA_MONET_PC\",\n",
    "            \"RENDA_NAO_MONET_PC\",\"DEDUCAO_PC\" ]\n",
    "\n",
    "# leitura dos dados\n",
    "MORADOR = pd.read_fwf(\n",
    "    os.path.join(diretorio, \"MORADOR.txt\"),\n",
    "    widths=larguras,\n",
    "    na_values=[\" \"],\n",
    "    names=colunas,\n",
    "    decimal=\".\"\n",
    ")\n",
    "\n",
    "print(MORADOR.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deu a mesma coisa que o codigo dos big data\n",
    "# inicial = DOMICILIO.merge(MORADOR, on = ['UF', 'ESTRATO_POF', 'TIPO_SITUACAO_REG','COD_UPA', 'NUM_DOM'], how = 'left')\n",
    "# inicial2 = inicial.merge(CONDICOES_VIDA, on = ['UF', 'ESTRATO_POF', 'TIPO_SITUACAO_REG','COD_UPA', 'NUM_DOM'], how='left')\n",
    "# base = inicial2.merge(MORADOR_QUALI_VIDA, on = ['UF', 'ESTRATO_POF', 'TIPO_SITUACAO_REG','COD_UPA', 'NUM_DOM'], how = 'left')\n",
    "\n",
    "\n",
    "# inicial = DOMICILIO.merge(MORADOR, how = 'left')\n",
    "# inicial2 = inicial.merge(CONDICOES_VIDA,  how='left')\n",
    "# base = inicial2.merge(MORADOR_QUALI_VIDA,  how = 'left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.12 GiB for an array with shape (17, 24650967) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Computadores Gamer\\OneDrive\\Documentos\\codigos importantes\\python\\dados.ipynb Cell 8\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Computadores%20Gamer/OneDrive/Documentos/codigos%20importantes/python/dados.ipynb#X53sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m MORADOR_QUALI_VIDA[\u001b[39m'\u001b[39m\u001b[39mchave_primaria\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m MORADOR_QUALI_VIDA[\u001b[39m'\u001b[39m\u001b[39mUF\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m MORADOR_QUALI_VIDA[\u001b[39m'\u001b[39m\u001b[39mESTRATO_POF\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m MORADOR_QUALI_VIDA[\u001b[39m'\u001b[39m\u001b[39mTIPO_SITUACAO_REG\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m MORADOR_QUALI_VIDA[\u001b[39m'\u001b[39m\u001b[39mCOD_UPA\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Computadores%20Gamer/OneDrive/Documentos/codigos%20importantes/python/dados.ipynb#X53sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m a \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mmerge(DOMICILIO, MORADOR, on \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mchave_primaria\u001b[39m\u001b[39m'\u001b[39m], how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Computadores%20Gamer/OneDrive/Documentos/codigos%20importantes/python/dados.ipynb#X53sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m b \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mmerge(CONDICOES_VIDA, a, on \u001b[39m=\u001b[39;49m [\u001b[39m'\u001b[39;49m\u001b[39mchave_primaria\u001b[39;49m\u001b[39m'\u001b[39;49m], how\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mright\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Computadores%20Gamer/OneDrive/Documentos/codigos%20importantes/python/dados.ipynb#X53sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m c \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mmerge(MORADOR_QUALI_VIDA, b, on \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mchave_primaria\u001b[39m\u001b[39m'\u001b[39m], how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mright\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Computadores Gamer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:124\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mleft : DataFrame or named Series\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     94\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    109\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[0;32m    110\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[0;32m    111\u001b[0m         left,\n\u001b[0;32m    112\u001b[0m         right,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    122\u001b[0m         validate\u001b[39m=\u001b[39mvalidate,\n\u001b[0;32m    123\u001b[0m     )\n\u001b[1;32m--> 124\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result(copy\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32mc:\\Users\\Computadores Gamer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:775\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    771\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indicator_pre_merge(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright)\n\u001b[0;32m    773\u001b[0m join_index, left_indexer, right_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_join_info()\n\u001b[1;32m--> 775\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reindex_and_concat(\n\u001b[0;32m    776\u001b[0m     join_index, left_indexer, right_indexer, copy\u001b[39m=\u001b[39;49mcopy\n\u001b[0;32m    777\u001b[0m )\n\u001b[0;32m    778\u001b[0m result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_type)\n\u001b[0;32m    780\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindicator:\n",
      "File \u001b[1;32mc:\\Users\\Computadores Gamer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:766\u001b[0m, in \u001b[0;36m_MergeOperation._reindex_and_concat\u001b[1;34m(self, join_index, left_indexer, right_indexer, copy)\u001b[0m\n\u001b[0;32m    764\u001b[0m left\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m llabels\n\u001b[0;32m    765\u001b[0m right\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m rlabels\n\u001b[1;32m--> 766\u001b[0m result \u001b[39m=\u001b[39m concat([left, right], axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    767\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Computadores Gamer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Computadores Gamer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:381\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[39mConcatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[39m1   3   4\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    368\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[0;32m    369\u001b[0m     objs,\n\u001b[0;32m    370\u001b[0m     axis\u001b[39m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    378\u001b[0m     sort\u001b[39m=\u001b[39msort,\n\u001b[0;32m    379\u001b[0m )\n\u001b[1;32m--> 381\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result()\n",
      "File \u001b[1;32mc:\\Users\\Computadores Gamer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:616\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    612\u001b[0m             indexers[ax] \u001b[39m=\u001b[39m obj_labels\u001b[39m.\u001b[39mget_indexer(new_labels)\n\u001b[0;32m    614\u001b[0m     mgrs_indexers\u001b[39m.\u001b[39mappend((obj\u001b[39m.\u001b[39m_mgr, indexers))\n\u001b[1;32m--> 616\u001b[0m new_data \u001b[39m=\u001b[39m concatenate_managers(\n\u001b[0;32m    617\u001b[0m     mgrs_indexers, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnew_axes, concat_axis\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbm_axis, copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy\n\u001b[0;32m    618\u001b[0m )\n\u001b[0;32m    619\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy:\n\u001b[0;32m    620\u001b[0m     new_data\u001b[39m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[1;32mc:\\Users\\Computadores Gamer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\concat.py:233\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m    231\u001b[0m     fastpath \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m values\u001b[39m.\u001b[39mdtype\n\u001b[0;32m    232\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 233\u001b[0m     values \u001b[39m=\u001b[39m _concatenate_join_units(join_units, concat_axis, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    234\u001b[0m     fastpath \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[39mif\u001b[39;00m fastpath:\n",
      "File \u001b[1;32mc:\\Users\\Computadores Gamer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\concat.py:542\u001b[0m, in \u001b[0;36m_concatenate_join_units\u001b[1;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[0;32m    539\u001b[0m has_none_blocks \u001b[39m=\u001b[39m \u001b[39many\u001b[39m(unit\u001b[39m.\u001b[39mblock\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mV\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m unit \u001b[39min\u001b[39;00m join_units)\n\u001b[0;32m    540\u001b[0m upcasted_na \u001b[39m=\u001b[39m _dtype_to_na_value(empty_dtype, has_none_blocks)\n\u001b[1;32m--> 542\u001b[0m to_concat \u001b[39m=\u001b[39m [\n\u001b[0;32m    543\u001b[0m     ju\u001b[39m.\u001b[39;49mget_reindexed_values(empty_dtype\u001b[39m=\u001b[39;49mempty_dtype, upcasted_na\u001b[39m=\u001b[39;49mupcasted_na)\n\u001b[0;32m    544\u001b[0m     \u001b[39mfor\u001b[39;49;00m ju \u001b[39min\u001b[39;49;00m join_units\n\u001b[0;32m    545\u001b[0m ]\n\u001b[0;32m    547\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(to_concat) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    548\u001b[0m     \u001b[39m# Only one block, nothing to concatenate.\u001b[39;00m\n\u001b[0;32m    549\u001b[0m     concat_values \u001b[39m=\u001b[39m to_concat[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Computadores Gamer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\concat.py:543\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    539\u001b[0m has_none_blocks \u001b[39m=\u001b[39m \u001b[39many\u001b[39m(unit\u001b[39m.\u001b[39mblock\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mV\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m unit \u001b[39min\u001b[39;00m join_units)\n\u001b[0;32m    540\u001b[0m upcasted_na \u001b[39m=\u001b[39m _dtype_to_na_value(empty_dtype, has_none_blocks)\n\u001b[0;32m    542\u001b[0m to_concat \u001b[39m=\u001b[39m [\n\u001b[1;32m--> 543\u001b[0m     ju\u001b[39m.\u001b[39;49mget_reindexed_values(empty_dtype\u001b[39m=\u001b[39;49mempty_dtype, upcasted_na\u001b[39m=\u001b[39;49mupcasted_na)\n\u001b[0;32m    544\u001b[0m     \u001b[39mfor\u001b[39;00m ju \u001b[39min\u001b[39;00m join_units\n\u001b[0;32m    545\u001b[0m ]\n\u001b[0;32m    547\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(to_concat) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    548\u001b[0m     \u001b[39m# Only one block, nothing to concatenate.\u001b[39;00m\n\u001b[0;32m    549\u001b[0m     concat_values \u001b[39m=\u001b[39m to_concat[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Computadores Gamer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\concat.py:522\u001b[0m, in \u001b[0;36mJoinUnit.get_reindexed_values\u001b[1;34m(self, empty_dtype, upcasted_na)\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    521\u001b[0m     \u001b[39mfor\u001b[39;00m ax, indexer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindexers\u001b[39m.\u001b[39mitems():\n\u001b[1;32m--> 522\u001b[0m         values \u001b[39m=\u001b[39m algos\u001b[39m.\u001b[39;49mtake_nd(values, indexer, axis\u001b[39m=\u001b[39;49max)\n\u001b[0;32m    524\u001b[0m \u001b[39mreturn\u001b[39;00m values\n",
      "File \u001b[1;32mc:\\Users\\Computadores Gamer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mtake(indexer, fill_value\u001b[39m=\u001b[39mfill_value, allow_fill\u001b[39m=\u001b[39mallow_fill)\n\u001b[0;32m    116\u001b[0m arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(arr)\n\u001b[1;32m--> 117\u001b[0m \u001b[39mreturn\u001b[39;00m _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)\n",
      "File \u001b[1;32mc:\\Users\\Computadores Gamer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:158\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    156\u001b[0m     out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(out_shape, dtype\u001b[39m=\u001b[39mdtype, order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mF\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    157\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(out_shape, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    160\u001b[0m func \u001b[39m=\u001b[39m _get_take_nd_function(\n\u001b[0;32m    161\u001b[0m     arr\u001b[39m.\u001b[39mndim, arr\u001b[39m.\u001b[39mdtype, out\u001b[39m.\u001b[39mdtype, axis\u001b[39m=\u001b[39maxis, mask_info\u001b[39m=\u001b[39mmask_info\n\u001b[0;32m    162\u001b[0m )\n\u001b[0;32m    163\u001b[0m func(arr, indexer, out, fill_value)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.12 GiB for an array with shape (17, 24650967) and data type int64"
     ]
    }
   ],
   "source": [
    "# verificando merge, juntando as colunas chaves de cada caderno para formar chave primária\n",
    "# DOMICILIO['chave_primaria'] = DOMICILIO['UF'].astype(str) + '-' + DOMICILIO['ESTRATO_POF'].astype(str) + '-' + DOMICILIO['TIPO_SITUACAO_REG'].astype(str) + '-' + DOMICILIO['COD_UPA'].astype(str)\n",
    "# MORADOR['chave_primaria'] = MORADOR['UF'].astype(str) + '-' + MORADOR['ESTRATO_POF'].astype(str) + '-' + MORADOR['TIPO_SITUACAO_REG'].astype(str) + '-' + MORADOR['COD_UPA'].astype(str)\n",
    "# CONDICOES_VIDA['chave_primaria'] = CONDICOES_VIDA['UF'].astype(str) + '-' + CONDICOES_VIDA['ESTRATO_POF'].astype(str) + '-' + CONDICOES_VIDA['TIPO_SITUACAO_REG'].astype(str) + '-' + CONDICOES_VIDA['COD_UPA'].astype(str)\n",
    "# MORADOR_QUALI_VIDA['chave_primaria'] = MORADOR_QUALI_VIDA['UF'].astype(str) + '-' + MORADOR_QUALI_VIDA['ESTRATO_POF'].astype(str) + '-' + MORADOR_QUALI_VIDA['TIPO_SITUACAO_REG'].astype(str) + '-' + MORADOR_QUALI_VIDA['COD_UPA'].astype(str)\n",
    "\n",
    "\n",
    "a = DOMICILIO.merge(MORADOR, on = ['chave_primaria'], how='left')\n",
    "# b = pd.merge(CONDICOES_VIDA, a, on = ['chave_primaria'], how='right')\n",
    "# c = pd.merge(MORADOR_QUALI_VIDA, b, on = ['chave_primaria'], how='right')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Merges\n",
    "bigdata = pd.merge(DOMICILIO, MORADOR, on = ['UF', 'ESTRATO_POF', 'TIPO_SITUACAO_REG','COD_UPA', 'NUM_DOM'], how= 'left')\n",
    "bigdata2 = pd.merge(CONDICOES_VIDA, bigdata, on = ['UF', 'ESTRATO_POF', 'TIPO_SITUACAO_REG','COD_UPA', 'NUM_DOM'], how='right')\n",
    "base = pd.merge(MORADOR_QUALI_VIDA, bigdata2, on = ['UF', 'ESTRATO_POF', 'TIPO_SITUACAO_REG','COD_UPA', 'NUM_DOM'], how='right')\n",
    "\n",
    "\n",
    "# removendo colunas duplicadas, ou seja, com sufixo '_x' e '_y'\n",
    "# '$' indica trecho no final da palavra\n",
    "colunas_del_x = base.filter(regex=f'_x$').columns\n",
    "base = base.drop(colunas_del_x, axis=1)\n",
    "\n",
    "colunas_del_y = base.filter(regex=f'_y$').columns\n",
    "base = base.drop(colunas_del_y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_depend1\n",
    "# MORADOR['RENDA_MONET_PC']\n",
    "# menor ou igual a 1/4 de SM = pobre\n",
    "# acima de 1/4 de SM = não pobre\n",
    "# SM (2017) = 937 \n",
    "\n",
    "\n",
    "corte_sm = 937/4\n",
    "\n",
    "base['rdpc'] = pd.Series()\n",
    "\n",
    "for i in range(len(base['RENDA_MONET_PC'])):\n",
    "    if base['RENDA_MONET_PC'][i] <= corte_sm:\n",
    "        base['rdpc'][i] = 1\n",
    "    else:\n",
    "        base['rdpc'][i] = 0\n",
    "        \n",
    "\n",
    "# grafico1 = sn.countplot(base, x='var_depend1')\n",
    "# porcentagem_pobre = base['var_depend1'].value_counts()['pobre']/len(base['var_depend1'])\n",
    "# porcentagem_naopobre = 1 - porcentagem_pobre\n",
    "# print(base['var_depend1'].value_counts(), f'% pobre:{porcentagem_pobre}', f'% nao pobre:{porcentagem_naopobre}') \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_depend2 \n",
    "# DOMICILIO['V6199']\n",
    "# 1 – Segurança = não pobre\n",
    "# 2 – Insegurança leve = pobre\n",
    "# 3 – Insegurança moderada = pobre\n",
    "# 4 – Insegurança grave = pobre\n",
    "\n",
    "\n",
    "base['seg_alimentar'] = pd.Series()\n",
    "\n",
    "for i in range(len(base['V6199'])):\n",
    "    if base['V6199'][i] == 1:\n",
    "        base['seg_alimentar'][i] = 0\n",
    "    elif base['V6199'][i]==2:\n",
    "        base['seg_alimentar'][i] = 1\n",
    "    elif base['V6199'][i]==3:\n",
    "        base['seg_alimentar'][i] = 1\n",
    "    elif base['V6199'][i]==4:\n",
    "        base['seg_alimentar'][i] = 1\n",
    "    \n",
    "\n",
    "# grafico2 = sn.countplot(base, x='var_depend2')\n",
    "# porcentagem_pobre = base['var_depend2'].value_counts()['pobre']/len(base['var_depend2'])\n",
    "# porcentagem_naopobre = 1 - porcentagem_pobre\n",
    "# print(base['var_depend2'].value_counts(), f'% pobre:{porcentagem_pobre}', f'% nao pobre:{porcentagem_naopobre}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_depend3.1_inicial\n",
    "# CONDICOES_VIDA['V6101']\n",
    "# 1 – Muita dificuldade = pobre\n",
    "# 2 – Dificuldade = pobre\n",
    "# 3 – Alguma dificuldade = não pobre\n",
    "# 4 – Alguma facilidade = não pobre\n",
    "# 5 – Facilidade = não pobre\n",
    "# 6 – Muita facilidade = não pobre\n",
    "\n",
    "\n",
    "base['var_depend3.1_inicial'] = pd.Series()\n",
    "\n",
    "for i in range(len(base['UF'])):\n",
    "    if base['V6101'][i] == 1:\n",
    "        base['var_depend3.1_inicial'][i] = 'pobre'\n",
    "    elif base['V6101'][i]==2:\n",
    "        base['var_depend3.1_inicial'][i]  = 'pobre'\n",
    "    elif base['V6101'][i]==3:\n",
    "        base['var_depend3.1_inicial'][i]  = 'não pobre'\n",
    "    elif base['V6101'][i]==4:\n",
    "        base['var_depend3.1_inicial'][i]  = 'não pobre'\n",
    "    elif base['V6101'][i]==5:\n",
    "        base['var_depend3.1_inicial'][i]  = 'não pobre'\n",
    "    elif base['V6101'][i]==6:\n",
    "        base['var_depend3.1_inicial'][i]  = 'não pobre'\n",
    "    \n",
    " \n",
    "# sn.countplot(CONDICOES_VIDA, x='var_depend3.1_inicial')\n",
    "# print(CONDICOES_VIDA['var_depend3.1_inicial'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_depend3.2_inicial\n",
    "# CONDICOES_VIDA['V61041']\n",
    "# 1 - Bom = não pobre\n",
    "# 2 - Satisfatório = não pobre\n",
    "# 3 - Ruim = pobre\n",
    "\n",
    "\n",
    "\n",
    "base['var_depend3.2_inicial'] = pd.Series()\n",
    "\n",
    "for i in range(len(base['UF'])):\n",
    "    if base['V61041'][i] == 1:\n",
    "        base['var_depend3.2_inicial'][i] = 'não pobre'\n",
    "    elif base['V61041'][i]==2:\n",
    "        base['var_depend3.2_inicial'][i]  = 'não pobre'\n",
    "    elif base['V61041'][i]==3:\n",
    "        base['var_depend3.2_inicial'][i]  = 'pobre'\n",
    "\n",
    "    \n",
    " \n",
    "# sn.countplot(base, x='var_depend3.2_inicial')\n",
    "# print(base['var_depend3.2_inicial'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_depend4.1_inicial\n",
    "# DOMICILIO['V0212']\n",
    "# 1 – Rede geral, rede pluvial ou fossa ligada à rede = não pobre\n",
    "# 2 – Fossa não ligada à rede = pobre\n",
    "# 3 – Vala = pobre\n",
    "# 4 – Rio, lago ou mar = pobre\n",
    "# 5 – Outra forma = pobre\n",
    "\n",
    "base['var_depend4.1_inicial'] = pd.Series()\n",
    "\n",
    "for i in range(len(base['UF'])):\n",
    "    if base['V0212'][i] == 1:\n",
    "        base['var_depend4.1_inicial'][i] = 'não pobre'\n",
    "    elif base['V0212'][i]==2:\n",
    "        base['var_depend4.1_inicial'][i]  = 'pobre'\n",
    "    elif base['V0212'][i]==3:\n",
    "        base['var_depend4.1_inicial'][i]  = 'pobre'\n",
    "    elif base['V0212'][i]==4:\n",
    "        base['var_depend4.1_inicial'][i]  = 'pobre'\n",
    "    elif base['V0212'][i]==5:\n",
    "        base['var_depend4.1_inicial'][i]  = 'pobre'\n",
    "\n",
    "  \n",
    " \n",
    "# sn.countplot(DOMICILIO, x='var_depend4.1_inicial')\n",
    "# print(DOMICILIO['var_depend4.1_inicial'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_depend4.2_inicial\n",
    "# DOMICILIO['V0213']\n",
    "# 1 – Coletado diretamente por serviço de limpeza = não pobre\n",
    "# 2 – Coletado em caçamba de serviço de limpeza = não pobre\n",
    "# 3 – Queimado (na propriedade) = pobre\n",
    "# 4 – Enterrado (na propriedade) = pobre\n",
    "# 5 – Jogado em terreno baldio ou logradouro = pobre\n",
    "# 6 – Outro destino = pobre\n",
    "\n",
    "\n",
    "base['var_depend4.2_inicial'] = pd.Series()\n",
    "\n",
    "for i in range(len(base['V6199'])):\n",
    "    if base['V0213'][i] == 1:\n",
    "        base['var_depend4.2_inicial'][i] = 'não pobre'\n",
    "    elif base['V0213'][i]==2:\n",
    "        base['var_depend4.2_inicial'][i]  = 'pobre'\n",
    "    elif base['V0213'][i]==3:\n",
    "        base['var_depend4.2_inicial'][i]  = 'pobre'\n",
    "    elif base['V0213'][i]==4:\n",
    "        base['var_depend4.2_inicial'][i]  = 'pobre'\n",
    "    elif base['V0213'][i]==5:\n",
    "        base['var_depend4.2_inicial'][i]  = 'pobre'\n",
    "    elif base['V0213'][i]==6:\n",
    "        base['var_depend4.2_inicial'][i]  = 'pobre'\n",
    "\n",
    "    \n",
    " \n",
    "# sn.countplot(DOMICILIO, x='var_depend4.2_inicial')\n",
    "# print(DOMICILIO['var_depend4.2_inicial'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_depend4.3_inicial\n",
    "# DOMICILIO['V0220']\n",
    "# 1 – Sim = não pobre\n",
    "# 2 – Não = pobre\n",
    "\n",
    "base['var_depend4.3_inicial'] = pd.Series()\n",
    "\n",
    "for i in range(len(base['V6199'])):\n",
    "    if base['V0220'][i] == 1:\n",
    "        base['var_depend4.3_inicial'][i] = 'não pobre'\n",
    "    elif base['V0220'][i]==2:\n",
    "        base['var_depend4.3_inicial'][i]  = 'pobre'\n",
    "    \n",
    " \n",
    "# sn.countplot(DOMICILIO, x='var_depend4.3_inicial')\n",
    "# print(DOMICILIO['var_depend4.3_inicial'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score variavel dependente do grupo 3\n",
    "# 3\n",
    "# Pontuação:\n",
    "# 0 - não pobre\n",
    "# 1 - pobre\n",
    "# 2 - pobre\n",
    "\n",
    "\n",
    "# gerando permutações 3\n",
    "lista = ['não pobre', 'pobre']\n",
    "permutas_3 = []\n",
    "\n",
    "for i in product(lista, repeat=2):\n",
    "    permutas_3.append(i)\n",
    "print(permutas_3)\n",
    "\n",
    "# [('não pobre', 'não pobre') = 0\n",
    "# ('não pobre', 'pobre') = 1\n",
    "# ('pobre', 'não pobre') = 1\n",
    "# ('pobre', 'pobre')] = 2\n",
    "\n",
    "   \n",
    "base['subjetividade'] = pd.Series()\n",
    "for i in range(len(base['UF'])):\n",
    "    if base['var_depend3.1_inicial'][i] =='não pobre' and base['var_depend3.2_inicial'][i] == 'não pobre':\n",
    "        base['subjetividade'][i] = 'não pobre'\n",
    "        \n",
    "    elif base['var_depend3.1_inicial'][i] =='pobre' and base['var_depend3.2_inicial'][i] == 'pobre':\n",
    "        base['subjetividade'][i]  = 'pobre'\n",
    "    \n",
    "    else:\n",
    "        base['subjetividade'][i]  = 'pobre'\n",
    "\n",
    " \n",
    "# grafico3 = sn.countplot(base, x='var_depend3')\n",
    "# print(base['subjetividade'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score variavel dependente do grupo 4\n",
    "# Pontuação:\n",
    "# 0 - não pobre\n",
    "# 1 - não pobre\n",
    "# 2 - pobre\n",
    "# 3 - pobre\n",
    "\n",
    "\n",
    "# gerando permutações 4    \n",
    "lista = ['não pobre', 'pobre']\n",
    "permutas_4 = []\n",
    "\n",
    "for i in product(lista, repeat=3):\n",
    "    permutas_4.append(i)\n",
    "print(permutas_4)\n",
    "    \n",
    "# ('não pobre', 'não pobre', 'não pobre') = não pobre\n",
    "# ('não pobre', 'não pobre', 'pobre') = não pobre\n",
    "# ('não pobre', 'pobre', 'não pobre') = não pobre\n",
    "# ('não pobre', 'pobre', 'pobre') = pobre\n",
    "# ('pobre', 'não pobre', 'não pobre') = não pobre\n",
    "# ('pobre', 'não pobre', 'pobre') = pobre\n",
    "# ('pobre', 'pobre', 'não pobre') = pobre\n",
    "# ('pobre', 'pobre', 'pobre') = pobre\n",
    "\n",
    "\n",
    "base['serv_essenciais'] = pd.Series()\n",
    "\n",
    "for i in range(len(base['V6199'])):\n",
    "    if base['var_depend4.1_inicial'][i]=='não pobre' and base['var_depend4.2_inicial'][i]=='não pobre' and base['var_depend4.3_inicial'][i]=='não pobre':\n",
    "        base['serv_essenciais'][i]='não pobre'\n",
    "        \n",
    "    elif base['var_depend4.1_inicial'][i]=='não pobre' and base['var_depend4.2_inicial'][i]=='não pobre' and base['var_depend4.3_inicial'][i]=='pobre':\n",
    "        base['serv_essenciais'][i]='não pobre'\n",
    "    \n",
    "    elif base['var_depend4.1_inicial'][i]=='não pobre' and base['var_depend4.2_inicial'][i]=='pobre' and base['var_depend4.3_inicial'][i]=='não pobre':\n",
    "        base['serv_essenciais'][i]='não pobre'\n",
    "        \n",
    "    elif base['var_depend4.1_inicial'][i]=='não pobre' and base['var_depend4.2_inicial'][i]=='pobre' and base['var_depend4.3_inicial'][i]=='pobre':\n",
    "        base['serv_essenciais'][i]='pobre'\n",
    "        \n",
    "    elif base['var_depend4.1_inicial'][i]=='pobre' and base['var_depend4.2_inicial'][i]=='não pobre' and base['var_depend4.3_inicial'][i]=='não pobre':\n",
    "        base['serv_essenciais'][i]='não pobre'\n",
    "        \n",
    "    elif base['var_depend4.1_inicial'][i]=='pobre' and base['var_depend4.2_inicial'][i]=='não pobre' and base['var_depend4.3_inicial'][i]=='pobre':\n",
    "        base['serv_essenciais'][i]='pobre'\n",
    "        \n",
    "    elif base['var_depend4.1_inicial'][i]=='pobre' and base['var_depend4.2_inicial'][i]=='pobre' and base['var_depend4.3_inicial'][i]=='não pobre':\n",
    "        base['serv_essenciais'][i]='pobre'\n",
    "        \n",
    "    elif base['var_depend4.1_inicial'][i]=='pobre' and base['var_depend4.2_inicial'][i]=='pobre' and base['var_depend4.3_inicial'][i]=='pobre':\n",
    "        base['serv_essenciais'][i]='pobre'\n",
    "        \n",
    "\n",
    "    \n",
    "# grafico4 = sn.countplot(DOMICILIO, x = 'var_depend4')\n",
    "# print(DOMICILIO['var_depend4'].value_counts())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificacao NAs nas variaveis que participam do processo de criacao das variaveis dependentes 1,2,3,4\n",
    "var = ['rdpc','seg_alimentar','var_depend3.1_inicial','var_depend3.2_inicial','subjetividade','var_depend4.1_inicial','var_depend4.2_inicial','serv_essenciais' ]\n",
    "for i in var:\n",
    "    j = base[i].unique()\n",
    "    print(f'{i}:', j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deletando linhas que possuem 'nan' na variavel dependente\n",
    "# linhas antes da remoção = 693760\n",
    "# linhas depois da remoção = 682767\n",
    "base = base.dropna(subset = ['serv_essenciais'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid das 4 variaveis\n",
    "# plano\n",
    "fig, eixos = mplt.subplots (2, 2, figsize=(10,10) )\n",
    "\n",
    "# grafico1 = sn.countplot(MORADOR, x = 'var_depend1')\n",
    "sn.countplot(base, x='rdpc', ax=eixos[0,0])\n",
    "eixos[0,0].set_title('RENDA_MONET_PC')\n",
    "eixos[0,0].set_xlabel('')\n",
    "eixos[0,0].set_ylabel('')\n",
    "\n",
    "# grafico2 = sn.countplot(DOMICILIO, x = 'var_depend2')\n",
    "sn.countplot(base, x = 'seg_alimentar', ax=eixos[0,1])\n",
    "eixos[0,1].set_title('V6199')\n",
    "eixos[0,1].set_xlabel('')\n",
    "eixos[0,1].set_ylabel('')\n",
    "\n",
    "# grafico3 = sn.countplot(CONDICOES_VIDA, x = 'var_depend3')\n",
    "sn.countplot(base, x = 'subjetividade', ax= eixos[1,0])\n",
    "eixos[1,0].set_title('V6101 e V61041')\n",
    "eixos[1,0].set_xlabel('')\n",
    "eixos[1,0].set_ylabel('')\n",
    "\n",
    "# grafico4 = sn.countplot(DOMICILIO, x = 'var_depend4')\n",
    "sn.countplot(base, x = 'serv_essenciais', ax= eixos[1,1])\n",
    "eixos[1,1].set_title('V0212, V0213 e V0220')\n",
    "eixos[1,1].set_xlabel('')\n",
    "eixos[1,1].set_ylabel('')\n",
    "\n",
    "mplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variaveis indepentendes que serão usadas para estatisticas descritivas\n",
    "# MORADOR = UF, RENDA_MONET_PC\n",
    "# DOMICILIO = UF, V0212,V0213,V0220,V6199\n",
    "# CONDICOES_VIDA = UF, V6101, V61041\n",
    "# MORADOR_QUALI_VIDA = UF, TIPO_SITUACAO_REG,GRANDE_REGIAO,C1,C2,C3,C4\n",
    "\n",
    "estat_morador = base[['RENDA_MONET_PC']].describe().round(2)\n",
    "# estat_domicilio = DOMICILIO[['V0212','V0213','V0220','V6199']].value_counts()\n",
    "# estat_condicoes_vida = CONDICOES_VIDA[['V6101','V61041']].describe().round(2)\n",
    "# estat_morador_quali = MORADOR_QUALI_VIDA[['C1','C2','C3','C4']].describe().round(2)\n",
    "\n",
    "\n",
    "tabela_estat = tabulate({\n",
    "    \"MORADOR (base)\": [estat_morador.to_string()],\n",
    "    # \"DOMICILIO\": [estat_domicilio.to_string()],\n",
    "    # \"CONDICOES_VIDA\": [estat_condicoes_vida.to_string()],\n",
    "    # \"MORADOR_QUALI_VIDA\": [estat_morador_quali.to_string()]\n",
    "}, headers=\"keys\", tablefmt=\"grid\")\n",
    "\n",
    "\n",
    "print(tabela_estat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modificando nome dos UF\n",
    "base['UF'] = base['UF'].map({11 : 'RO',\n",
    "                               12 : 'AC',\n",
    "                                13 : 'AM',\n",
    "                                14 : 'RR',\n",
    "                                15 : 'PR',\n",
    "                                16 : 'AM',\n",
    "                                17 : 'TO',\n",
    "                                21 : 'MA',\n",
    "                                22 : 'PI',\n",
    "                                23 : 'CE',\n",
    "                                24 : 'RN',\n",
    "                                25 : 'PB',\n",
    "                                26 : 'PE',\n",
    "                                27 : 'AL',\n",
    "                                28 : 'SE',\n",
    "                                29 : 'BA',\n",
    "                                31 : 'MG',\n",
    "                                32 : 'ES',\n",
    "                                33 : 'RJ',\n",
    "                                35 : 'SP',\n",
    "                                41 : 'PR',\n",
    "                                42 : 'SC',\n",
    "                                43 : 'RS',\n",
    "                                50 : 'MS',\n",
    "                                51 : 'MT',\n",
    "                                52 : 'GO',\n",
    "                                53 : 'DF'}) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# media salarial por estado\n",
    "media_renda_uf = base.groupby('UF')['RENDA_MONET_PC'].mean().sort_values()\n",
    "print(media_renda_uf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analise das variaveis independentes escolhidas de cada caderno por UF\n",
    "# RENDA_MONET_PC\n",
    "fig, ax1 = mplt.subplots(figsize=(10,5))\n",
    "sn.barplot(x = 'UF' , y = 'RENDA_MONET_PC' , data = base, ax = ax1, palette='dark' )\n",
    "mplt.xlabel('Estado')\n",
    "mplt.ylabel('Renda Monetária Per Capita')\n",
    "mplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlacao de pearson entre variaveis dependentes e RENDA_MONET_PC\n",
    "\n",
    "# rdpc e RENDA_MONET_PC\n",
    "# Removendo valores infinitos e ausentes\n",
    "valid_indexes = np.isfinite(base['seg_alimentar']) & np.isfinite(base['RENDA_MONET_PC'])\n",
    "filtered_rdpc = base['seg_alimentar'][valid_indexes]\n",
    "filtered_renda = base['RENDA_MONET_PC'][valid_indexes]\n",
    "\n",
    "# Cálculo da correlação de Pearson\n",
    "correlacao1, p_valor1 = stats.pearsonr(filtered_rdpc, filtered_renda)\n",
    "print(correlacao1)\n",
    "print(p_valor1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(base['rdpc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIÁVEIS INDEPENDENTES\n",
    "# C4 - Nível de Instrução da pessoa (perfil do chefe)\n",
    "    # 1 – Sem instrução\n",
    "    # 2 – Ensino Fundamental Incompleto\n",
    "    # 3 – Ensino Fundamental Completo \n",
    "    # 4 – Ensino Médio Incompleto\n",
    "    # 5 – Ensino Médio Completo \n",
    "    # 6 – Ensino Superior Incompleto\n",
    "    # 7 – Ensino Superior Completo\n",
    "\n",
    "# C3 - Sexo (PERFIL DO CHEFE)\n",
    "    # 1- Masculino\n",
    "    # 2- Feminino\n",
    "\n",
    "# C2 - Cor ou raça (PERFI DO CHEFE)\n",
    "    # 1 – Brancos\n",
    "    # 2 – Pretos e Pardos\n",
    "    # 3 – Outros\n",
    "\n",
    "# C1 - IDADE - PERFIL DO CHEFE\n",
    "    # 1 – Até 24 anos\n",
    "    # 2 – 25 a 49 anos\n",
    "    # 3 – 50 a 64 anos\n",
    "    # 4 – 65 anos ou mais\n",
    "\n",
    "# GRANDE_REGIAO - REGIÃO (DUMY) - referência é o sudeste\n",
    "    # 1- Norte\n",
    "    # 2- Nordeste\n",
    "    # 3- Sudeste\n",
    "    # 4- Sul\n",
    "    # 5- Centro-Oeste\n",
    "    \n",
    "# TIPO_SITUACAO_REG urbano (1) x rural (2)\n",
    "    # 1 - Urbano\n",
    "    # 2 - Rural\n",
    "\n",
    "\n",
    "# VARIÁVEIS DEPENDENTES\n",
    "# rdpc\n",
    "# seg_alimentar\n",
    "# subjetividade\n",
    "# serv_essenciais\n",
    "\n",
    "base_final = base[['rdpc','seg_alimentar','subjetividade','serv_essenciais', 'TIPO_SITUACAO_REG','GRANDE_REGIAO', 'C1', 'C2', 'C3', 'C4']]\n",
    "\n",
    "# mapeamento das variaveis\n",
    "base_final['TIPO_SITUACAO_REG'] = base_final['TIPO_SITUACAO_REG'].map({1:'Urbano', 2:'Rural'})      \n",
    "base_final['GRANDE_REGIAO'] = base_final['GRANDE_REGIAO'].map({1:'Não sudeste', 2:'Não sudeste', 3:'Sudeste', 4:'Não sudeste', 5:'Não sudeste'})\n",
    "base_final['C1'] = base_final['C1'].map({1:'Até 24 anos', 2:'25 a 49 anos', 3:'50 a 64 anos', 4:'65 anos ou mais'})      \n",
    "base_final['C2'] = base_final['C2'].map({1:'Brancos', 2:'Pretos e Pardos', 3:'Outros'}) \n",
    "base_final['C3'] = base_final['C3'].map({1:'Masculino', 2:'Feminino'})\n",
    "base_final['C4'] = base_final['C4'].map({1:'Sem instrução', 2:'Ensino Fundamental Incompleto', 3:'Ensino Fundamental Completo ', 4:'Ensino Médio Incompleto', 5:'Ensino Médio Completo ',6:'Ensino Superior Incompleto', 7:'Ensino Superior Completo' })\n",
    "\n",
    "base_final.to_excel('base_final.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MQO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # transferir para excel caso nao exceda o numero de linhas\n",
    "# # limite de linhas excel = 1.048.576 linhas e 16.384 colunas\n",
    "# # ex: CARACTERISTICAS_DIETA.to_excel('caracteristicas_dieta.xlsx', index=False)\n",
    "# # os itens de 'tabelas' e 'nome_tabelas' precisam estar alinhados\n",
    "\n",
    "# # x\n",
    "# tabelas = [ CARACTERISTICAS_DIETA,\n",
    "#             CONDICOES_VIDA,\n",
    "#             CONSUMO_ALIMENTAR,\n",
    "#             DOMICILIO,\n",
    "#             MORADOR,\n",
    "#             MORADOR_QUALI_VIDA ]\n",
    "\n",
    "# # i \n",
    "# nomes_tabelas = [   'CARACTERISTICAS_DIETA',\n",
    "#                     'CONDICOES_VIDA',\n",
    "#                     'CONSUMO_ALIMENTAR',\n",
    "#                     'DOMICILIO',\n",
    "#                     'MORADOR',\n",
    "#                     'MORADOR_QUALI_VIDA' ]\n",
    "\n",
    "\n",
    "# # zip serve para fazer o loop ao mesmo tempo nas minhas duas listas\n",
    "# for x, i in zip(tabelas, nomes_tabelas):\n",
    "    \n",
    "#     if len(x) < 1048576:\n",
    "#         print(f'{len(x)} , baixar: {i}')\n",
    "        \n",
    "#         dados = pd.DataFrame(x)\n",
    "#         nome_arquivo = i +'.xlsx'\n",
    "#         dados.to_excel(nome_arquivo, index=False)\n",
    "        \n",
    "#         print(f'arquivo {i} baixado com sucesso')\n",
    "                    \n",
    "#     else:\n",
    "#         print(f'{len(x)} , nao baixar: {i}')\n",
    "        \n",
    "       \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variaveis de cada tabela\n",
    "# for x , i in zip(tabelas, nomes_tabelas):\n",
    "#     dados_desc = pd.DataFrame(x).describe()\n",
    "#     arquivo = pd.ExcelWriter('arquivo_estatisticas_descritivas.xlsx', engine = 'xlsxwriter')\n",
    "#     dados_desc.to_excel(arquivo, sheet_name='{}'.format(i), index=True)\n",
    "#     arquivo.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arquivos de dicionarios das variaveis\n",
    "# diretorio_dic = r'C:\\Users\\Computadores Gamer\\OneDrive\\Área de Trabalho\\dados gradilene\\dados'\n",
    "# diretorio_dic = diretorio_dic.replace('\\\\', '/')\n",
    "# os.chdir(diretorio_dic)\n",
    "\n",
    "# os.listdir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sheets do arquivo dicionario\n",
    "# from openpyxl import load_workbook\n",
    "# dicionario = load_workbook('dicvar1718.xlsx')\n",
    "# sheets = dicionario.sheetnames\n",
    "# print(sheets) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lendo sheet 'Morador' e mantendo apenas as variaveis 'V....'\n",
    "# necessario generalizar esse codigo para cada sheet do arquivo\n",
    "\n",
    "\n",
    "# morador = pd.read_excel('dicvar1718.xlsx', sheet_name='Morador')\n",
    "\n",
    "# # cabecalho \n",
    "# morador.columns = morador.iloc[2,]\n",
    "\n",
    "# # preenchendo elementos NAs da coluna 'Código da variável', senao a função 'startswith' nao funciona\n",
    "# morador['Código da variável'].fillna('',inplace=True)\n",
    "\n",
    "# # filtrar apenas linhas em que em 'Código da variável' o elemento começa com 'V'\n",
    "# # lembrar que 'startswith' só funciona com o '.str'\n",
    "# morador = morador[morador['Código da variável'].str.startswith('V')]        # filtrando apenas as linhas de codigos 'V....'\n",
    "# print(morador)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generalizando codigo de ler cada sheet e filtrar apenas os codigos das variaveis\n",
    "# lista_tabelas_codigos = []\n",
    "\n",
    "# for i in sheets:\n",
    "#     caderno = pd.read_excel('dicvar1718.xlsx', sheet_name=i)\n",
    "#     caderno.columns = caderno.iloc[2,]\n",
    "#     caderno['Código da variável'].fillna('', inplace=True)\n",
    "#     caderno = caderno[caderno['Código da variável'].str.startswith('V')]\n",
    "#     lista_tabelas_codigos.append(caderno)\n",
    "\n",
    "\n",
    "# codigos_site = pd.concat(lista_tabelas_codigos, axis=0)\n",
    "# codigos_site = codigos_site[['Código da variável', 'Descrição']]\n",
    "# print(codigos_site)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vendo quantas variaveis de codigo tem em cada caderno para depois fazer o merge com a tabela 'codigos'\n",
    "# lista_cadernos = [CONSUMO_ALIMENTAR, CARACTERISTICAS_DIETA, DOMICILIO, CONDICOES_VIDA, MORADOR_QUALI_VIDA , MORADOR]\n",
    "\n",
    "# # colunas = CONSUMO_ALIMENTAR.columns.str.startswith('V')\n",
    "# # CONSUMO_ALIMENTAR.columns[np.where(colunas==True)]\n",
    "\n",
    "# codigos_total = []\n",
    "# for i in lista_cadernos:\n",
    "#     colunas = i.columns.str.startswith('V')\n",
    "#     nome = i.columns[np.where(np.logical_and(colunas, i.columns.str.match('.*[0-9]$')))] # logical_and é pra unir as condicoes. '.*[0-9]$' é uma expressao regular\n",
    "#     print(len(nome.unique()),nome)\n",
    "#     codigos_total.extend(nome) # coloca na lista, parecido com append, porem append é para adicionar um unico elemento no final da lista, o extend ja adiciona tudo de uma vez\n",
    "    \n",
    "    \n",
    "# codigos_cadernos = pd.DataFrame({'codigo':codigos_total})\n",
    "# codigos_cadernos.columns = ['Código da variável']\n",
    "# # codigos_cadernos.to_excel('codigos_cadernos.xlsx', index=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fazendo merge dos codigos que achei com os 207 codigos que sao o total de codigos de todos cadernos\n",
    "# codigos_final = pd.merge(codigos_site, codigos_cadernos, on='Código da variável', how = 'outer')\n",
    "# codigos_final = codigos_final[['Código da variável','Descrição']]\n",
    "# print(codigos_final)\n",
    "\n",
    "# codigos_final.to_excel('codigos_final.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
