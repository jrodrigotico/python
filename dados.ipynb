{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'reportlab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Computadores Gamer\\OneDrive\\Documentos\\codigos importantes\\python\\dados.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Computadores%20Gamer/OneDrive/Documentos/codigos%20importantes/python/dados.ipynb#W0sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mstatsmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msms\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Computadores%20Gamer/OneDrive/Documentos/codigos%20importantes/python/dados.ipynb#W0sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mstatsmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moutliers_influence\u001b[39;00m \u001b[39mimport\u001b[39;00m variance_inflation_factor\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Computadores%20Gamer/OneDrive/Documentos/codigos%20importantes/python/dados.ipynb#W0sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mreportlab\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpagesizes\u001b[39;00m \u001b[39mimport\u001b[39;00m letter\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Computadores%20Gamer/OneDrive/Documentos/codigos%20importantes/python/dados.ipynb#W0sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mreportlab\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpdfgen\u001b[39;00m \u001b[39mimport\u001b[39;00m canvas\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'reportlab'"
     ]
    }
   ],
   "source": [
    "# pacotes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "import seaborn as sn\n",
    "from itertools import permutations, product\n",
    "import matplotlib.pyplot as mplt\n",
    "import scipy.stats as stats\n",
    "from tabulate import tabulate\n",
    "from scipy.stats import chi2_contingency \n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tools as smt\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setar diretorio dos cadernos (codigo caso puxe os arquivos com todas as colunas originais do ibge)\n",
    "diretorio = r'C:\\Users\\Computadores Gamer\\OneDrive\\√Årea de Trabalho\\dados gradilene\\dados'\n",
    "diretorio = diretorio.replace('\\\\', '/')\n",
    "\n",
    "os.chdir(diretorio)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Cadernos IBGE\n",
    "\n",
    "#### DOMICILIO\n",
    "# largura do txt\n",
    "larguras = [2,4,1,9,2,1,1,1,1,2,1,1,1,1,1,1,1,1,1,2,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,14,14,1]\n",
    "\n",
    "# nome das colunas\n",
    "colunas = [\"UF\", \"ESTRATO_POF\", \"TIPO_SITUACAO_REG\",\n",
    "            \"COD_UPA\", \"NUM_DOM\", \"V0201\", \"V0202\",\n",
    "            \"V0203\", \"V0204\", \"V0205\", \"V0206\", \"V0207\",\n",
    "            \"V0208\", \"V0209\", \"V02101\", \"V02102\",\n",
    "            \"V02103\", \"V02104\", \"V02105\", \"V02111\",\n",
    "            \"V02112\", \"V02113\", \"V0212\", \"V0213\",\n",
    "            \"V02141\", \"V02142\", \"V0215\", \"V02161\",\n",
    "            \"V02162\", \"V02163\", \"V02164\", \"V0217\",\n",
    "            \"V0219\", \"V0220\", \"V0221\", \"PESO\",\n",
    "            \"PESO_FINAL\", \"V6199\"]\n",
    "\n",
    "# leitura dos dados\n",
    "DOMICILIO = pd.read_fwf(\n",
    "    os.path.join(diretorio, \"DOMICILIO.txt\"), \n",
    "    widths=larguras,\n",
    "    na_values=[\" \"],\n",
    "    names=colunas,\n",
    "    decimal=\".\"\n",
    ")\n",
    "\n",
    "##### CONDICOES_VIDA\n",
    "# largura do txt\n",
    "larguras = [2,4,1,9,2,1,2,1,6,5,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,14,14,10]\n",
    "\n",
    "# nome das colunas\n",
    "colunas = [\"UF\", \"ESTRATO_POF\", \"TIPO_SITUACAO_REG\",\n",
    "            \"COD_UPA\", \"NUM_DOM\", \"NUM_UC\", \"COD_INFORMANTE\",\n",
    "            \"V6101\", \"V6102\", \"V6103\", \"V61041\", \"V61042\",\n",
    "            \"V61043\", \"V61044\", \"V61045\", \"V61046\",\n",
    "            \"V61051\", \"V61052\", \"V61053\", \"V61054\",\n",
    "            \"V61055\", \"V61056\", \"V61057\", \"V61058\",\n",
    "            \"V61061\", \"V61062\", \"V61063\", \"V61064\",\n",
    "            \"V61065\", \"V61066\", \"V61067\", \"V61068\",\n",
    "            \"V61069\", \"V610610\", \"V610611\", \"V61071\",\n",
    "            \"V61072\", \"V61073\", \"V6108\", \"V6109\",\n",
    "            \"V6110\", \"V6111\", \"V6112\", \"V6113\", \"V6114\",\n",
    "            \"V6115\", \"V6116\", \"V6117\", \"V6118\", \"V6119\",\n",
    "            \"V6120\", \"V6121\", \"PESO\", \"PESO_FINAL\",\n",
    "            \"RENDA_TOTAL\"]\n",
    "\n",
    "# leitura dos dados\n",
    "CONDICOES_VIDA = pd.read_fwf(\n",
    "    os.path.join(diretorio, \"CONDICOES_VIDA.txt\"),\n",
    "    widths=larguras,\n",
    "    na_values=[\" \"],\n",
    "    names=colunas,\n",
    "    decimal=\".\"\n",
    ")\n",
    "\n",
    "\n",
    "##### MORADOR_QUALI_VIDA\n",
    "# largura do txt\n",
    "larguras = [2,4,1,9,2,1,2,20,20,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,2,20,20,14,14]\n",
    "\n",
    "# nome das colunas\n",
    "colunas = [\"UF\",\"ESTRATO_POF\",\"TIPO_SITUACAO_REG\",\"COD_UPA\",\n",
    "            \"NUM_DOM\",\"NUM_UC\",\"COD_INFORMANTE\",\"CONTAGEM_PONDERADA\",\n",
    "            \"FUNCAO_PERDA\",\"V201\",\"V202\",\"V204\",\"V205\",\"V206\",\n",
    "            \"V207\",\"V208\",\"V209\",\"V210\",\"V211\",\"V212\",\"V214\",\"V215\",\n",
    "            \"V216\",\"V217\",\"V301\",\"V302\",\"V303\",\"V304\",\"V305\",\"V306\",\n",
    "            \"V307\",\"V308\",\"V401\",\"V402\",\"V403\",\"V501\",\"V502\",\"V503\",\n",
    "            \"V504\",\"V505\",\"V506\",\"V601\",\"V602\",\"V603\",\"V604\",\"V605\",\n",
    "            \"V606\",\"V607\",\"V608\",\"V609\",\"V610\",\"V611\",\"V701\",\"V702\",\n",
    "            \"V703\",\"V704\",\"V801\",\"V802\",\"V901\",\"V902\",\"GRANDE_REGIAO\",\n",
    "            \"C1\",\"C2\",\"C3\",\"C4\",\"C5\",\"C6\",\"C7\",\"RENDA_DISP_PC\",\n",
    "            \"RENDA_DISP_PC_SS\",\"PESO\",\"PESO_FINAL\"]\n",
    "\n",
    "# leitura dos dados\n",
    "MORADOR_QUALI_VIDA = pd.read_fwf(\n",
    "    os.path.join(diretorio, \"MORADOR_QUALI_VIDA.txt\"),\n",
    "    widths=larguras,\n",
    "    na_values=[\" \"],\n",
    "    names=colunas,\n",
    "    decimal=\".\"\n",
    ")\n",
    "\n",
    "\n",
    "#### MORADOR\n",
    "# largura do txt\n",
    "larguras = [2,4,1,9,2,1,2,2,1,2,2,4,3,1,1,\n",
    "            1,1,1,2,1,2,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,2,1,1,2,1,1,2,1,1,1,\n",
    "            2,1,2,14,14,10,1,20,20,20,20]\n",
    "\n",
    "# nome das colunas\n",
    "colunas = [\"UF\", \"ESTRATO_POF\", \"TIPO_SITUACAO_REG\",\n",
    "            \"COD_UPA\", \"NUM_DOM\", \"NUM_UC\", \"COD_INFORMANTE\",\n",
    "            \"V0306\", \"V0401\", \"V04021\", \"V04022\", \"V04023\",\n",
    "            \"V0403\", \"V0404\", \"V0405\", \"V0406\", \"V0407\",\n",
    "            \"V0408\", \"V0409\", \"V0410\", \"V0411\", \"V0412\",\n",
    "            \"V0413\", \"V0414\", \"V0415\", \"V0416\",\n",
    "            \"V041711\", \"V041712\", \"V041721\", \"V041722\",\n",
    "            \"V041731\", \"V041732\", \"V041741\", \"V041742\",\n",
    "            \"V0418\", \"V0419\", \"V0420\", \"V0421\", \"V0422\",\n",
    "            \"V0423\", \"V0424\", \"V0425\", \"V0426\", \"V0427\",\n",
    "            \"V0428\", \"V0429\", \"V0430\", \"ANOS_ESTUDO\",\n",
    "            \"PESO\", \"PESO_FINAL\", \"RENDA_TOTAL\",\n",
    "            \"NIVEL_INSTRUCAO\", \"RENDA_DISP_PC\",\"RENDA_MONET_PC\",\n",
    "            \"RENDA_NAO_MONET_PC\",\"DEDUCAO_PC\" ]\n",
    "\n",
    "# leitura dos dados\n",
    "MORADOR = pd.read_fwf(\n",
    "    os.path.join(diretorio, \"MORADOR.txt\"),\n",
    "    widths=larguras,\n",
    "    na_values=[\" \"],\n",
    "    names=colunas,\n",
    "    decimal=\".\"\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deu a mesma coisa que o codigo dos big data\n",
    "# inicial = DOMICILIO.merge(MORADOR, on = ['UF', 'ESTRATO_POF', 'TIPO_SITUACAO_REG','COD_UPA', 'NUM_DOM'], how = 'left')\n",
    "# inicial2 = inicial.merge(CONDICOES_VIDA, on = ['UF', 'ESTRATO_POF', 'TIPO_SITUACAO_REG','COD_UPA', 'NUM_DOM'], how='left')\n",
    "# base = inicial2.merge(MORADOR_QUALI_VIDA, on = ['UF', 'ESTRATO_POF', 'TIPO_SITUACAO_REG','COD_UPA', 'NUM_DOM'], how = 'left')\n",
    "\n",
    "\n",
    "# inicial = DOMICILIO.merge(MORADOR, how = 'left')\n",
    "# inicial2 = inicial.merge(CONDICOES_VIDA,  how='left')\n",
    "# base = inicial2.merge(MORADOR_QUALI_VIDA,  how = 'left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando merge, juntando as colunas chaves de cada caderno para formar chave prim√°ria\n",
    "# DOMICILIO['chave_primaria'] = DOMICILIO['UF'].astype(str) + '-' + DOMICILIO['ESTRATO_POF'].astype(str) + '-' + DOMICILIO['TIPO_SITUACAO_REG'].astype(str) + '-' + DOMICILIO['COD_UPA'].astype(str)\n",
    "# MORADOR['chave_primaria'] = MORADOR['UF'].astype(str) + '-' + MORADOR['ESTRATO_POF'].astype(str) + '-' + MORADOR['TIPO_SITUACAO_REG'].astype(str) + '-' + MORADOR['COD_UPA'].astype(str)\n",
    "# CONDICOES_VIDA['chave_primaria'] = CONDICOES_VIDA['UF'].astype(str) + '-' + CONDICOES_VIDA['ESTRATO_POF'].astype(str) + '-' + CONDICOES_VIDA['TIPO_SITUACAO_REG'].astype(str) + '-' + CONDICOES_VIDA['COD_UPA'].astype(str)\n",
    "# MORADOR_QUALI_VIDA['chave_primaria'] = MORADOR_QUALI_VIDA['UF'].astype(str) + '-' + MORADOR_QUALI_VIDA['ESTRATO_POF'].astype(str) + '-' + MORADOR_QUALI_VIDA['TIPO_SITUACAO_REG'].astype(str) + '-' + MORADOR_QUALI_VIDA['COD_UPA'].astype(str)\n",
    "\n",
    "\n",
    "# a = DOMICILIO.merge(MORADOR, on = ['chave_primaria'], how='left')\n",
    "# b = CONDICOES_VIDA.merge(a, on = ['chave_primaria'], how='left')\n",
    "# c = MORADOR_QUALI_VIDA.merge(b, on = ['chave_primaria'], how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Merges \n",
    "# pd.set_option('display.max_columns', 100)\n",
    "\n",
    "\n",
    "\n",
    "bigdata = pd.merge(DOMICILIO, MORADOR, on = ['UF', 'ESTRATO_POF',\"TIPO_SITUACAO_REG\",\"COD_UPA\", \"NUM_DOM\"], how='left')\n",
    "bigdata2 = pd.merge(CONDICOES_VIDA, bigdata, on = ['UF', 'ESTRATO_POF',\"TIPO_SITUACAO_REG\",\"COD_UPA\", \"NUM_DOM\"], how = 'right')\n",
    "base = pd.merge(MORADOR_QUALI_VIDA, bigdata2, on = ['UF', 'ESTRATO_POF',\"TIPO_SITUACAO_REG\",\"COD_UPA\", \"NUM_DOM\"],how = 'right')\n",
    "\n",
    "\n",
    "# removendo colunas duplicadas, ou seja, com sufixo '_x' e '_y'\n",
    "# '$' indica trecho no final da palavra\n",
    "# colunas_del_x = base.filter(regex=f'_x$').columns\n",
    "# base = base.drop(colunas_del_x, axis=1)\n",
    "\n",
    "# colunas_del_y = base.filter(regex=f'_y$').columns\n",
    "# base = base.drop(colunas_del_y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tratamento da 'base'\n",
    "\n",
    "# testando o metodo dropna(how = 'all')\n",
    "# df_teste = pd.DataFrame({'a': [np.nan,2,3],\n",
    "#                          'b': [np.nan,np.nan,7],\n",
    "#                          'c':[np.nan,np.nan,np.nan],\n",
    "#                          'd':[4,5,6]})\n",
    "# print(df_teste)\n",
    "# df = df_teste.dropna()\n",
    "# print(df)\n",
    "\n",
    "# excluindo todas as linhas que possuem tudo 'nan'\n",
    "base = base.dropna(how = 'all') \n",
    "\n",
    "\n",
    "# tratando valores nan em RENDA_MONET_PC como zero\n",
    "for i in range(len(base['UF'])):\n",
    "    if pd.isna(base['RENDA_MONET_PC'][i]):\n",
    "       base['RENDA_MONET_PC'][i]=float(0) \n",
    "\n",
    "print(base['RENDA_MONET_PC'].isna().unique())\n",
    "\n",
    "\n",
    "for i in range(len(base['UF'])):\n",
    "    if pd.isna(base['V6199'][i]):\n",
    "       base['V6199'][i]='teste' \n",
    "\n",
    "print(base['V6199'].unique())\n",
    "\n",
    "\n",
    "for i in range(len(base['UF'])):\n",
    "    if pd.isna(base['V6101'][i]):\n",
    "       base['V6101'][i]='teste'\n",
    "\n",
    "print(base['V6101'].unique())\n",
    "\n",
    "\n",
    "for i in range(len(base['UF'])):\n",
    "    if pd.isna(base['V61041'][i]):\n",
    "       base['V61041'][i]='teste' \n",
    "\n",
    "print(base['V61041'].unique())\n",
    "\n",
    "\n",
    "# aqui tem na\n",
    "for i in range(len(base['UF'])):\n",
    "    if pd.isna(base['V0212'][i]):\n",
    "       base['V0212'][i]='existe na' \n",
    "\n",
    "print(base['V0212'].unique())\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(base['UF'])):\n",
    "    if pd.isna(base['V0213'][i]):\n",
    "       base['V0213'][i]='existe na' \n",
    "\n",
    "print(base['V0213'].unique())\n",
    "\n",
    "\n",
    "for i in range(len(base['UF'])):\n",
    "    if pd.isna(base['V0220'][i]):\n",
    "       base['V0220'][i]='existe na' \n",
    "\n",
    "print(base['V0220'].unique())\n",
    "\n",
    "\n",
    "# retirando linha da variavel 'V0212' que possui na\n",
    "base = base.loc[base['V0212'] != 'existe na']\n",
    "\n",
    "\n",
    "# reindexando a base\n",
    "# com as linhas deletadas os ind√≠ces ficam fora de ordem e isso pode dar problema nos loops seguintes\n",
    "base.reset_index(drop=True, inplace=True) \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria√ß√£o vari√°veis dependentes - parte 1\n",
    "\n",
    "#rdpc\n",
    "# var_depend1\n",
    "# MORADOR['RENDA_MONET_PC']\n",
    "# menor ou igual a 1/4 de SM = pobre\n",
    "# acima de 1/4 de SM = n√£o pobre\n",
    "# SM (2017) = 937 \n",
    "def get_rdpc(z):\n",
    "    if z <= 937/4:\n",
    "        return 1\n",
    "    return 0\n",
    "base['rdpc'] = base['RENDA_MONET_PC'].apply(lambda z: get_rdpc(z))\n",
    "\n",
    "# seg_alimentar\n",
    "# var_depend2 \n",
    "# DOMICILIO['V6199']\n",
    "# 1 ‚Äì Seguran√ßa = n√£o pobre\n",
    "# 2 ‚Äì Inseguran√ßa leve = pobre\n",
    "# 3 ‚Äì Inseguran√ßa moderada = pobre\n",
    "# 4 ‚Äì Inseguran√ßa grave = pobre\n",
    "def get_seg_alimentar(z):\n",
    "    if z == 1:\n",
    "        return 0\n",
    "    return 1\n",
    "base['seg_alimentar'] = base['V6199'].apply( lambda z: get_seg_alimentar(z))\n",
    "\n",
    "\n",
    "# subjetividade 1\n",
    "# var_depend3.1_inicial\n",
    "# CONDICOES_VIDA['V6101']\n",
    "# 1 ‚Äì Muita dificuldade = pobre\n",
    "# 2 ‚Äì Dificuldade = pobre\n",
    "# 3 ‚Äì Alguma dificuldade = n√£o pobre\n",
    "# 4 ‚Äì Alguma facilidade = n√£o pobre\n",
    "# 5 ‚Äì Facilidade = n√£o pobre\n",
    "# 6 ‚Äì Muita facilidade = n√£o pobre\n",
    "def get_subjetividade_i(z):\n",
    "    if z == 1 or z==2:\n",
    "        return 1\n",
    "    return 0\n",
    "base['var_depend3.1_inicial'] = base['V6101'].apply(lambda z: get_subjetividade_i(z))\n",
    "\n",
    "\n",
    "# subjetividade 2\n",
    "# var_depend3.2_inicial\n",
    "# CONDICOES_VIDA['V61041']\n",
    "# 1 - Bom = n√£o pobre\n",
    "# 2 - Satisfat√≥rio = n√£o pobre\n",
    "# 3 - Ruim = pobre\n",
    "def get_subjetividade_i2(z):\n",
    "    if z == 3:\n",
    "        return 1\n",
    "    return 0\n",
    "base['var_depend3.2_inicial'] = base['V61041'].apply(lambda z: get_subjetividade_i2(z))\n",
    "\n",
    "\n",
    "# serv_essenciais1\n",
    "# var_depend4.1_inicial\n",
    "# DOMICILIO['V0212']\n",
    "# 1 ‚Äì Rede geral, rede pluvial ou fossa ligada √† rede = n√£o pobre\n",
    "# 2 ‚Äì Fossa n√£o ligada √† rede = pobre\n",
    "# 3 ‚Äì Vala = pobre\n",
    "# 4 ‚Äì Rio, lago ou mar = pobre\n",
    "# 5 ‚Äì Outra forma = pobre\n",
    "def get_serv_essenciais1(z):\n",
    "    if z == 1:\n",
    "        return 0\n",
    "    return 1\n",
    "base['var_depend4.1_inicial'] = base['V0212'].apply(lambda z: get_serv_essenciais1(z))\n",
    "\n",
    "\n",
    "# serv_essenciais2\n",
    "# var_depend4.2_inicial\n",
    "# DOMICILIO['V0213']\n",
    "# 1 ‚Äì Coletado diretamente por servi√ßo de limpeza = n√£o pobre\n",
    "# 2 ‚Äì Coletado em ca√ßamba de servi√ßo de limpeza = n√£o pobre\n",
    "# 3 ‚Äì Queimado (na propriedade) = pobre\n",
    "# 4 ‚Äì Enterrado (na propriedade) = pobre\n",
    "# 5 ‚Äì Jogado em terreno baldio ou logradouro = pobre\n",
    "# 6 ‚Äì Outro destino = pobre\n",
    "def get_serv_essenciais2(z):\n",
    "    if z == 1 or z==2:\n",
    "        return 0\n",
    "    return 1    \n",
    "base['var_depend4.2_inicial'] = base['V0213'].apply(lambda z: get_serv_essenciais2(z))\n",
    "\n",
    "\n",
    "\n",
    "# serv_essenciais3\n",
    "# var_depend4.3_inicial\n",
    "# DOMICILIO['V0220']\n",
    "# 1 ‚Äì Sim = n√£o pobre\n",
    "# 2 ‚Äì N√£o = pobre\n",
    "def get_serv_essenciais3(z):\n",
    "    if z == 1:\n",
    "        return 0\n",
    "    return 1    \n",
    "base['var_depend4.3_inicial'] = base['V0220'].apply(lambda z: get_serv_essenciais3(z))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Cria√ß√£o v√°riaveis dependentes - parte 2\n",
    "\n",
    "# score variavel dependente do grupo 3\n",
    "# 3\n",
    "# Pontua√ß√£o:\n",
    "# 0 - n√£o pobre\n",
    "# 1 - pobre\n",
    "# 2 - pobre\n",
    "\n",
    "# gerando permuta√ß√µes 3\n",
    "lista = ['n√£o pobre', 'pobre']\n",
    "permutas_3 = []\n",
    "\n",
    "for i in product(lista, repeat=2):\n",
    "    permutas_3.append(i)\n",
    "print(permutas_3)\n",
    "\n",
    "# [('n√£o pobre', 'n√£o pobre') = 0\n",
    "# ('n√£o pobre', 'pobre') = 1\n",
    "# ('pobre', 'n√£o pobre') = 1\n",
    "# ('pobre', 'pobre')] = 2\n",
    "\n",
    "def get_subjetividade_principal(z,w):\n",
    "    if z == 0  and w == 0:\n",
    "        return 0\n",
    "    return 1    \n",
    "base['subjetividade'] = base.apply(lambda row: get_subjetividade_principal(row['var_depend3.1_inicial'], row['var_depend3.2_inicial']), axis=1)\n",
    "\n",
    "\n",
    "# score variavel dependente do grupo 4\n",
    "# Pontua√ß√£o:\n",
    "# 0 - n√£o pobre\n",
    "# 1 - n√£o pobre\n",
    "# 2 -¬†pobre\n",
    "# 3¬†-¬†pobre\n",
    "\n",
    "\n",
    "# gerando permuta√ß√µes 4    \n",
    "lista = ['n√£o pobre', 'pobre']\n",
    "permutas_4 = []\n",
    "\n",
    "for i in product(lista, repeat=3):\n",
    "    permutas_4.append(i)\n",
    "print(permutas_4)\n",
    "    \n",
    "# ('n√£o pobre', 'n√£o pobre', 'n√£o pobre') = n√£o pobre\n",
    "# ('n√£o pobre', 'n√£o pobre', 'pobre') = n√£o pobre\n",
    "# ('n√£o pobre', 'pobre', 'n√£o pobre') = n√£o pobre\n",
    "# ('n√£o pobre', 'pobre', 'pobre') = pobre\n",
    "# ('pobre', 'n√£o pobre', 'n√£o pobre') = n√£o pobre\n",
    "# ('pobre', 'n√£o pobre', 'pobre') = pobre\n",
    "# ('pobre', 'pobre', 'n√£o pobre') = pobre\n",
    "# ('pobre', 'pobre', 'pobre') = pobre\n",
    "\n",
    "def get_serv_essenciais_principal(z,w,p):\n",
    "    if z == 0  and w == 0 and p==0:\n",
    "        return 0\n",
    "    elif z == 0  and w == 0 and p==1:\n",
    "        return 0\n",
    "    elif z == 0  and w == 1 and p==0:\n",
    "        return 0\n",
    "    elif z == 1  and w == 0 and p==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1       \n",
    "base['serv_essenciais'] = base.apply(lambda row: get_serv_essenciais_principal(row['var_depend4.1_inicial'], row['var_depend4.2_inicial'],row['var_depend4.3_inicial'] ), axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Cria√ß√£o de vari√°veis dependentes - parte 1\n",
    "# # var_depend1\n",
    "# # MORADOR['RENDA_MONET_PC']\n",
    "# # menor ou igual a 1/4 de SM = pobre\n",
    "# # acima de 1/4 de SM = n√£o pobre\n",
    "# # SM (2017) = 937 \n",
    "# # base2 = base.copy()\n",
    "\n",
    "# corte_sm = 937/4\n",
    "\n",
    "# base['rdpc'] = pd.Series()\n",
    "\n",
    "# for i in range(len(base['UF'])):\n",
    "#     if base['RENDA_MONET_PC'][i] <= corte_sm:\n",
    "#         base['rdpc'][i] = 1\n",
    "#     else:\n",
    "#         base['rdpc'][i] = 0\n",
    "        \n",
    "    \n",
    "# # grafico1 = sn.countplot(base, x='var_depend1')\n",
    "# # porcentagem_pobre = base['var_depend1'].value_counts()['pobre']/len(base['var_depend1'])\n",
    "# # porcentagem_naopobre = 1 - porcentagem_pobre\n",
    "# # print(base['var_depend1'].value_counts(), f'% pobre:{porcentagem_pobre}', f'% nao pobre:{porcentagem_naopobre}') \n",
    "\n",
    "# # var_depend2 \n",
    "# # DOMICILIO['V6199']\n",
    "# # 1 ‚Äì Seguran√ßa = n√£o pobre\n",
    "# # 2 ‚Äì Inseguran√ßa leve = pobre\n",
    "# # 3 ‚Äì Inseguran√ßa moderada = pobre\n",
    "# # 4 ‚Äì Inseguran√ßa grave = pobre\n",
    "\n",
    "\n",
    "# base['seg_alimentar'] = pd.Series()\n",
    "\n",
    "# for i in range(len(base['V6199'])):\n",
    "#     if base['V6199'][i] == 1:\n",
    "#         base['seg_alimentar'][i] = 0\n",
    "#     elif base['V6199'][i]==2:\n",
    "#         base['seg_alimentar'][i] = 1\n",
    "#     elif base['V6199'][i]==3:\n",
    "#         base['seg_alimentar'][i] = 1\n",
    "#     elif base['V6199'][i]==4:\n",
    "#         base['seg_alimentar'][i] = 1\n",
    "    \n",
    "\n",
    "# # grafico2 = sn.countplot(base, x='var_depend2')\n",
    "# # porcentagem_pobre = base['var_depend2'].value_counts()['pobre']/len(base['var_depend2'])\n",
    "# # porcentagem_naopobre = 1 - porcentagem_pobre\n",
    "# # print(base['var_depend2'].value_counts(), f'% pobre:{porcentagem_pobre}', f'% nao pobre:{porcentagem_naopobre}')\n",
    "\n",
    "# # var_depend3.1_inicial\n",
    "# # CONDICOES_VIDA['V6101']\n",
    "# # 1 ‚Äì Muita dificuldade = pobre\n",
    "# # 2 ‚Äì Dificuldade = pobre\n",
    "# # 3 ‚Äì Alguma dificuldade = n√£o pobre\n",
    "# # 4 ‚Äì Alguma facilidade = n√£o pobre\n",
    "# # 5 ‚Äì Facilidade = n√£o pobre\n",
    "# # 6 ‚Äì Muita facilidade = n√£o pobre\n",
    "\n",
    "\n",
    "# base['var_depend3.1_inicial'] = pd.Series()\n",
    "\n",
    "# for i in range(len(base['UF'])):\n",
    "#     if base['V6101'][i] == 1:\n",
    "#         base['var_depend3.1_inicial'][i] = 'pobre'\n",
    "#     elif base['V6101'][i]==2:\n",
    "#         base['var_depend3.1_inicial'][i]  = 'pobre'\n",
    "#     elif base['V6101'][i]==3:\n",
    "#         base['var_depend3.1_inicial'][i]  = 'n√£o pobre'\n",
    "#     elif base['V6101'][i]==4:\n",
    "#         base['var_depend3.1_inicial'][i]  = 'n√£o pobre'\n",
    "#     elif base['V6101'][i]==5:\n",
    "#         base['var_depend3.1_inicial'][i]  = 'n√£o pobre'\n",
    "#     elif base['V6101'][i]==6:\n",
    "#         base['var_depend3.1_inicial'][i]  = 'n√£o pobre'\n",
    "    \n",
    " \n",
    "# # sn.countplot(CONDICOES_VIDA, x='var_depend3.1_inicial')\n",
    "# # print(CONDICOES_VIDA['var_depend3.1_inicial'].value_counts())\n",
    "\n",
    "# # var_depend3.2_inicial\n",
    "# # CONDICOES_VIDA['V61041']\n",
    "# # 1 - Bom = n√£o pobre\n",
    "# # 2 - Satisfat√≥rio = n√£o pobre\n",
    "# # 3 - Ruim = pobre\n",
    "\n",
    "# base['var_depend3.2_inicial'] = pd.Series()\n",
    "\n",
    "# for i in range(len(base['UF'])):\n",
    "#     if base['V61041'][i] == 1:\n",
    "#         base['var_depend3.2_inicial'][i] = 'n√£o pobre'\n",
    "#     elif base['V61041'][i]==2:\n",
    "#         base['var_depend3.2_inicial'][i]  = 'n√£o pobre'\n",
    "#     elif base['V61041'][i]==3:\n",
    "#         base['var_depend3.2_inicial'][i]  = 'pobre'\n",
    "\n",
    "    \n",
    " \n",
    "# # sn.countplot(base, x='var_depend3.2_inicial')\n",
    "# # print(base['var_depend3.2_inicial'].value_counts())\n",
    "\n",
    "\n",
    "# # var_depend4.1_inicial\n",
    "# # DOMICILIO['V0212']\n",
    "# # 1 ‚Äì Rede geral, rede pluvial ou fossa ligada √† rede = n√£o pobre\n",
    "# # 2 ‚Äì Fossa n√£o ligada √† rede = pobre\n",
    "# # 3 ‚Äì Vala = pobre\n",
    "# # 4 ‚Äì Rio, lago ou mar = pobre\n",
    "# # 5 ‚Äì Outra forma = pobre\n",
    "\n",
    "# base['var_depend4.1_inicial'] = pd.Series()\n",
    "\n",
    "# for i in range(len(base['UF'])):\n",
    "#     if base['V0212'][i] == 1:\n",
    "#         base['var_depend4.1_inicial'][i] = 'n√£o pobre'\n",
    "#     elif base['V0212'][i]==2:\n",
    "#         base['var_depend4.1_inicial'][i]  = 'pobre'\n",
    "#     elif base['V0212'][i]==3:\n",
    "#         base['var_depend4.1_inicial'][i]  = 'pobre'\n",
    "#     elif base['V0212'][i]==4:\n",
    "#         base['var_depend4.1_inicial'][i]  = 'pobre'\n",
    "#     elif base['V0212'][i]==5:\n",
    "#         base['var_depend4.1_inicial'][i]  = 'pobre'\n",
    "\n",
    "  \n",
    " \n",
    "# # sn.countplot(DOMICILIO, x='var_depend4.1_inicial')\n",
    "# # print(DOMICILIO['var_depend4.1_inicial'].value_counts())\n",
    "\n",
    "\n",
    "# # var_depend4.2_inicial\n",
    "# # DOMICILIO['V0213']\n",
    "# # 1 ‚Äì Coletado diretamente por servi√ßo de limpeza = n√£o pobre\n",
    "# # 2 ‚Äì Coletado em ca√ßamba de servi√ßo de limpeza = n√£o pobre\n",
    "# # 3 ‚Äì Queimado (na propriedade) = pobre\n",
    "# # 4 ‚Äì Enterrado (na propriedade) = pobre\n",
    "# # 5 ‚Äì Jogado em terreno baldio ou logradouro = pobre\n",
    "# # 6 ‚Äì Outro destino = pobre\n",
    "\n",
    "\n",
    "# base['var_depend4.2_inicial'] = pd.Series()\n",
    "\n",
    "# for i in range(len(base['V6199'])):\n",
    "#     if base['V0213'][i] == 1:\n",
    "#         base['var_depend4.2_inicial'][i] = 'n√£o pobre'\n",
    "#     elif base['V0213'][i]==2:\n",
    "#         base['var_depend4.2_inicial'][i]  = 'pobre'\n",
    "#     elif base['V0213'][i]==3:\n",
    "#         base['var_depend4.2_inicial'][i]  = 'pobre'\n",
    "#     elif base['V0213'][i]==4:\n",
    "#         base['var_depend4.2_inicial'][i]  = 'pobre'\n",
    "#     elif base['V0213'][i]==5:\n",
    "#         base['var_depend4.2_inicial'][i]  = 'pobre'\n",
    "#     elif base['V0213'][i]==6:\n",
    "#         base['var_depend4.2_inicial'][i]  = 'pobre'\n",
    "\n",
    "    \n",
    " \n",
    "# # sn.countplot(DOMICILIO, x='var_depend4.2_inicial')\n",
    "# # print(DOMICILIO['var_depend4.2_inicial'].value_counts())\n",
    "\n",
    "\n",
    "# # var_depend4.3_inicial\n",
    "# # DOMICILIO['V0220']\n",
    "# # 1 ‚Äì Sim = n√£o pobre\n",
    "# # 2 ‚Äì N√£o = pobre\n",
    "\n",
    "# base['var_depend4.3_inicial'] = pd.Series()\n",
    "\n",
    "# for i in range(len(base['V6199'])):\n",
    "#     if base['V0220'][i] == 1:\n",
    "#         base['var_depend4.3_inicial'][i] = 'n√£o pobre'\n",
    "#     elif base['V0220'][i]==2:\n",
    "#         base['var_depend4.3_inicial'][i]  = 'pobre'\n",
    "    \n",
    " \n",
    "# # sn.countplot(DOMICILIO, x='var_depend4.3_inicial')\n",
    "# # print(DOMICILIO['var_depend4.3_inicial'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Cria√ß√£o v√°riaveis dependentes - parte 2\n",
    "\n",
    "# score variavel dependente do grupo 3\n",
    "# 3\n",
    "# Pontua√ß√£o:\n",
    "# 0 - n√£o pobre\n",
    "# 1 - pobre\n",
    "# 2 - pobre\n",
    "\n",
    "\n",
    "# gerando permuta√ß√µes 3\n",
    "lista = ['n√£o pobre', 'pobre']\n",
    "permutas_3 = []\n",
    "\n",
    "for i in product(lista, repeat=2):\n",
    "    permutas_3.append(i)\n",
    "print(permutas_3)\n",
    "\n",
    "# [('n√£o pobre', 'n√£o pobre') = 0\n",
    "# ('n√£o pobre', 'pobre') = 1\n",
    "# ('pobre', 'n√£o pobre') = 1\n",
    "# ('pobre', 'pobre')] = 2\n",
    "\n",
    "   \n",
    "base['subjetividade'] = pd.Series()\n",
    "for i in range(len(base['UF'])):\n",
    "    if base['var_depend3.1_inicial'][i] =='n√£o pobre' and base['var_depend3.2_inicial'][i] == 'n√£o pobre':\n",
    "        base['subjetividade'][i] = 0\n",
    "        \n",
    "    elif base['var_depend3.1_inicial'][i] =='pobre' and base['var_depend3.2_inicial'][i] == 'pobre':\n",
    "        base['subjetividade'][i]  = 1\n",
    "    \n",
    "    else:\n",
    "        base['subjetividade'][i]  = 1\n",
    "\n",
    " \n",
    "# grafico3 = sn.countplot(base, x='var_depend3')\n",
    "# print(base['subjetividade'].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "# score variavel dependente do grupo 4\n",
    "# Pontua√ß√£o:\n",
    "# 0 - n√£o pobre\n",
    "# 1 - n√£o pobre\n",
    "# 2 -¬†pobre\n",
    "# 3¬†-¬†pobre\n",
    "\n",
    "\n",
    "# gerando permuta√ß√µes 4    \n",
    "lista = ['n√£o pobre', 'pobre']\n",
    "permutas_4 = []\n",
    "\n",
    "for i in product(lista, repeat=3):\n",
    "    permutas_4.append(i)\n",
    "print(permutas_4)\n",
    "    \n",
    "# ('n√£o pobre', 'n√£o pobre', 'n√£o pobre') = n√£o pobre\n",
    "# ('n√£o pobre', 'n√£o pobre', 'pobre') = n√£o pobre\n",
    "# ('n√£o pobre', 'pobre', 'n√£o pobre') = n√£o pobre\n",
    "# ('n√£o pobre', 'pobre', 'pobre') = pobre\n",
    "# ('pobre', 'n√£o pobre', 'n√£o pobre') = n√£o pobre\n",
    "# ('pobre', 'n√£o pobre', 'pobre') = pobre\n",
    "# ('pobre', 'pobre', 'n√£o pobre') = pobre\n",
    "# ('pobre', 'pobre', 'pobre') = pobre\n",
    "\n",
    "\n",
    "base['serv_essenciais'] = pd.Series()\n",
    "\n",
    "for i in range(len(base['V6199'])):\n",
    "    if base['var_depend4.1_inicial'][i]=='n√£o pobre' and base['var_depend4.2_inicial'][i]=='n√£o pobre' and base['var_depend4.3_inicial'][i]=='n√£o pobre':\n",
    "        base['serv_essenciais'][i]=0\n",
    "        \n",
    "    elif base['var_depend4.1_inicial'][i]=='n√£o pobre' and base['var_depend4.2_inicial'][i]=='n√£o pobre' and base['var_depend4.3_inicial'][i]=='pobre':\n",
    "        base['serv_essenciais'][i]=0\n",
    "    \n",
    "    elif base['var_depend4.1_inicial'][i]=='n√£o pobre' and base['var_depend4.2_inicial'][i]=='pobre' and base['var_depend4.3_inicial'][i]=='n√£o pobre':\n",
    "        base['serv_essenciais'][i]=0\n",
    "        \n",
    "    elif base['var_depend4.1_inicial'][i]=='n√£o pobre' and base['var_depend4.2_inicial'][i]=='pobre' and base['var_depend4.3_inicial'][i]=='pobre':\n",
    "        base['serv_essenciais'][i]=1\n",
    "        \n",
    "    elif base['var_depend4.1_inicial'][i]=='pobre' and base['var_depend4.2_inicial'][i]=='n√£o pobre' and base['var_depend4.3_inicial'][i]=='n√£o pobre':\n",
    "        base['serv_essenciais'][i]=0\n",
    "        \n",
    "    elif base['var_depend4.1_inicial'][i]=='pobre' and base['var_depend4.2_inicial'][i]=='n√£o pobre' and base['var_depend4.3_inicial'][i]=='pobre':\n",
    "        base['serv_essenciais'][i]=1\n",
    "        \n",
    "    elif base['var_depend4.1_inicial'][i]=='pobre' and base['var_depend4.2_inicial'][i]=='pobre' and base['var_depend4.3_inicial'][i]=='n√£o pobre':\n",
    "        base['serv_essenciais'][i]=1\n",
    "        \n",
    "    elif base['var_depend4.1_inicial'][i]=='pobre' and base['var_depend4.2_inicial'][i]=='pobre' and base['var_depend4.3_inicial'][i]=='pobre':\n",
    "        base['serv_essenciais'][i]=1\n",
    "        \n",
    "\n",
    "    \n",
    "# grafico4 = sn.countplot(DOMICILIO, x = 'var_depend4')\n",
    "# print(DOMICILIO['var_depend4'].value_counts())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # verificacao NAs nas variaveis que participam do processo de criacao das variaveis dependentes 1,2,3,4\n",
    "var = ['rdpc','seg_alimentar','var_depend3.1_inicial','var_depend3.2_inicial','subjetividade','var_depend4.1_inicial','var_depend4.2_inicial','serv_essenciais' ]\n",
    "for i in var:\n",
    "    j = base[i].unique()\n",
    "    print(f'{i}:', j)\n",
    "    \n",
    "    \n",
    "# # deletando linhas que possuem 'nan' na variavel dependente\n",
    "# # linhas antes da remo√ß√£o = 693760\n",
    "# # linhas depois da remo√ß√£o = 682767\n",
    "# base = base.dropna(subset = ['serv_essenciais'])\n",
    "\n",
    "\n",
    "var = ['rdpc','seg_alimentar','var_depend3.1_inicial','var_depend3.2_inicial','subjetividade','var_depend4.1_inicial','var_depend4.2_inicial','serv_essenciais' ]\n",
    "for i in var:\n",
    "    j = base[i].unique()\n",
    "    print(f'{i}:', j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid das 4 variaveis\n",
    "# plano\n",
    "fig, eixos = mplt.subplots (2, 2, figsize=(10,10) )\n",
    "\n",
    "# grafico1 = sn.countplot(MORADOR, x = 'var_depend1')\n",
    "sn.countplot(base, x='rdpc', ax=eixos[0,0])\n",
    "eixos[0,0].set_title('RENDA_MONET_PC')\n",
    "eixos[0,0].set_xlabel('')\n",
    "eixos[0,0].set_ylabel('')\n",
    "\n",
    "# grafico2 = sn.countplot(DOMICILIO, x = 'var_depend2')\n",
    "sn.countplot(base, x = 'seg_alimentar', ax=eixos[0,1])\n",
    "eixos[0,1].set_title('V6199')\n",
    "eixos[0,1].set_xlabel('')\n",
    "eixos[0,1].set_ylabel('')\n",
    "\n",
    "# grafico3 = sn.countplot(CONDICOES_VIDA, x = 'var_depend3')\n",
    "sn.countplot(base, x = 'subjetividade', ax= eixos[1,0])\n",
    "eixos[1,0].set_title('V6101 e V61041')\n",
    "eixos[1,0].set_xlabel('')\n",
    "eixos[1,0].set_ylabel('')\n",
    "\n",
    "# grafico4 = sn.countplot(DOMICILIO, x = 'var_depend4')\n",
    "sn.countplot(base, x = 'serv_essenciais', ax= eixos[1,1])\n",
    "eixos[1,1].set_title('V0212, V0213 e V0220')\n",
    "eixos[1,1].set_xlabel('')\n",
    "eixos[1,1].set_ylabel('')\n",
    "\n",
    "mplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARI√ÅVEIS INDEPENDENTES\n",
    "# C4 - N√≠vel de Instru√ß√£o da pessoa (perfil do chefe)\n",
    "    # 1 ‚Äì Sem instru√ß√£o\n",
    "    # 2 ‚Äì Ensino Fundamental Incompleto\n",
    "    # 3 ‚Äì Ensino Fundamental Completo \n",
    "    # 4 ‚Äì Ensino M√©dio Incompleto\n",
    "    # 5 ‚Äì Ensino M√©dio Completo \n",
    "    # 6 ‚Äì Ensino Superior Incompleto\n",
    "    # 7 ‚Äì Ensino Superior Completo - dummy\n",
    "\n",
    "# C3 - Sexo (PERFIL DO CHEFE)\n",
    "    # 1- Masculino - dummy\n",
    "    # 2- Feminino\n",
    "\n",
    "# C2 - Cor ou ra√ßa (PERFI DO CHEFE)\n",
    "    # 1 ‚Äì Brancos - dummy\n",
    "    # 2 ‚Äì Pretos e Pardos\n",
    "    # 3 ‚Äì Outros\n",
    "\n",
    "# C1 - IDADE - PERFIL DO CHEFE\n",
    "    # 1 ‚Äì At√© 24 anos\n",
    "    # 2 ‚Äì 25 a 49 anos\n",
    "    # 3 ‚Äì 50 a 64 anos - dummy \n",
    "    # 4 ‚Äì 65 anos ou mais - dummy\n",
    "\n",
    "# GRANDE_REGIAO - REGI√ÉO (DUMY) - refer√™ncia √© o sudeste\n",
    "    # 1- Norte\n",
    "    # 2- Nordeste\n",
    "    # 3- Sudeste - dummy\n",
    "    # 4- Sul\n",
    "    # 5- Centro-Oeste\n",
    "    \n",
    "# TIPO_SITUACAO_REG¬†urbano (1)¬†x¬†rural (2)\n",
    "    # 1 - Urbano - dummy\n",
    "    # 2 - Rural\n",
    "\n",
    "\n",
    "# VARI√ÅVEIS DEPENDENTES\n",
    "# rdpc\n",
    "# seg_alimentar\n",
    "# subjetividade\n",
    "# serv_essenciais\n",
    "\n",
    "base_final = base[['rdpc','seg_alimentar','subjetividade','serv_essenciais', 'TIPO_SITUACAO_REG','GRANDE_REGIAO', 'C1', 'C2', 'C3', 'C4']]\n",
    "\n",
    "# criacao de dummies\n",
    "base_final = pd.get_dummies(base_final, columns=['TIPO_SITUACAO_REG', 'GRANDE_REGIAO','C1', 'C2', 'C3', 'C4'])\n",
    "\n",
    "# considerando apenas as dummies de referencia\n",
    "base_final = base_final[['rdpc','seg_alimentar','subjetividade','serv_essenciais', 'C4_7', 'C3_1','C2_1', 'C1_3', 'C1_4', 'GRANDE_REGIAO_3', 'TIPO_SITUACAO_REG_1']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variaveis indepentendes que ser√£o usadas para estatisticas descritivas\n",
    "# MORADOR = UF, RENDA_MONET_PC\n",
    "# DOMICILIO = UF, V0212,V0213,V0220,V6199\n",
    "# CONDICOES_VIDA = UF, V6101, V61041\n",
    "# MORADOR_QUALI_VIDA = UF, TIPO_SITUACAO_REG,GRANDE_REGIAO,C1,C2,C3,C4\n",
    "\n",
    "estat_morador = base[['RENDA_MONET_PC']].describe().round(2)\n",
    "# estat_domicilio = DOMICILIO[['V0212','V0213','V0220','V6199']].value_counts()\n",
    "# estat_condicoes_vida = CONDICOES_VIDA[['V6101','V61041']].describe().round(2)\n",
    "# estat_morador_quali = MORADOR_QUALI_VIDA[['C1','C2','C3','C4']].describe().round(2)\n",
    "\n",
    "\n",
    "tabela_estat = tabulate({\n",
    "    \"MORADOR (base)\": [estat_morador.to_string()],\n",
    "    # \"DOMICILIO\": [estat_domicilio.to_string()],\n",
    "    # \"CONDICOES_VIDA\": [estat_condicoes_vida.to_string()],\n",
    "    # \"MORADOR_QUALI_VIDA\": [estat_morador_quali.to_string()]\n",
    "}, headers=\"keys\", tablefmt=\"grid\")\n",
    "\n",
    "\n",
    "print(tabela_estat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modificando nome dos UF e media salarial por estado\n",
    "base['UF'] = base['UF'].map({11 : 'RO',\n",
    "                               12 : 'AC',\n",
    "                                13 : 'AM',\n",
    "                                14 : 'RR',\n",
    "                                15 : 'PR',\n",
    "                                16 : 'AM',\n",
    "                                17 : 'TO',\n",
    "                                21 : 'MA',\n",
    "                                22 : 'PI',\n",
    "                                23 : 'CE',\n",
    "                                24 : 'RN',\n",
    "                                25 : 'PB',\n",
    "                                26 : 'PE',\n",
    "                                27 : 'AL',\n",
    "                                28 : 'SE',\n",
    "                                29 : 'BA',\n",
    "                                31 : 'MG',\n",
    "                                32 : 'ES',\n",
    "                                33 : 'RJ',\n",
    "                                35 : 'SP',\n",
    "                                41 : 'PR',\n",
    "                                42 : 'SC',\n",
    "                                43 : 'RS',\n",
    "                                50 : 'MS',\n",
    "                                51 : 'MT',\n",
    "                                52 : 'GO',\n",
    "                                53 : 'DF'}) \n",
    "\n",
    "media_renda_uf = base.groupby('UF')['RENDA_MONET_PC'].mean().sort_values()\n",
    "print(media_renda_uf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analise das variaveis independentes escolhidas de cada caderno por UF\n",
    "# RENDA_MONET_PC\n",
    "fig, ax1 = mplt.subplots(figsize=(10,5))\n",
    "sn.barplot(x = 'UF' , y = 'RENDA_MONET_PC' , data = base, ax = ax1, palette='dark' )\n",
    "mplt.xlabel('Estado')\n",
    "mplt.ylabel('Renda Monet√°ria Per Capita')\n",
    "mplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlacao de pearson entre variaveis dependentes e RENDA_MONET_PC\n",
    "\n",
    "# rdpc e RENDA_MONET_PC\n",
    "# Removendo valores infinitos e ausentes\n",
    "valid_indexes1 = np.isfinite(base['rdpc']) & np.isfinite(base['RENDA_MONET_PC'])\n",
    "filtered_rdpc = base['rdpc'][valid_indexes1]\n",
    "filtered_renda1 = base['RENDA_MONET_PC'][valid_indexes1]\n",
    "\n",
    "# C√°lculo da correla√ß√£o de Pearson\n",
    "correlacao1, p_valor1 = stats.pearsonr(filtered_rdpc, filtered_renda1)\n",
    "print('rdpc: ',correlacao1)\n",
    "\n",
    "\n",
    "# seg_alimentar e RENDA_MONET_PC\n",
    "# Removendo valores infinitos e ausentes\n",
    "valid_indexes2 = np.isfinite(base['seg_alimentar']) & np.isfinite(base['RENDA_MONET_PC'])\n",
    "filtered_seg_alimentar = base['seg_alimentar'][valid_indexes2]\n",
    "filtered_renda2 = base['RENDA_MONET_PC'][valid_indexes2]\n",
    "\n",
    "# C√°lculo da correla√ß√£o de Pearson\n",
    "correlacao2, p_valor2 = stats.pearsonr(filtered_seg_alimentar, filtered_renda2)\n",
    "print('seg_alimentar: ',correlacao2)\n",
    "\n",
    "\n",
    "# subjetividade e RENDA_MONET_PC\n",
    "# Removendo valores infinitos e ausentes\n",
    "valid_indexes3 = np.isfinite(base['subjetividade']) & np.isfinite(base['RENDA_MONET_PC'])\n",
    "filtered_subjetividade = base['subjetividade'][valid_indexes3]\n",
    "filtered_renda3 = base['RENDA_MONET_PC'][valid_indexes3]\n",
    "\n",
    "# C√°lculo da correla√ß√£o de Pearson\n",
    "correlacao3, p_valor3 = stats.pearsonr(filtered_subjetividade, filtered_renda3)\n",
    "print('subjetividade: ',correlacao3)\n",
    "\n",
    "\n",
    "# serv_essenciais e RENDA_MONET_PC\n",
    "# Removendo valores infinitos e serv_essenciais\n",
    "valid_indexes4 = np.isfinite(base['serv_essenciais']) & np.isfinite(base['RENDA_MONET_PC'])\n",
    "filtered_serv_essenciais = base['serv_essenciais'][valid_indexes4]\n",
    "filtered_renda4 = base['RENDA_MONET_PC'][valid_indexes4]\n",
    "\n",
    "# C√°lculo da correla√ß√£o de Pearson\n",
    "correlacao4, p_valor4 = stats.pearsonr(filtered_serv_essenciais, filtered_renda4)\n",
    "print('serv_essenciais: ',correlacao4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   rdpc   R-squared:                       0.082\n",
      "Model:                            OLS   Adj. R-squared:                  0.082\n",
      "Method:                 Least Squares   F-statistic:                     8768.\n",
      "Date:                Sun, 19 Nov 2023   Prob (F-statistic):               0.00\n",
      "Time:                        00:26:25   Log-Likelihood:            -2.8390e+05\n",
      "No. Observations:              682767   AIC:                         5.678e+05\n",
      "Df Residuals:                  682759   BIC:                         5.679e+05\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                   0.4010      0.001    329.141      0.000       0.399       0.403\n",
      "C4_7                   -0.1479      0.002    -97.521      0.000      -0.151      -0.145\n",
      "C3_1                   -0.0584      0.001    -63.620      0.000      -0.060      -0.057\n",
      "C2_1                   -0.0824      0.001    -85.674      0.000      -0.084      -0.080\n",
      "C1_3                   -0.0750      0.001    -73.397      0.000      -0.077      -0.073\n",
      "C1_4                   -0.1563      0.001   -116.783      0.000      -0.159      -0.154\n",
      "GRANDE_REGIAO_3        -0.0725      0.001    -68.101      0.000      -0.075      -0.070\n",
      "TIPO_SITUACAO_REG_1    -0.1142      0.001   -106.149      0.000      -0.116      -0.112\n",
      "==============================================================================\n",
      "Omnibus:                   142205.437   Durbin-Watson:                   0.103\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           249889.980\n",
      "Skew:                           1.453   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.580   Cond. No.                         5.54\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "(0.46623686763738487, 0.9999999999999999, 'increasing')\n",
      "                          vif\n",
      "C4_7                 1.037806\n",
      "C3_1                 1.032487\n",
      "C2_1                 1.031663\n",
      "C1_3                 1.068146\n",
      "C1_4                 1.072027\n",
      "GRANDE_REGIAO_3      1.018489\n",
      "TIPO_SITUACAO_REG_1  1.046959\n"
     ]
    }
   ],
   "source": [
    "# MQO \n",
    "# https://nathaliatito.medium.com/scikit-learn-ou-statsmodels-avaliando-meu-modelo-de-regress√£o-f4c04b361fa7\n",
    "# variaveis x (ser√£o iguais para todos os modelos)\n",
    "var_x = base_final[['C4_7', 'C3_1','C2_1', 'C1_3', 'C1_4', 'GRANDE_REGIAO_3', 'TIPO_SITUACAO_REG_1']]\n",
    "\n",
    "# rdpc\n",
    "var_y = base_final[['rdpc']]\n",
    "var_x = sm.add_constant(var_x)\n",
    "modelo = sm.OLS(var_y, var_x ).fit()\n",
    "print(modelo_rdpc.summary())# Teste t de signific√¢ncia individual = H0 indica irrelev√¢ncia da variavel, portanto :. p_valor < 0.05 aceita H1 e mant√©m a variavel\n",
    "\n",
    "\n",
    "# teste homocedasticidade\n",
    "teste_homo_rdpc = sms.het_goldfeldquandt(modelo.resid, modelo.model.exog)  # exog indica variaveis ex√≥genas, ou seja, faz uma matriz das variaveis independentes do modelo\n",
    "print(teste_homo_rdpc)\n",
    "\n",
    "# vif - rdpc\n",
    "# teste de multicolinearidade, usando VIF (Variance Inflation Factor)\n",
    "# caso o valor seja maior que 10, indica multicolinearidade, √© preciso excluir essas vari√°veis\n",
    "vif= [ variance_inflation_factor(var_x.values, i ) for i in range(var_x.shape[1])]\n",
    "tabela_vif = pd.DataFrame({'vif':vif[1:]}, index = var_x.columns.drop('const'))\n",
    "print(tabela_vif)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          seg_alimentar   R-squared:                       0.083\n",
      "Model:                            OLS   Adj. R-squared:                  0.083\n",
      "Method:                 Least Squares   F-statistic:                     8790.\n",
      "Date:                Sun, 19 Nov 2023   Prob (F-statistic):               0.00\n",
      "Time:                        00:27:55   Log-Likelihood:            -4.6591e+05\n",
      "No. Observations:              682767   AIC:                         9.318e+05\n",
      "Df Residuals:                  682759   BIC:                         9.319e+05\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                   0.7086      0.002    445.483      0.000       0.706       0.712\n",
      "C4_7                   -0.2493      0.002   -125.921      0.000      -0.253      -0.245\n",
      "C3_1                   -0.1030      0.001    -86.034      0.000      -0.105      -0.101\n",
      "C2_1                   -0.1687      0.001   -134.412      0.000      -0.171      -0.166\n",
      "C1_3                   -0.0509      0.001    -38.138      0.000      -0.054      -0.048\n",
      "C1_4                   -0.1012      0.002    -57.929      0.000      -0.105      -0.098\n",
      "GRANDE_REGIAO_3        -0.0980      0.001    -70.536      0.000      -0.101      -0.095\n",
      "TIPO_SITUACAO_REG_1    -0.0377      0.001    -26.823      0.000      -0.040      -0.035\n",
      "==============================================================================\n",
      "Omnibus:                  2951116.896   Durbin-Watson:                   0.140\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            81651.663\n",
      "Skew:                           0.001   Prob(JB):                         0.00\n",
      "Kurtosis:                       1.306   Cond. No.                         5.54\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "(0.9570938407824919, 0.9999999999999999, 'increasing')\n",
      "                          vif\n",
      "C4_7                 1.037806\n",
      "C3_1                 1.032487\n",
      "C2_1                 1.031663\n",
      "C1_3                 1.068146\n",
      "C1_4                 1.072027\n",
      "GRANDE_REGIAO_3      1.018489\n",
      "TIPO_SITUACAO_REG_1  1.046959\n"
     ]
    }
   ],
   "source": [
    "# MQO - seg_alimentar\n",
    "var_y = base_final[['seg_alimentar']]\n",
    "var_x = sm.add_constant(var_x)\n",
    "modelo = sm.OLS(var_y, var_x ).fit()\n",
    "print(modelo.summary()) # Teste t de signific√¢ncia individual = H0 indica irrelev√¢ncia da variavel, portanto :. p_valor < 0.05 aceita H1 e mant√©m a variavel\n",
    "\n",
    "\n",
    "# teste homocedasticidade\n",
    "teste_homo_seg_alimentar = sms.het_goldfeldquandt(modelo.resid, modelo.model.exog)  # exog indica variaveis ex√≥genas, ou seja, faz uma matriz das variaveis independentes do modelo\n",
    "print(teste_homo_seg_alimentar)\n",
    "\n",
    "# vif - rdpc\n",
    "# teste de multicolinearidade, usando VIF (Variance Inflation Factor)\n",
    "# caso o valor seja maior que 10, indica multicolinearidade, √© preciso excluir essas vari√°veis\n",
    "vif= [ variance_inflation_factor(var_x.values, i ) for i in range(var_x.shape[1])]\n",
    "tabela_vif = pd.DataFrame({'vif':vif[1:]}, index = var_x.columns.drop('const'))\n",
    "print(tabela_vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          subjetividade   R-squared:                       0.039\n",
      "Model:                            OLS   Adj. R-squared:                  0.039\n",
      "Method:                 Least Squares   F-statistic:                     3919.\n",
      "Date:                Sun, 19 Nov 2023   Prob (F-statistic):               0.00\n",
      "Time:                        00:29:08   Log-Likelihood:            -4.6908e+05\n",
      "No. Observations:              682767   AIC:                         9.382e+05\n",
      "Df Residuals:                  682759   BIC:                         9.383e+05\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                   0.5090      0.002    318.504      0.000       0.506       0.512\n",
      "C4_7                   -0.1977      0.002    -99.400      0.000      -0.202      -0.194\n",
      "C3_1                   -0.0915      0.001    -76.032      0.000      -0.094      -0.089\n",
      "C2_1                   -0.1025      0.001    -81.302      0.000      -0.105      -0.100\n",
      "C1_3                    0.0272      0.001     20.253      0.000       0.025       0.030\n",
      "C1_4                    0.0031      0.002      1.773      0.076      -0.000       0.007\n",
      "GRANDE_REGIAO_3        -0.0453      0.001    -32.443      0.000      -0.048      -0.043\n",
      "TIPO_SITUACAO_REG_1     0.0048      0.001      3.430      0.001       0.002       0.008\n",
      "==============================================================================\n",
      "Omnibus:                  2870364.116   Durbin-Watson:                   0.152\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            99201.717\n",
      "Skew:                           0.358   Prob(JB):                         0.00\n",
      "Kurtosis:                       1.275   Cond. No.                         5.54\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "(0.8818624389445177, 0.9999999999999999, 'increasing')\n",
      "                          vif\n",
      "C4_7                 1.037806\n",
      "C3_1                 1.032487\n",
      "C2_1                 1.031663\n",
      "C1_3                 1.068146\n",
      "C1_4                 1.072027\n",
      "GRANDE_REGIAO_3      1.018489\n",
      "TIPO_SITUACAO_REG_1  1.046959\n"
     ]
    }
   ],
   "source": [
    "# MQO - subjetividade\n",
    "var_y = base_final[['subjetividade']]\n",
    "var_x = sm.add_constant(var_x)\n",
    "modelo = sm.OLS(var_y, var_x ).fit()\n",
    "print(modelo.summary()) # Teste t de signific√¢ncia individual = H0 indica irrelev√¢ncia da variavel, portanto :. p_valor < 0.05 aceita H1 e mant√©m a variavel\n",
    "\n",
    "\n",
    "# teste homocedasticidade\n",
    "teste_homo_subjetividade = sms.het_goldfeldquandt(modelo.resid, modelo.model.exog)  # exog indica variaveis ex√≥genas, ou seja, faz uma matriz das variaveis independentes do modelo\n",
    "print(teste_homo_subjetividade)\n",
    "\n",
    "# vif - rdpc\n",
    "# teste de multicolinearidade, usando VIF (Variance Inflation Factor)\n",
    "# caso o valor seja maior que 10, indica multicolinearidade, √© preciso excluir essas vari√°veis\n",
    "vif= [ variance_inflation_factor(var_x.values, i ) for i in range(var_x.shape[1])]\n",
    "tabela_vif = pd.DataFrame({'vif':vif[1:]}, index = var_x.columns.drop('const'))\n",
    "print(tabela_vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:        serv_essenciais   R-squared:                       0.470\n",
      "Model:                            OLS   Adj. R-squared:                  0.470\n",
      "Method:                 Least Squares   F-statistic:                 8.650e+04\n",
      "Date:                Sun, 19 Nov 2023   Prob (F-statistic):               0.00\n",
      "Time:                        00:29:43   Log-Likelihood:            -2.2715e+05\n",
      "No. Observations:              682767   AIC:                         4.543e+05\n",
      "Df Residuals:                  682759   BIC:                         4.544e+05\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                   0.9182      0.001    818.852      0.000       0.916       0.920\n",
      "C4_7                   -0.1047      0.001    -75.053      0.000      -0.107      -0.102\n",
      "C3_1                    0.0090      0.001     10.668      0.000       0.007       0.011\n",
      "C2_1                   -0.0376      0.001    -42.531      0.000      -0.039      -0.036\n",
      "C1_3                   -0.0222      0.001    -23.636      0.000      -0.024      -0.020\n",
      "C1_4                   -0.0433      0.001    -35.205      0.000      -0.046      -0.041\n",
      "GRANDE_REGIAO_3        -0.1172      0.001   -119.631      0.000      -0.119      -0.115\n",
      "TIPO_SITUACAO_REG_1    -0.7151      0.001   -722.407      0.000      -0.717      -0.713\n",
      "==============================================================================\n",
      "Omnibus:                   124879.219   Durbin-Watson:                   0.081\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           269813.053\n",
      "Skew:                           1.074   Prob(JB):                         0.00\n",
      "Kurtosis:                       5.208   Cond. No.                         5.54\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "(0.8818624389445177, 0.9999999999999999, 'increasing')\n",
      "                          vif\n",
      "C4_7                 1.037806\n",
      "C3_1                 1.032487\n",
      "C2_1                 1.031663\n",
      "C1_3                 1.068146\n",
      "C1_4                 1.072027\n",
      "GRANDE_REGIAO_3      1.018489\n",
      "TIPO_SITUACAO_REG_1  1.046959\n"
     ]
    }
   ],
   "source": [
    "# MQO - serv_essenciais\n",
    "var_y = base_final[['serv_essenciais']]\n",
    "var_x = sm.add_constant(var_x)\n",
    "modelo = sm.OLS(var_y, var_x ).fit()\n",
    "print(modelo.summary()) # Teste t de signific√¢ncia individual = H0 indica irrelev√¢ncia da variavel, portanto :. p_valor < 0.05 aceita H1 e mant√©m a variavel\n",
    "\n",
    "\n",
    "# teste homocedasticidade\n",
    "teste_homo_serv_essenciais = sms.het_goldfeldquandt(modelo.resid, modelo.model.exog)  # exog indica variaveis ex√≥genas, ou seja, faz uma matriz das variaveis independentes do modelo\n",
    "print(teste_homo_subjetividade)\n",
    "\n",
    "# vif - rdpc\n",
    "# teste de multicolinearidade, usando VIF (Variance Inflation Factor)\n",
    "# caso o valor seja maior que 10, indica multicolinearidade, √© preciso excluir essas vari√°veis\n",
    "vif= [ variance_inflation_factor(var_x.values, i ) for i in range(var_x.shape[1])]\n",
    "tabela_vif = pd.DataFrame({'vif':vif[1:]}, index = var_x.columns.drop('const'))\n",
    "print(tabela_vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.597349354785771, 0.9999999999999999, 'increasing')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# teste de homocedasticidade usando Goldfeld-Quandt, p-valor < 0.05 indica que os dados n√£o s√£o homoced√°sticos\n",
    "# homocedasticidade = varia√ß√£o dos res√≠duos √© constante\n",
    "\n",
    "\n",
    "###############\n",
    "# O resultado do teste de Goldfeld-Quandt que voc√™ obteve √© o seguinte: (0.4761528626243073, 0.9999999999999999, 'increasing'). Vamos interpretar cada um desses valores:\n",
    "\n",
    "# O primeiro valor, 0.4761528626243073, √© o valor estat√≠stico calculado pelo teste de Goldfeld-Quandt. Esse valor √© usado para avaliar a presen√ßa de heteroscedasticidade nos res√≠duos do modelo de regress√£o.\n",
    "\n",
    "# Em geral, se o valor estiver pr√≥ximo de 1, isso sugere que n√£o h√° evid√™ncia significativa de heteroscedasticidade nos res√≠duos. No seu caso, o valor obtido √© menor que 1, o que indica que h√° ind√≠cios de heteroscedasticidade nos res√≠duos do modelo.\n",
    "\n",
    "# O segundo valor, 0.9999999999999999, √© o valor p (p-value) associado ao valor estat√≠stico. O valor p √© usado para determinar se o valor estat√≠stico √© estatisticamente significativo. Nesse caso, o valor p √© muito pr√≥ximo de 1, o que sugere que n√£o h√° evid√™ncia significativa para rejeitar a hip√≥tese nula de aus√™ncia de heteroscedasticidade. Em outras palavras, n√£o h√° evid√™ncia estat√≠stica para afirmar que a heteroscedasticidade est√° presente nos res√≠duos.\n",
    "\n",
    "# O terceiro valor, 'increasing', indica o padr√£o observado na heteroscedasticidade. O termo \"increasing\" significa que a vari√¢ncia dos res√≠duos aumenta conforme os valores previstos (vari√°vel independente) do modelo aumentam. Isso implica que a dispers√£o dos erros √© maior √† medida que os valores previstos aumentam.\n",
    "###############\n",
    "\n",
    "teste_homo1 = sms.het_goldfeldquandt(modelo_rdpc.resid, modelo_rdpc.model.exog)  # exog indica variaveis ex√≥genas, ou seja, faz uma matriz das variaveis independentes do modelo\n",
    "teste_homo1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          vif\n",
      "rdpc                 1.166286\n",
      "seg_alimentar        1.290572\n",
      "subjetividade        1.222268\n",
      "serv_essenciais      1.909014\n",
      "C4_7                 1.078975\n",
      "C3_1                 1.050334\n",
      "C2_1                 1.066490\n",
      "C1_3                 1.081144\n",
      "C1_4                 1.098542\n",
      "GRANDE_REGIAO_3      1.048660\n",
      "TIPO_SITUACAO_REG_1  1.853469\n"
     ]
    }
   ],
   "source": [
    "# vif - rdpc\n",
    "# teste de multicolinearidade, usando VIF (Variance Inflation Factor)\n",
    "# caso o valor seja maior que 10, indica multicolinearidade, √© preciso excluir essas vari√°veis\n",
    "vif= [ variance_inflation_factor(var_x.values, i ) for i in range(var_x.shape[1])]\n",
    "tabela_vif = pd.DataFrame({'vif':vif[1:]}, index = var_x.columns.drop('const'))\n",
    "print(tabela_vif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # transferir para excel caso nao exceda o numero de linhas\n",
    "# # limite de linhas excel = 1.048.576 linhas e 16.384 colunas\n",
    "# # ex: CARACTERISTICAS_DIETA.to_excel('caracteristicas_dieta.xlsx', index=False)\n",
    "# # os itens de 'tabelas' e 'nome_tabelas' precisam estar alinhados\n",
    "\n",
    "# # x\n",
    "# tabelas = [ CARACTERISTICAS_DIETA,\n",
    "#             CONDICOES_VIDA,\n",
    "#             CONSUMO_ALIMENTAR,\n",
    "#             DOMICILIO,\n",
    "#             MORADOR,\n",
    "#             MORADOR_QUALI_VIDA ]\n",
    "\n",
    "# # i \n",
    "# nomes_tabelas = [   'CARACTERISTICAS_DIETA',\n",
    "#                     'CONDICOES_VIDA',\n",
    "#                     'CONSUMO_ALIMENTAR',\n",
    "#                     'DOMICILIO',\n",
    "#                     'MORADOR',\n",
    "#                     'MORADOR_QUALI_VIDA' ]\n",
    "\n",
    "\n",
    "# # zip serve para fazer o loop ao mesmo tempo nas minhas duas listas\n",
    "# for x, i in zip(tabelas, nomes_tabelas):\n",
    "    \n",
    "#     if len(x) < 1048576:\n",
    "#         print(f'{len(x)} , baixar: {i}')\n",
    "        \n",
    "#         dados = pd.DataFrame(x)\n",
    "#         nome_arquivo = i +'.xlsx'\n",
    "#         dados.to_excel(nome_arquivo, index=False)\n",
    "        \n",
    "#         print(f'arquivo {i} baixado com sucesso')\n",
    "                    \n",
    "#     else:\n",
    "#         print(f'{len(x)} , nao baixar: {i}')\n",
    "        \n",
    "       \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variaveis de cada tabela\n",
    "# for x , i in zip(tabelas, nomes_tabelas):\n",
    "#     dados_desc = pd.DataFrame(x).describe()\n",
    "#     arquivo = pd.ExcelWriter('arquivo_estatisticas_descritivas.xlsx', engine = 'xlsxwriter')\n",
    "#     dados_desc.to_excel(arquivo, sheet_name='{}'.format(i), index=True)\n",
    "#     arquivo.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arquivos de dicionarios das variaveis\n",
    "# diretorio_dic = r'C:\\Users\\Computadores Gamer\\OneDrive\\√Årea de Trabalho\\dados gradilene\\dados'\n",
    "# diretorio_dic = diretorio_dic.replace('\\\\', '/')\n",
    "# os.chdir(diretorio_dic)\n",
    "\n",
    "# os.listdir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sheets do arquivo dicionario\n",
    "# from openpyxl import load_workbook\n",
    "# dicionario = load_workbook('dicvar1718.xlsx')\n",
    "# sheets = dicionario.sheetnames\n",
    "# print(sheets) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lendo sheet 'Morador' e mantendo apenas as variaveis 'V....'\n",
    "# necessario generalizar esse codigo para cada sheet do arquivo\n",
    "\n",
    "\n",
    "# morador = pd.read_excel('dicvar1718.xlsx', sheet_name='Morador')\n",
    "\n",
    "# # cabecalho \n",
    "# morador.columns = morador.iloc[2,]\n",
    "\n",
    "# # preenchendo elementos NAs da coluna 'C√≥digo da vari√°vel', senao a fun√ß√£o 'startswith' nao funciona\n",
    "# morador['C√≥digo da vari√°vel'].fillna('',inplace=True)\n",
    "\n",
    "# # filtrar apenas linhas em que em 'C√≥digo da vari√°vel' o elemento come√ßa com 'V'\n",
    "# # lembrar que 'startswith' s√≥ funciona com o '.str'\n",
    "# morador = morador[morador['C√≥digo da vari√°vel'].str.startswith('V')]        # filtrando apenas as linhas de codigos 'V....'\n",
    "# print(morador)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generalizando codigo de ler cada sheet e filtrar apenas os codigos das variaveis\n",
    "# lista_tabelas_codigos = []\n",
    "\n",
    "# for i in sheets:\n",
    "#     caderno = pd.read_excel('dicvar1718.xlsx', sheet_name=i)\n",
    "#     caderno.columns = caderno.iloc[2,]\n",
    "#     caderno['C√≥digo da vari√°vel'].fillna('', inplace=True)\n",
    "#     caderno = caderno[caderno['C√≥digo da vari√°vel'].str.startswith('V')]\n",
    "#     lista_tabelas_codigos.append(caderno)\n",
    "\n",
    "\n",
    "# codigos_site = pd.concat(lista_tabelas_codigos, axis=0)\n",
    "# codigos_site = codigos_site[['C√≥digo da vari√°vel', 'Descri√ß√£o']]\n",
    "# print(codigos_site)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vendo quantas variaveis de codigo tem em cada caderno para depois fazer o merge com a tabela 'codigos'\n",
    "# lista_cadernos = [CONSUMO_ALIMENTAR, CARACTERISTICAS_DIETA, DOMICILIO, CONDICOES_VIDA, MORADOR_QUALI_VIDA , MORADOR]\n",
    "\n",
    "# # colunas = CONSUMO_ALIMENTAR.columns.str.startswith('V')\n",
    "# # CONSUMO_ALIMENTAR.columns[np.where(colunas==True)]\n",
    "\n",
    "# codigos_total = []\n",
    "# for i in lista_cadernos:\n",
    "#     colunas = i.columns.str.startswith('V')\n",
    "#     nome = i.columns[np.where(np.logical_and(colunas, i.columns.str.match('.*[0-9]$')))] # logical_and √© pra unir as condicoes. '.*[0-9]$' √© uma expressao regular\n",
    "#     print(len(nome.unique()),nome)\n",
    "#     codigos_total.extend(nome) # coloca na lista, parecido com append, porem append √© para adicionar um unico elemento no final da lista, o extend ja adiciona tudo de uma vez\n",
    "    \n",
    "    \n",
    "# codigos_cadernos = pd.DataFrame({'codigo':codigos_total})\n",
    "# codigos_cadernos.columns = ['C√≥digo da vari√°vel']\n",
    "# # codigos_cadernos.to_excel('codigos_cadernos.xlsx', index=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fazendo merge dos codigos que achei com os 207 codigos que sao o total de codigos de todos cadernos\n",
    "# codigos_final = pd.merge(codigos_site, codigos_cadernos, on='C√≥digo da vari√°vel', how = 'outer')\n",
    "# codigos_final = codigos_final[['C√≥digo da vari√°vel','Descri√ß√£o']]\n",
    "# print(codigos_final)\n",
    "\n",
    "# codigos_final.to_excel('codigos_final.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
