{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pacotes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "import seaborn as sn\n",
    "from itertools import permutations, product\n",
    "import matplotlib.pyplot as mplt\n",
    "import scipy.stats as stats\n",
    "from tabulate import tabulate\n",
    "from scipy.stats import chi2_contingency \n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tools as smt\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setar diretorio dos cadernos (codigo caso puxe os arquivos com todas as colunas originais do ibge)\n",
    "diretorio = r'C:\\Users\\Computadores Gamer\\OneDrive\\Área de Trabalho\\dados gradilene\\dados'\n",
    "diretorio = diretorio.replace('\\\\', '/')\n",
    "\n",
    "os.chdir(diretorio)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Cadernos IBGE\n",
    "\n",
    "#### DOMICILIO\n",
    "# largura do txt\n",
    "larguras = [2,4,1,9,2,1,1,1,1,2,1,1,1,1,1,1,1,1,1,2,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,14,14,1]\n",
    "\n",
    "# nome das colunas\n",
    "colunas = [\"UF\", \"ESTRATO_POF\", \"TIPO_SITUACAO_REG\",\n",
    "            \"COD_UPA\", \"NUM_DOM\", \"V0201\", \"V0202\",\n",
    "            \"V0203\", \"V0204\", \"V0205\", \"V0206\", \"V0207\",\n",
    "            \"V0208\", \"V0209\", \"V02101\", \"V02102\",\n",
    "            \"V02103\", \"V02104\", \"V02105\", \"V02111\",\n",
    "            \"V02112\", \"V02113\", \"V0212\", \"V0213\",\n",
    "            \"V02141\", \"V02142\", \"V0215\", \"V02161\",\n",
    "            \"V02162\", \"V02163\", \"V02164\", \"V0217\",\n",
    "            \"V0219\", \"V0220\", \"V0221\", \"PESO\",\n",
    "            \"PESO_FINAL\", \"V6199\"]\n",
    "\n",
    "# leitura dos dados\n",
    "DOMICILIO = pd.read_fwf(\n",
    "    os.path.join(diretorio, \"DOMICILIO.txt\"), \n",
    "    widths=larguras,\n",
    "    na_values=[\" \"],\n",
    "    names=colunas,\n",
    "    decimal=\".\"\n",
    ")\n",
    "\n",
    "##### CONDICOES_VIDA\n",
    "# largura do txt\n",
    "larguras = [2,4,1,9,2,1,2,1,6,5,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,14,14,10]\n",
    "\n",
    "# nome das colunas\n",
    "colunas = [\"UF\", \"ESTRATO_POF\", \"TIPO_SITUACAO_REG\",\n",
    "            \"COD_UPA\", \"NUM_DOM\", \"NUM_UC\", \"COD_INFORMANTE\",\n",
    "            \"V6101\", \"V6102\", \"V6103\", \"V61041\", \"V61042\",\n",
    "            \"V61043\", \"V61044\", \"V61045\", \"V61046\",\n",
    "            \"V61051\", \"V61052\", \"V61053\", \"V61054\",\n",
    "            \"V61055\", \"V61056\", \"V61057\", \"V61058\",\n",
    "            \"V61061\", \"V61062\", \"V61063\", \"V61064\",\n",
    "            \"V61065\", \"V61066\", \"V61067\", \"V61068\",\n",
    "            \"V61069\", \"V610610\", \"V610611\", \"V61071\",\n",
    "            \"V61072\", \"V61073\", \"V6108\", \"V6109\",\n",
    "            \"V6110\", \"V6111\", \"V6112\", \"V6113\", \"V6114\",\n",
    "            \"V6115\", \"V6116\", \"V6117\", \"V6118\", \"V6119\",\n",
    "            \"V6120\", \"V6121\", \"PESO\", \"PESO_FINAL\",\n",
    "            \"RENDA_TOTAL\"]\n",
    "\n",
    "# leitura dos dados\n",
    "CONDICOES_VIDA = pd.read_fwf(\n",
    "    os.path.join(diretorio, \"CONDICOES_VIDA.txt\"),\n",
    "    widths=larguras,\n",
    "    na_values=[\" \"],\n",
    "    names=colunas,\n",
    "    decimal=\".\"\n",
    ")\n",
    "\n",
    "\n",
    "##### MORADOR_QUALI_VIDA\n",
    "# largura do txt\n",
    "larguras = [2,4,1,9,2,1,2,20,20,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,2,20,20,14,14]\n",
    "\n",
    "# nome das colunas\n",
    "colunas = [\"UF\",\"ESTRATO_POF\",\"TIPO_SITUACAO_REG\",\"COD_UPA\",\n",
    "            \"NUM_DOM\",\"NUM_UC\",\"COD_INFORMANTE\",\"CONTAGEM_PONDERADA\",\n",
    "            \"FUNCAO_PERDA\",\"V201\",\"V202\",\"V204\",\"V205\",\"V206\",\n",
    "            \"V207\",\"V208\",\"V209\",\"V210\",\"V211\",\"V212\",\"V214\",\"V215\",\n",
    "            \"V216\",\"V217\",\"V301\",\"V302\",\"V303\",\"V304\",\"V305\",\"V306\",\n",
    "            \"V307\",\"V308\",\"V401\",\"V402\",\"V403\",\"V501\",\"V502\",\"V503\",\n",
    "            \"V504\",\"V505\",\"V506\",\"V601\",\"V602\",\"V603\",\"V604\",\"V605\",\n",
    "            \"V606\",\"V607\",\"V608\",\"V609\",\"V610\",\"V611\",\"V701\",\"V702\",\n",
    "            \"V703\",\"V704\",\"V801\",\"V802\",\"V901\",\"V902\",\"GRANDE_REGIAO\",\n",
    "            \"C1\",\"C2\",\"C3\",\"C4\",\"C5\",\"C6\",\"C7\",\"RENDA_DISP_PC\",\n",
    "            \"RENDA_DISP_PC_SS\",\"PESO\",\"PESO_FINAL\"]\n",
    "\n",
    "# leitura dos dados\n",
    "MORADOR_QUALI_VIDA = pd.read_fwf(\n",
    "    os.path.join(diretorio, \"MORADOR_QUALI_VIDA.txt\"),\n",
    "    widths=larguras,\n",
    "    na_values=[\" \"],\n",
    "    names=colunas,\n",
    "    decimal=\".\"\n",
    ")\n",
    "\n",
    "\n",
    "#### MORADOR\n",
    "# largura do txt\n",
    "larguras = [2,4,1,9,2,1,2,2,1,2,2,4,3,1,1,\n",
    "            1,1,1,2,1,2,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,2,1,1,2,1,1,2,1,1,1,\n",
    "            2,1,2,14,14,10,1,20,20,20,20]\n",
    "\n",
    "# nome das colunas\n",
    "colunas = [\"UF\", \"ESTRATO_POF\", \"TIPO_SITUACAO_REG\",\n",
    "            \"COD_UPA\", \"NUM_DOM\", \"NUM_UC\", \"COD_INFORMANTE\",\n",
    "            \"V0306\", \"V0401\", \"V04021\", \"V04022\", \"V04023\",\n",
    "            \"V0403\", \"V0404\", \"V0405\", \"V0406\", \"V0407\",\n",
    "            \"V0408\", \"V0409\", \"V0410\", \"V0411\", \"V0412\",\n",
    "            \"V0413\", \"V0414\", \"V0415\", \"V0416\",\n",
    "            \"V041711\", \"V041712\", \"V041721\", \"V041722\",\n",
    "            \"V041731\", \"V041732\", \"V041741\", \"V041742\",\n",
    "            \"V0418\", \"V0419\", \"V0420\", \"V0421\", \"V0422\",\n",
    "            \"V0423\", \"V0424\", \"V0425\", \"V0426\", \"V0427\",\n",
    "            \"V0428\", \"V0429\", \"V0430\", \"ANOS_ESTUDO\",\n",
    "            \"PESO\", \"PESO_FINAL\", \"RENDA_TOTAL\",\n",
    "            \"NIVEL_INSTRUCAO\", \"RENDA_DISP_PC\",\"RENDA_MONET_PC\",\n",
    "            \"RENDA_NAO_MONET_PC\",\"DEDUCAO_PC\" ]\n",
    "\n",
    "# leitura dos dados\n",
    "MORADOR = pd.read_fwf(\n",
    "    os.path.join(diretorio, \"MORADOR.txt\"),\n",
    "    widths=larguras,\n",
    "    na_values=[\" \"],\n",
    "    names=colunas,\n",
    "    decimal=\".\"\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Computadores Gamer\\AppData\\Local\\Temp\\ipykernel_16656\\1938701892.py:5: FutureWarning: Passing 'suffixes' which cause duplicate columns {'PESO_FINAL_y', 'PESO_y'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  base = pd.merge(MORADOR_QUALI_VIDA, bigdata2, on = ['UF', 'ESTRATO_POF',\"TIPO_SITUACAO_REG\",\"COD_UPA\", \"NUM_DOM\"],how = 'right')\n"
     ]
    }
   ],
   "source": [
    "# #### Merges \n",
    "# pd.set_option('display.max_columns', 100)\n",
    "bigdata = pd.merge(DOMICILIO, MORADOR, on = ['UF', 'ESTRATO_POF',\"TIPO_SITUACAO_REG\",\"COD_UPA\", \"NUM_DOM\"], how='left')\n",
    "bigdata2 = pd.merge(CONDICOES_VIDA, bigdata, on = ['UF', 'ESTRATO_POF',\"TIPO_SITUACAO_REG\",\"COD_UPA\", \"NUM_DOM\"], how = 'right')\n",
    "base = pd.merge(MORADOR_QUALI_VIDA, bigdata2, on = ['UF', 'ESTRATO_POF',\"TIPO_SITUACAO_REG\",\"COD_UPA\", \"NUM_DOM\"],how = 'right')\n",
    "\n",
    "\n",
    "# removendo colunas duplicadas, ou seja, com sufixo '_x' e '_y'\n",
    "# '$' indica trecho no final da palavra\n",
    "# colunas_del_x = base.filter(regex=f'_x$').columns\n",
    "# base = base.drop(colunas_del_x, axis=1)\n",
    "\n",
    "# colunas_del_y = base.filter(regex=f'_y$').columns\n",
    "# base = base.drop(colunas_del_y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tratamento da 'base'\n",
    "# excluindo todas as linhas que possuem tudo 'nan'\n",
    "base = base.dropna(how = 'all') \n",
    "\n",
    "\n",
    "# tratando valores nan em RENDA_MONET_PC como zero\n",
    "for i in range(len(base['UF'])):\n",
    "    if pd.isna(base['RENDA_MONET_PC'][i]):\n",
    "       base['RENDA_MONET_PC'][i]=float(0) \n",
    "\n",
    "print(base['RENDA_MONET_PC'].isna().unique())\n",
    "\n",
    "\n",
    "for i in range(len(base['UF'])):\n",
    "    if pd.isna(base['V6199'][i]):\n",
    "       base['V6199'][i]='teste' \n",
    "\n",
    "print(base['V6199'].unique())\n",
    "\n",
    "\n",
    "for i in range(len(base['UF'])):\n",
    "    if pd.isna(base['V6101'][i]):\n",
    "       base['V6101'][i]='teste'\n",
    "\n",
    "print(base['V6101'].unique())\n",
    "\n",
    "\n",
    "for i in range(len(base['UF'])):\n",
    "    if pd.isna(base['V61041'][i]):\n",
    "       base['V61041'][i]='teste' \n",
    "\n",
    "print(base['V61041'].unique())\n",
    "\n",
    "\n",
    "# aqui tem na\n",
    "for i in range(len(base['UF'])):\n",
    "    if pd.isna(base['V0212'][i]):\n",
    "       base['V0212'][i]='existe na' \n",
    "\n",
    "print(base['V0212'].unique())\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(base['UF'])):\n",
    "    if pd.isna(base['V0213'][i]):\n",
    "       base['V0213'][i]='existe na' \n",
    "\n",
    "print(base['V0213'].unique())\n",
    "\n",
    "\n",
    "for i in range(len(base['UF'])):\n",
    "    if pd.isna(base['V0220'][i]):\n",
    "       base['V0220'][i]='existe na' \n",
    "\n",
    "print(base['V0220'].unique())\n",
    "\n",
    "\n",
    "# retirando linha da variavel 'V0212' que possui na\n",
    "base = base.loc[base['V0212'] != 'existe na']\n",
    "\n",
    "\n",
    "# reindexando a base\n",
    "# com as linhas deletadas os indíces ficam fora de ordem e isso pode dar problema nos loops seguintes\n",
    "base.reset_index(drop=True, inplace=True) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando 'na' nas colunas que serão utilizadas no decorrer do código\n",
    "# esse código é mais performático\n",
    "base = base[['UF', 'ESTRATO_POF','TIPO_SITUACAO_REG','COD_UPA', 'NUM_DOM','RENDA_MONET_PC','V6199','V6101','V61041','V0212','V0213','V0220', 'C1','C2','C3','C4','GRANDE_REGIAO','TIPO_SITUACAO_REG']]\n",
    "\n",
    "colunas_na = base.columns[base.isna().any()].tolist()\n",
    "print(colunas_na)\n",
    "\n",
    "base = base.dropna(subset=['RENDA_MONET_PC','V0212'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação variáveis dependentes - parte 1\n",
    "\n",
    "#rdpc\n",
    "# var_depend1\n",
    "# MORADOR['RENDA_MONET_PC']\n",
    "# menor ou igual a 1/4 de SM = pobre\n",
    "# acima de 1/4 de SM = não pobre\n",
    "# SM (2017) = 937 \n",
    "def get_rdpc(z):\n",
    "    if z <= 937/4:\n",
    "        return 1\n",
    "    return 0\n",
    "base['rdpc'] = base['RENDA_MONET_PC'].apply(lambda z: get_rdpc(z))\n",
    "\n",
    "# seg_alimentar\n",
    "# var_depend2 \n",
    "# DOMICILIO['V6199']\n",
    "# 1 – Segurança = não pobre\n",
    "# 2 – Insegurança leve = pobre\n",
    "# 3 – Insegurança moderada = pobre\n",
    "# 4 – Insegurança grave = pobre\n",
    "def get_seg_alimentar(z):\n",
    "    if z == 1:\n",
    "        return 0\n",
    "    return 1\n",
    "base['seg_alimentar'] = base['V6199'].apply( lambda z: get_seg_alimentar(z))\n",
    "\n",
    "\n",
    "# subjetividade 1\n",
    "# var_depend3.1_inicial\n",
    "# CONDICOES_VIDA['V6101']\n",
    "# 1 – Muita dificuldade = pobre\n",
    "# 2 – Dificuldade = pobre\n",
    "# 3 – Alguma dificuldade = não pobre\n",
    "# 4 – Alguma facilidade = não pobre\n",
    "# 5 – Facilidade = não pobre\n",
    "# 6 – Muita facilidade = não pobre\n",
    "def get_subjetividade_i(z):\n",
    "    if z == 1 or z==2:\n",
    "        return 1\n",
    "    return 0\n",
    "base['var_depend3.1_inicial'] = base['V6101'].apply(lambda z: get_subjetividade_i(z))\n",
    "\n",
    "\n",
    "# subjetividade 2\n",
    "# var_depend3.2_inicial\n",
    "# CONDICOES_VIDA['V61041']\n",
    "# 1 - Bom = não pobre\n",
    "# 2 - Satisfatório = não pobre\n",
    "# 3 - Ruim = pobre\n",
    "def get_subjetividade_i2(z):\n",
    "    if z == 3:\n",
    "        return 1\n",
    "    return 0\n",
    "base['var_depend3.2_inicial'] = base['V61041'].apply(lambda z: get_subjetividade_i2(z))\n",
    "\n",
    "\n",
    "# serv_essenciais1\n",
    "# var_depend4.1_inicial\n",
    "# DOMICILIO['V0212']\n",
    "# 1 – Rede geral, rede pluvial ou fossa ligada à rede = não pobre\n",
    "# 2 – Fossa não ligada à rede = pobre\n",
    "# 3 – Vala = pobre\n",
    "# 4 – Rio, lago ou mar = pobre\n",
    "# 5 – Outra forma = pobre\n",
    "def get_serv_essenciais1(z):\n",
    "    if z == 1:\n",
    "        return 0\n",
    "    return 1\n",
    "base['var_depend4.1_inicial'] = base['V0212'].apply(lambda z: get_serv_essenciais1(z))\n",
    "\n",
    "\n",
    "# serv_essenciais2\n",
    "# var_depend4.2_inicial\n",
    "# DOMICILIO['V0213']\n",
    "# 1 – Coletado diretamente por serviço de limpeza = não pobre\n",
    "# 2 – Coletado em caçamba de serviço de limpeza = não pobre\n",
    "# 3 – Queimado (na propriedade) = pobre\n",
    "# 4 – Enterrado (na propriedade) = pobre\n",
    "# 5 – Jogado em terreno baldio ou logradouro = pobre\n",
    "# 6 – Outro destino = pobre\n",
    "def get_serv_essenciais2(z):\n",
    "    if z == 1 or z==2:\n",
    "        return 0\n",
    "    return 1    \n",
    "base['var_depend4.2_inicial'] = base['V0213'].apply(lambda z: get_serv_essenciais2(z))\n",
    "\n",
    "\n",
    "\n",
    "# serv_essenciais3\n",
    "# var_depend4.3_inicial\n",
    "# DOMICILIO['V0220']\n",
    "# 1 – Sim = não pobre\n",
    "# 2 – Não = pobre\n",
    "def get_serv_essenciais3(z):\n",
    "    if z == 1:\n",
    "        return 0\n",
    "    return 1    \n",
    "base['var_depend4.3_inicial'] = base['V0220'].apply(lambda z: get_serv_essenciais3(z))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('não pobre', 'não pobre'), ('não pobre', 'pobre'), ('pobre', 'não pobre'), ('pobre', 'pobre')]\n",
      "[('não pobre', 'não pobre', 'não pobre'), ('não pobre', 'não pobre', 'pobre'), ('não pobre', 'pobre', 'não pobre'), ('não pobre', 'pobre', 'pobre'), ('pobre', 'não pobre', 'não pobre'), ('pobre', 'não pobre', 'pobre'), ('pobre', 'pobre', 'não pobre'), ('pobre', 'pobre', 'pobre')]\n"
     ]
    }
   ],
   "source": [
    "#### Criação váriaveis dependentes - parte 2\n",
    "\n",
    "# score variavel dependente do grupo 3\n",
    "# 3\n",
    "# Pontuação:\n",
    "# 0 - não pobre\n",
    "# 1 - pobre\n",
    "# 2 - pobre\n",
    "\n",
    "# gerando permutações 3\n",
    "lista = ['não pobre', 'pobre']\n",
    "permutas_3 = []\n",
    "\n",
    "for i in product(lista, repeat=2):\n",
    "    permutas_3.append(i)\n",
    "print(permutas_3)\n",
    "\n",
    "# [('não pobre', 'não pobre') = 0\n",
    "# ('não pobre', 'pobre') = 1\n",
    "# ('pobre', 'não pobre') = 1\n",
    "# ('pobre', 'pobre')] = 2\n",
    "\n",
    "def get_subjetividade_principal(z,w):\n",
    "    if z == 0  and w == 0:\n",
    "        return 0\n",
    "    return 1    \n",
    "base['subjetividade'] = base.apply(lambda row: get_subjetividade_principal(row['var_depend3.1_inicial'], row['var_depend3.2_inicial']), axis=1)\n",
    "\n",
    "\n",
    "# score variavel dependente do grupo 4\n",
    "# Pontuação:\n",
    "# 0 - não pobre\n",
    "# 1 - não pobre\n",
    "# 2 - pobre\n",
    "# 3 - pobre\n",
    "\n",
    "\n",
    "# gerando permutações 4    \n",
    "lista = ['não pobre', 'pobre']\n",
    "permutas_4 = []\n",
    "\n",
    "for i in product(lista, repeat=3):\n",
    "    permutas_4.append(i)\n",
    "print(permutas_4)\n",
    "    \n",
    "# ('não pobre', 'não pobre', 'não pobre') = não pobre\n",
    "# ('não pobre', 'não pobre', 'pobre') = não pobre\n",
    "# ('não pobre', 'pobre', 'não pobre') = não pobre\n",
    "# ('não pobre', 'pobre', 'pobre') = pobre\n",
    "# ('pobre', 'não pobre', 'não pobre') = não pobre\n",
    "# ('pobre', 'não pobre', 'pobre') = pobre\n",
    "# ('pobre', 'pobre', 'não pobre') = pobre\n",
    "# ('pobre', 'pobre', 'pobre') = pobre\n",
    "\n",
    "def get_serv_essenciais_principal(z,w,p):\n",
    "    if z == 0  and w == 0 and p==0:\n",
    "        return 0\n",
    "    elif z == 0  and w == 0 and p==1:\n",
    "        return 0\n",
    "    elif z == 0  and w == 1 and p==0:\n",
    "        return 0\n",
    "    elif z == 1  and w == 0 and p==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1       \n",
    "base['serv_essenciais'] = base.apply(lambda row: get_serv_essenciais_principal(row['var_depend4.1_inicial'], row['var_depend4.2_inicial'],row['var_depend4.3_inicial'] ), axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # verificacao NAs nas variaveis que participam do processo de criacao das variaveis dependentes 1,2,3,4\n",
    "var = ['rdpc','seg_alimentar','var_depend3.1_inicial','var_depend3.2_inicial','subjetividade','var_depend4.1_inicial','var_depend4.2_inicial','serv_essenciais' ]\n",
    "for i in var:\n",
    "    j = base[i].unique()\n",
    "    print(f'{i}:', j)\n",
    "    \n",
    "    \n",
    "# # deletando linhas que possuem 'nan' na variavel dependente\n",
    "# # linhas antes da remoção = 693760\n",
    "# # linhas depois da remoção = 682767\n",
    "# base = base.dropna(subset = ['serv_essenciais'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid das 4 variaveis\n",
    "# plano\n",
    "fig, eixos = mplt.subplots (2, 2, figsize=(10,10) )\n",
    "\n",
    "# grafico1 = sn.countplot(MORADOR, x = 'var_depend1')\n",
    "sn.countplot(base, x='rdpc', ax=eixos[0,0])\n",
    "eixos[0,0].set_title('RENDA_MONET_PC')\n",
    "eixos[0,0].set_xlabel('')\n",
    "eixos[0,0].set_ylabel('')\n",
    "\n",
    "# grafico2 = sn.countplot(DOMICILIO, x = 'var_depend2')\n",
    "sn.countplot(base, x = 'seg_alimentar', ax=eixos[0,1])\n",
    "eixos[0,1].set_title('V6199')\n",
    "eixos[0,1].set_xlabel('')\n",
    "eixos[0,1].set_ylabel('')\n",
    "\n",
    "# grafico3 = sn.countplot(CONDICOES_VIDA, x = 'var_depend3')\n",
    "sn.countplot(base, x = 'subjetividade', ax= eixos[1,0])\n",
    "eixos[1,0].set_title('V6101 e V61041')\n",
    "eixos[1,0].set_xlabel('')\n",
    "eixos[1,0].set_ylabel('')\n",
    "\n",
    "# grafico4 = sn.countplot(DOMICILIO, x = 'var_depend4')\n",
    "sn.countplot(base, x = 'serv_essenciais', ax= eixos[1,1])\n",
    "eixos[1,1].set_title('V0212, V0213 e V0220')\n",
    "eixos[1,1].set_xlabel('')\n",
    "eixos[1,1].set_ylabel('')\n",
    "\n",
    "mplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação das dummies\n",
    "# C4 - Nível de Instrução da pessoa (perfil do chefe)\n",
    "    # 1 – Sem instrução\n",
    "    # 2 – Ensino Fundamental Incompleto\n",
    "    # 3 – Ensino Fundamental Completo \n",
    "    # 4 – Ensino Médio Incompleto\n",
    "    # 5 – Ensino Médio Completo \n",
    "    # 6 – Ensino Superior Incompleto\n",
    "    # 7 – Ensino Superior Completo - dummy\n",
    "\n",
    "# C3 - Sexo (PERFIL DO CHEFE)\n",
    "    # 1- Masculino - dummy\n",
    "    # 2- Feminino\n",
    "\n",
    "# C2 - Cor ou raça (PERFI DO CHEFE)\n",
    "    # 1 – Brancos - dummy\n",
    "    # 2 – Pretos e Pardos\n",
    "    # 3 – Outros\n",
    "\n",
    "# C1 - IDADE - PERFIL DO CHEFE\n",
    "    # 1 – Até 24 anos\n",
    "    # 2 – 25 a 49 anos\n",
    "    # 3 – 50 a 64 anos - dummy \n",
    "    # 4 – 65 anos ou mais - dummy\n",
    "\n",
    "# GRANDE_REGIAO - REGIÃO (DUMY) - referência é o sudeste\n",
    "    # 1- Norte\n",
    "    # 2- Nordeste\n",
    "    # 3- Sudeste - dummy\n",
    "    # 4- Sul\n",
    "    # 5- Centro-Oeste\n",
    "    \n",
    "# TIPO_SITUACAO_REG urbano (1) x rural (2)\n",
    "    # 1 - Urbano - dummy\n",
    "    # 2 - Rural\n",
    "\n",
    "\n",
    "# VARIÁVEIS DEPENDENTES\n",
    "# rdpc\n",
    "# seg_alimentar\n",
    "# subjetividade\n",
    "# serv_essenciais\n",
    "\n",
    "# base = base[['rdpc','seg_alimentar','subjetividade','serv_essenciais', 'TIPO_SITUACAO_REG','GRANDE_REGIAO', 'C1', 'C2', 'C3', 'C4']]\n",
    "\n",
    "# # criacao de dummies\n",
    "base = pd.get_dummies(base, columns=['TIPO_SITUACAO_REG', 'GRANDE_REGIAO','C1', 'C2', 'C3', 'C4'])\n",
    "\n",
    "# # considerando apenas as dummies de referencia\n",
    "base = base[['rdpc','seg_alimentar','subjetividade','serv_essenciais', 'C4_7', 'C3_1','C2_1', 'C1_3', 'C1_4', 'GRANDE_REGIAO_3', 'TIPO_SITUACAO_REG_1']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estatistica descritiva de 'base_final'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grafico renda media por estado\n",
    "media_renda_uf = base.groupby('UF')['RENDA_MONET_PC'].mean().sort_values()\n",
    "tabela = pd.DataFrame(media_renda_uf).reset_index()\n",
    "\n",
    "tabela['UF'] = tabela['UF'].map({11 : 'RO',\n",
    "                               12 : 'AC',\n",
    "                                13 : 'AM',\n",
    "                                14 : 'RR',\n",
    "                                15 : 'PR',\n",
    "                                16 : 'AM',\n",
    "                                17 : 'TO',\n",
    "                                21 : 'MA',\n",
    "                                22 : 'PI',\n",
    "                                23 : 'CE',\n",
    "                                24 : 'RN',\n",
    "                                25 : 'PB',\n",
    "                                26 : 'PE',\n",
    "                                27 : 'AL',\n",
    "                                28 : 'SE',\n",
    "                                29 : 'BA',\n",
    "                                31 : 'MG',\n",
    "                                32 : 'ES',\n",
    "                                33 : 'RJ',\n",
    "                                35 : 'SP',\n",
    "                                41 : 'PR',\n",
    "                                42 : 'SC',\n",
    "                                43 : 'RS',\n",
    "                                50 : 'MS',\n",
    "                                51 : 'MT',\n",
    "                                52 : 'GO',\n",
    "                                53 : 'DF'}) \n",
    "\n",
    "fig, ax = mplt.subplots(figsize = (10,10))\n",
    "sn.barplot(y='RENDA_MONET_PC', x='UF', data = tabela, ax=ax, palette='dark')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlacao de pearson entre variaveis dependentes e RENDA_MONET_PC\n",
    "\n",
    "# rdpc e RENDA_MONET_PC\n",
    "# Removendo valores infinitos e ausentes\n",
    "valid_indexes1 = np.isfinite(base['rdpc']) & np.isfinite(base['RENDA_MONET_PC'])\n",
    "filtered_rdpc = base['rdpc'][valid_indexes1]\n",
    "filtered_renda1 = base['RENDA_MONET_PC'][valid_indexes1]\n",
    "\n",
    "# Cálculo da correlação de Pearson\n",
    "correlacao1, p_valor1 = stats.pearsonr(filtered_rdpc, filtered_renda1)\n",
    "print('rdpc: ',correlacao1)\n",
    "\n",
    "\n",
    "# seg_alimentar e RENDA_MONET_PC\n",
    "# Removendo valores infinitos e ausentes\n",
    "valid_indexes2 = np.isfinite(base['seg_alimentar']) & np.isfinite(base['RENDA_MONET_PC'])\n",
    "filtered_seg_alimentar = base['seg_alimentar'][valid_indexes2]\n",
    "filtered_renda2 = base['RENDA_MONET_PC'][valid_indexes2]\n",
    "\n",
    "# Cálculo da correlação de Pearson\n",
    "correlacao2, p_valor2 = stats.pearsonr(filtered_seg_alimentar, filtered_renda2)\n",
    "print('seg_alimentar: ',correlacao2)\n",
    "\n",
    "\n",
    "# subjetividade e RENDA_MONET_PC\n",
    "# Removendo valores infinitos e ausentes\n",
    "valid_indexes3 = np.isfinite(base['subjetividade']) & np.isfinite(base['RENDA_MONET_PC'])\n",
    "filtered_subjetividade = base['subjetividade'][valid_indexes3]\n",
    "filtered_renda3 = base['RENDA_MONET_PC'][valid_indexes3]\n",
    "\n",
    "# Cálculo da correlação de Pearson\n",
    "correlacao3, p_valor3 = stats.pearsonr(filtered_subjetividade, filtered_renda3)\n",
    "print('subjetividade: ',correlacao3)\n",
    "\n",
    "\n",
    "# serv_essenciais e RENDA_MONET_PC\n",
    "# Removendo valores infinitos e serv_essenciais\n",
    "valid_indexes4 = np.isfinite(base['serv_essenciais']) & np.isfinite(base['RENDA_MONET_PC'])\n",
    "filtered_serv_essenciais = base['serv_essenciais'][valid_indexes4]\n",
    "filtered_renda4 = base['RENDA_MONET_PC'][valid_indexes4]\n",
    "\n",
    "# Cálculo da correlação de Pearson\n",
    "correlacao4, p_valor4 = stats.pearsonr(filtered_serv_essenciais, filtered_renda4)\n",
    "print('serv_essenciais: ',correlacao4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   rdpc   R-squared:                       0.091\n",
      "Model:                            OLS   Adj. R-squared:                  0.091\n",
      "Method:                 Least Squares   F-statistic:                     9968.\n",
      "Date:                Sun, 19 Nov 2023   Prob (F-statistic):               0.00\n",
      "Time:                        11:12:12   Log-Likelihood:            -2.9582e+05\n",
      "No. Observations:              693760   AIC:                         5.917e+05\n",
      "Df Residuals:                  693752   BIC:                         5.917e+05\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                   0.4236      0.001    352.120      0.000       0.421       0.426\n",
      "C4_7                   -0.1506      0.002    -98.350      0.000      -0.154      -0.148\n",
      "C3_1                   -0.0572      0.001    -62.119      0.000      -0.059      -0.055\n",
      "C2_1                   -0.0860      0.001    -88.989      0.000      -0.088      -0.084\n",
      "C1_3                   -0.0774      0.001    -75.511      0.000      -0.079      -0.075\n",
      "C1_4                   -0.1627      0.001   -120.989      0.000      -0.165      -0.160\n",
      "GRANDE_REGIAO_3        -0.0766      0.001    -71.328      0.000      -0.079      -0.074\n",
      "TIPO_SITUACAO_REG_1    -0.1328      0.001   -124.722      0.000      -0.135      -0.131\n",
      "==============================================================================\n",
      "Omnibus:                   132213.746   Durbin-Watson:                   0.101\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           223638.138\n",
      "Skew:                           1.376   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.399   Cond. No.                         5.46\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "(0.47545220226821655, 0.9999999999999999, 'increasing')\n",
      "                          vif\n",
      "C4_7                 1.038999\n",
      "C3_1                 1.032612\n",
      "C2_1                 1.032198\n",
      "C1_3                 1.067598\n",
      "C1_4                 1.071462\n",
      "GRANDE_REGIAO_3      1.020282\n",
      "TIPO_SITUACAO_REG_1  1.050207\n"
     ]
    }
   ],
   "source": [
    "# MQO - rdpc\n",
    "# https://nathaliatito.medium.com/scikit-learn-ou-statsmodels-avaliando-meu-modelo-de-regressão-f4c04b361fa7\n",
    "# variaveis x (serão iguais para todos os modelos)\n",
    "var_x = base[['C4_7', 'C3_1','C2_1', 'C1_3', 'C1_4', 'GRANDE_REGIAO_3', 'TIPO_SITUACAO_REG_1']]\n",
    "\n",
    "# rdpc\n",
    "var_y = base[['rdpc']]\n",
    "var_x = sm.add_constant(var_x)\n",
    "modelo = sm.OLS(var_y, var_x ).fit()\n",
    "print(modelo.summary())# Teste t de significância individual = H0 indica irrelevância da variavel, portanto :. p_valor < 0.05 aceita H1 e mantém a variavel\n",
    "\n",
    "\n",
    "# teste homocedasticidade\n",
    "teste_homo_rdpc = sms.het_goldfeldquandt(modelo.resid, modelo.model.exog)  # exog indica variaveis exógenas, ou seja, faz uma matriz das variaveis independentes do modelo\n",
    "print(teste_homo_rdpc)\n",
    "\n",
    "# vif - rdpc\n",
    "# teste de multicolinearidade, usando VIF (Variance Inflation Factor)\n",
    "# caso o valor seja maior que 10, indica multicolinearidade, é preciso excluir essas variáveis\n",
    "vif= [ variance_inflation_factor(var_x.values, i ) for i in range(var_x.shape[1])]\n",
    "tabela_vif = pd.DataFrame({'vif':vif[1:]}, index = var_x.columns.drop('const'))\n",
    "print(tabela_vif)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          seg_alimentar   R-squared:                       0.085\n",
      "Model:                            OLS   Adj. R-squared:                  0.085\n",
      "Method:                 Least Squares   F-statistic:                     9215.\n",
      "Date:                Sun, 19 Nov 2023   Prob (F-statistic):               0.00\n",
      "Time:                        11:12:24   Log-Likelihood:            -4.7264e+05\n",
      "No. Observations:              693760   AIC:                         9.453e+05\n",
      "Df Residuals:                  693752   BIC:                         9.454e+05\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                   0.7233      0.002    465.967      0.000       0.720       0.726\n",
      "C4_7                   -0.2513      0.002   -127.158      0.000      -0.255      -0.247\n",
      "C3_1                   -0.1022      0.001    -86.056      0.000      -0.104      -0.100\n",
      "C2_1                   -0.1700      0.001   -136.300      0.000      -0.172      -0.168\n",
      "C1_3                   -0.0501      0.001    -37.873      0.000      -0.053      -0.047\n",
      "C1_4                   -0.1036      0.002    -59.699      0.000      -0.107      -0.100\n",
      "GRANDE_REGIAO_3        -0.1013      0.001    -73.152      0.000      -0.104      -0.099\n",
      "TIPO_SITUACAO_REG_1    -0.0504      0.001    -36.660      0.000      -0.053      -0.048\n",
      "==============================================================================\n",
      "Omnibus:                  3030875.158   Durbin-Watson:                   0.140\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            82096.506\n",
      "Skew:                          -0.020   Prob(JB):                         0.00\n",
      "Kurtosis:                       1.315   Cond. No.                         5.46\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "(0.9690787630740043, 0.9999999999999999, 'increasing')\n",
      "                          vif\n",
      "C4_7                 1.038999\n",
      "C3_1                 1.032612\n",
      "C2_1                 1.032198\n",
      "C1_3                 1.067598\n",
      "C1_4                 1.071462\n",
      "GRANDE_REGIAO_3      1.020282\n",
      "TIPO_SITUACAO_REG_1  1.050207\n"
     ]
    }
   ],
   "source": [
    "# MQO - seg_alimentar\n",
    "var_y = base[['seg_alimentar']]\n",
    "var_x = sm.add_constant(var_x)\n",
    "modelo = sm.OLS(var_y, var_x ).fit()\n",
    "print(modelo.summary()) # Teste t de significância individual = H0 indica irrelevância da variavel, portanto :. p_valor < 0.05 aceita H1 e mantém a variavel\n",
    "\n",
    "\n",
    "# teste homocedasticidade\n",
    "teste_homo_seg_alimentar = sms.het_goldfeldquandt(modelo.resid, modelo.model.exog)  # exog indica variaveis exógenas, ou seja, faz uma matriz das variaveis independentes do modelo\n",
    "print(teste_homo_seg_alimentar)\n",
    "\n",
    "# vif - rdpc\n",
    "# teste de multicolinearidade, usando VIF (Variance Inflation Factor)\n",
    "# caso o valor seja maior que 10, indica multicolinearidade, é preciso excluir essas variáveis\n",
    "vif= [ variance_inflation_factor(var_x.values, i ) for i in range(var_x.shape[1])]\n",
    "tabela_vif = pd.DataFrame({'vif':vif[1:]}, index = var_x.columns.drop('const'))\n",
    "print(tabela_vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          subjetividade   R-squared:                       0.039\n",
      "Model:                            OLS   Adj. R-squared:                  0.039\n",
      "Method:                 Least Squares   F-statistic:                     4046.\n",
      "Date:                Sun, 19 Nov 2023   Prob (F-statistic):               0.00\n",
      "Time:                        11:12:33   Log-Likelihood:            -4.7762e+05\n",
      "No. Observations:              693760   AIC:                         9.553e+05\n",
      "Df Residuals:                  693752   BIC:                         9.554e+05\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                   0.5246      0.002    335.521      0.000       0.522       0.528\n",
      "C4_7                   -0.1984      0.002    -99.702      0.000      -0.202      -0.195\n",
      "C3_1                   -0.0916      0.001    -76.630      0.000      -0.094      -0.089\n",
      "C2_1                   -0.1042      0.001    -82.987      0.000      -0.107      -0.102\n",
      "C1_3                    0.0264      0.001     19.818      0.000       0.024       0.029\n",
      "C1_4                   -0.0005      0.002     -0.310      0.756      -0.004       0.003\n",
      "GRANDE_REGIAO_3        -0.0482      0.001    -34.518      0.000      -0.051      -0.045\n",
      "TIPO_SITUACAO_REG_1    -0.0079      0.001     -5.728      0.000      -0.011      -0.005\n",
      "==============================================================================\n",
      "Omnibus:                  2881405.766   Durbin-Watson:                   0.151\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           100452.291\n",
      "Skew:                           0.339   Prob(JB):                         0.00\n",
      "Kurtosis:                       1.264   Cond. No.                         5.46\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "(0.8849449181393987, 0.9999999999999999, 'increasing')\n",
      "                          vif\n",
      "C4_7                 1.038999\n",
      "C3_1                 1.032612\n",
      "C2_1                 1.032198\n",
      "C1_3                 1.067598\n",
      "C1_4                 1.071462\n",
      "GRANDE_REGIAO_3      1.020282\n",
      "TIPO_SITUACAO_REG_1  1.050207\n"
     ]
    }
   ],
   "source": [
    "# MQO - subjetividade\n",
    "var_y = base[['subjetividade']]\n",
    "var_x = sm.add_constant(var_x)\n",
    "modelo = sm.OLS(var_y, var_x ).fit()\n",
    "print(modelo.summary()) # Teste t de significância individual = H0 indica irrelevância da variavel, portanto :. p_valor < 0.05 aceita H1 e mantém a variavel\n",
    "\n",
    "\n",
    "# teste homocedasticidade\n",
    "teste_homo_subjetividade = sms.het_goldfeldquandt(modelo.resid, modelo.model.exog)  # exog indica variaveis exógenas, ou seja, faz uma matriz das variaveis independentes do modelo\n",
    "print(teste_homo_subjetividade)\n",
    "\n",
    "# vif - rdpc\n",
    "# teste de multicolinearidade, usando VIF (Variance Inflation Factor)\n",
    "# caso o valor seja maior que 10, indica multicolinearidade, é preciso excluir essas variáveis\n",
    "vif= [ variance_inflation_factor(var_x.values, i ) for i in range(var_x.shape[1])]\n",
    "tabela_vif = pd.DataFrame({'vif':vif[1:]}, index = var_x.columns.drop('const'))\n",
    "print(tabela_vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:        serv_essenciais   R-squared:                       0.482\n",
      "Model:                            OLS   Adj. R-squared:                  0.482\n",
      "Method:                 Least Squares   F-statistic:                 9.240e+04\n",
      "Date:                Sun, 19 Nov 2023   Prob (F-statistic):               0.00\n",
      "Time:                        11:12:43   Log-Likelihood:            -2.2846e+05\n",
      "No. Observations:              693760   AIC:                         4.569e+05\n",
      "Df Residuals:                  693752   BIC:                         4.570e+05\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                   0.9249      0.001    847.228      0.000       0.923       0.927\n",
      "C4_7                   -0.1061      0.001    -76.323      0.000      -0.109      -0.103\n",
      "C3_1                    0.0083      0.001      9.939      0.000       0.007       0.010\n",
      "C2_1                   -0.0391      0.001    -44.580      0.000      -0.041      -0.037\n",
      "C1_3                   -0.0224      0.001    -24.031      0.000      -0.024      -0.021\n",
      "C1_4                   -0.0442      0.001    -36.262      0.000      -0.047      -0.042\n",
      "GRANDE_REGIAO_3        -0.1191      0.001   -122.240      0.000      -0.121      -0.117\n",
      "TIPO_SITUACAO_REG_1    -0.7190      0.001   -744.229      0.000      -0.721      -0.717\n",
      "==============================================================================\n",
      "Omnibus:                   126195.188   Durbin-Watson:                   0.081\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           275514.105\n",
      "Skew:                           1.064   Prob(JB):                         0.00\n",
      "Kurtosis:                       5.237   Cond. No.                         5.46\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "(0.8849449181393987, 0.9999999999999999, 'increasing')\n",
      "                          vif\n",
      "C4_7                 1.038999\n",
      "C3_1                 1.032612\n",
      "C2_1                 1.032198\n",
      "C1_3                 1.067598\n",
      "C1_4                 1.071462\n",
      "GRANDE_REGIAO_3      1.020282\n",
      "TIPO_SITUACAO_REG_1  1.050207\n"
     ]
    }
   ],
   "source": [
    "# MQO - serv_essenciais\n",
    "var_y = base[['serv_essenciais']]\n",
    "var_x = sm.add_constant(var_x)\n",
    "modelo = sm.OLS(var_y, var_x ).fit()\n",
    "print(modelo.summary()) # Teste t de significância individual = H0 indica irrelevância da variavel, portanto :. p_valor < 0.05 aceita H1 e mantém a variavel\n",
    "\n",
    "\n",
    "# teste homocedasticidade\n",
    "teste_homo_serv_essenciais = sms.het_goldfeldquandt(modelo.resid, modelo.model.exog)  # exog indica variaveis exógenas, ou seja, faz uma matriz das variaveis independentes do modelo\n",
    "print(teste_homo_subjetividade)\n",
    "\n",
    "# vif - rdpc\n",
    "# teste de multicolinearidade, usando VIF (Variance Inflation Factor)\n",
    "# caso o valor seja maior que 10, indica multicolinearidade, é preciso excluir essas variáveis\n",
    "vif= [ variance_inflation_factor(var_x.values, i ) for i in range(var_x.shape[1])]\n",
    "tabela_vif = pd.DataFrame({'vif':vif[1:]}, index = var_x.columns.drop('const'))\n",
    "print(tabela_vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # transferir para excel caso nao exceda o numero de linhas\n",
    "# # limite de linhas excel = 1.048.576 linhas e 16.384 colunas\n",
    "# # ex: CARACTERISTICAS_DIETA.to_excel('caracteristicas_dieta.xlsx', index=False)\n",
    "# # os itens de 'tabelas' e 'nome_tabelas' precisam estar alinhados\n",
    "\n",
    "# # x\n",
    "# tabelas = [ CARACTERISTICAS_DIETA,\n",
    "#             CONDICOES_VIDA,\n",
    "#             CONSUMO_ALIMENTAR,\n",
    "#             DOMICILIO,\n",
    "#             MORADOR,\n",
    "#             MORADOR_QUALI_VIDA ]\n",
    "\n",
    "# # i \n",
    "# nomes_tabelas = [   'CARACTERISTICAS_DIETA',\n",
    "#                     'CONDICOES_VIDA',\n",
    "#                     'CONSUMO_ALIMENTAR',\n",
    "#                     'DOMICILIO',\n",
    "#                     'MORADOR',\n",
    "#                     'MORADOR_QUALI_VIDA' ]\n",
    "\n",
    "\n",
    "# # zip serve para fazer o loop ao mesmo tempo nas minhas duas listas\n",
    "# for x, i in zip(tabelas, nomes_tabelas):\n",
    "    \n",
    "#     if len(x) < 1048576:\n",
    "#         print(f'{len(x)} , baixar: {i}')\n",
    "        \n",
    "#         dados = pd.DataFrame(x)\n",
    "#         nome_arquivo = i +'.xlsx'\n",
    "#         dados.to_excel(nome_arquivo, index=False)\n",
    "        \n",
    "#         print(f'arquivo {i} baixado com sucesso')\n",
    "                    \n",
    "#     else:\n",
    "#         print(f'{len(x)} , nao baixar: {i}')\n",
    "        \n",
    "       \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variaveis de cada tabela\n",
    "# for x , i in zip(tabelas, nomes_tabelas):\n",
    "#     dados_desc = pd.DataFrame(x).describe()\n",
    "#     arquivo = pd.ExcelWriter('arquivo_estatisticas_descritivas.xlsx', engine = 'xlsxwriter')\n",
    "#     dados_desc.to_excel(arquivo, sheet_name='{}'.format(i), index=True)\n",
    "#     arquivo.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arquivos de dicionarios das variaveis\n",
    "# diretorio_dic = r'C:\\Users\\Computadores Gamer\\OneDrive\\Área de Trabalho\\dados gradilene\\dados'\n",
    "# diretorio_dic = diretorio_dic.replace('\\\\', '/')\n",
    "# os.chdir(diretorio_dic)\n",
    "\n",
    "# os.listdir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sheets do arquivo dicionario\n",
    "# from openpyxl import load_workbook\n",
    "# dicionario = load_workbook('dicvar1718.xlsx')\n",
    "# sheets = dicionario.sheetnames\n",
    "# print(sheets) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lendo sheet 'Morador' e mantendo apenas as variaveis 'V....'\n",
    "# necessario generalizar esse codigo para cada sheet do arquivo\n",
    "\n",
    "\n",
    "# morador = pd.read_excel('dicvar1718.xlsx', sheet_name='Morador')\n",
    "\n",
    "# # cabecalho \n",
    "# morador.columns = morador.iloc[2,]\n",
    "\n",
    "# # preenchendo elementos NAs da coluna 'Código da variável', senao a função 'startswith' nao funciona\n",
    "# morador['Código da variável'].fillna('',inplace=True)\n",
    "\n",
    "# # filtrar apenas linhas em que em 'Código da variável' o elemento começa com 'V'\n",
    "# # lembrar que 'startswith' só funciona com o '.str'\n",
    "# morador = morador[morador['Código da variável'].str.startswith('V')]        # filtrando apenas as linhas de codigos 'V....'\n",
    "# print(morador)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generalizando codigo de ler cada sheet e filtrar apenas os codigos das variaveis\n",
    "# lista_tabelas_codigos = []\n",
    "\n",
    "# for i in sheets:\n",
    "#     caderno = pd.read_excel('dicvar1718.xlsx', sheet_name=i)\n",
    "#     caderno.columns = caderno.iloc[2,]\n",
    "#     caderno['Código da variável'].fillna('', inplace=True)\n",
    "#     caderno = caderno[caderno['Código da variável'].str.startswith('V')]\n",
    "#     lista_tabelas_codigos.append(caderno)\n",
    "\n",
    "\n",
    "# codigos_site = pd.concat(lista_tabelas_codigos, axis=0)\n",
    "# codigos_site = codigos_site[['Código da variável', 'Descrição']]\n",
    "# print(codigos_site)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vendo quantas variaveis de codigo tem em cada caderno para depois fazer o merge com a tabela 'codigos'\n",
    "# lista_cadernos = [CONSUMO_ALIMENTAR, CARACTERISTICAS_DIETA, DOMICILIO, CONDICOES_VIDA, MORADOR_QUALI_VIDA , MORADOR]\n",
    "\n",
    "# # colunas = CONSUMO_ALIMENTAR.columns.str.startswith('V')\n",
    "# # CONSUMO_ALIMENTAR.columns[np.where(colunas==True)]\n",
    "\n",
    "# codigos_total = []\n",
    "# for i in lista_cadernos:\n",
    "#     colunas = i.columns.str.startswith('V')\n",
    "#     nome = i.columns[np.where(np.logical_and(colunas, i.columns.str.match('.*[0-9]$')))] # logical_and é pra unir as condicoes. '.*[0-9]$' é uma expressao regular\n",
    "#     print(len(nome.unique()),nome)\n",
    "#     codigos_total.extend(nome) # coloca na lista, parecido com append, porem append é para adicionar um unico elemento no final da lista, o extend ja adiciona tudo de uma vez\n",
    "    \n",
    "    \n",
    "# codigos_cadernos = pd.DataFrame({'codigo':codigos_total})\n",
    "# codigos_cadernos.columns = ['Código da variável']\n",
    "# # codigos_cadernos.to_excel('codigos_cadernos.xlsx', index=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fazendo merge dos codigos que achei com os 207 codigos que sao o total de codigos de todos cadernos\n",
    "# codigos_final = pd.merge(codigos_site, codigos_cadernos, on='Código da variável', how = 'outer')\n",
    "# codigos_final = codigos_final[['Código da variável','Descrição']]\n",
    "# print(codigos_final)\n",
    "\n",
    "# codigos_final.to_excel('codigos_final.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
