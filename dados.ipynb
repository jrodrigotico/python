{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pacotes\n",
    "Pacotes usando durante o código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "import seaborn as sn\n",
    "from itertools import permutations, product\n",
    "import matplotlib.pyplot as mplt\n",
    "import scipy.stats as stats\n",
    "from tabulate import tabulate\n",
    "import scipy.stats as ss\n",
    "from scipy.stats import chi2_contingency \n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tools as smt\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setar diretorio dos cadernos (codigo caso puxe os arquivos com todas as colunas originais do ibge)\n",
    "diretorio = r'C:\\Users\\Computadores Gamer\\OneDrive\\Área de Trabalho\\dados gradilene\\dados'\n",
    "diretorio = diretorio.replace('\\\\', '/')\n",
    "\n",
    "os.chdir(diretorio)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Cadernos IBGE\n",
    "\n",
    "#### DOMICILIO\n",
    "# largura do txt\n",
    "larguras = [2,4,1,9,2,1,1,1,1,2,1,1,1,1,1,1,1,1,1,2,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,14,14,1]\n",
    "\n",
    "# nome das colunas\n",
    "colunas = [\"UF\", \"ESTRATO_POF\", \"TIPO_SITUACAO_REG\",\n",
    "            \"COD_UPA\", \"NUM_DOM\", \"V0201\", \"V0202\",\n",
    "            \"V0203\", \"V0204\", \"V0205\", \"V0206\", \"V0207\",\n",
    "            \"V0208\", \"V0209\", \"V02101\", \"V02102\",\n",
    "            \"V02103\", \"V02104\", \"V02105\", \"V02111\",\n",
    "            \"V02112\", \"V02113\", \"V0212\", \"V0213\",\n",
    "            \"V02141\", \"V02142\", \"V0215\", \"V02161\",\n",
    "            \"V02162\", \"V02163\", \"V02164\", \"V0217\",\n",
    "            \"V0219\", \"V0220\", \"V0221\", \"PESO\",\n",
    "            \"PESO_FINAL\", \"V6199\"]\n",
    "\n",
    "# leitura dos dados\n",
    "DOMICILIO = pd.read_fwf(\n",
    "    os.path.join(diretorio, \"DOMICILIO.txt\"), \n",
    "    widths=larguras,\n",
    "    na_values=[\" \"],\n",
    "    names=colunas,\n",
    "    decimal=\".\"\n",
    ")\n",
    "\n",
    "##### CONDICOES_VIDA\n",
    "# largura do txt\n",
    "larguras = [2,4,1,9,2,1,2,1,6,5,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,14,14,10]\n",
    "\n",
    "# nome das colunas\n",
    "colunas = [\"UF\", \"ESTRATO_POF\", \"TIPO_SITUACAO_REG\",\n",
    "            \"COD_UPA\", \"NUM_DOM\", \"NUM_UC\", \"COD_INFORMANTE\",\n",
    "            \"V6101\", \"V6102\", \"V6103\", \"V61041\", \"V61042\",\n",
    "            \"V61043\", \"V61044\", \"V61045\", \"V61046\",\n",
    "            \"V61051\", \"V61052\", \"V61053\", \"V61054\",\n",
    "            \"V61055\", \"V61056\", \"V61057\", \"V61058\",\n",
    "            \"V61061\", \"V61062\", \"V61063\", \"V61064\",\n",
    "            \"V61065\", \"V61066\", \"V61067\", \"V61068\",\n",
    "            \"V61069\", \"V610610\", \"V610611\", \"V61071\",\n",
    "            \"V61072\", \"V61073\", \"V6108\", \"V6109\",\n",
    "            \"V6110\", \"V6111\", \"V6112\", \"V6113\", \"V6114\",\n",
    "            \"V6115\", \"V6116\", \"V6117\", \"V6118\", \"V6119\",\n",
    "            \"V6120\", \"V6121\", \"PESO\", \"PESO_FINAL\",\n",
    "            \"RENDA_TOTAL\"]\n",
    "\n",
    "# leitura dos dados\n",
    "CONDICOES_VIDA = pd.read_fwf(\n",
    "    os.path.join(diretorio, \"CONDICOES_VIDA.txt\"),\n",
    "    widths=larguras,\n",
    "    na_values=[\" \"],\n",
    "    names=colunas,\n",
    "    decimal=\".\"\n",
    ")\n",
    "\n",
    "\n",
    "##### MORADOR_QUALI_VIDA\n",
    "# largura do txt\n",
    "larguras = [2,4,1,9,2,1,2,20,20,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,1,1,1,2,20,20,14,14]\n",
    "\n",
    "# nome das colunas\n",
    "colunas = [\"UF\",\"ESTRATO_POF\",\"TIPO_SITUACAO_REG\",\"COD_UPA\",\n",
    "            \"NUM_DOM\",\"NUM_UC\",\"COD_INFORMANTE\",\"CONTAGEM_PONDERADA\",\n",
    "            \"FUNCAO_PERDA\",\"V201\",\"V202\",\"V204\",\"V205\",\"V206\",\n",
    "            \"V207\",\"V208\",\"V209\",\"V210\",\"V211\",\"V212\",\"V214\",\"V215\",\n",
    "            \"V216\",\"V217\",\"V301\",\"V302\",\"V303\",\"V304\",\"V305\",\"V306\",\n",
    "            \"V307\",\"V308\",\"V401\",\"V402\",\"V403\",\"V501\",\"V502\",\"V503\",\n",
    "            \"V504\",\"V505\",\"V506\",\"V601\",\"V602\",\"V603\",\"V604\",\"V605\",\n",
    "            \"V606\",\"V607\",\"V608\",\"V609\",\"V610\",\"V611\",\"V701\",\"V702\",\n",
    "            \"V703\",\"V704\",\"V801\",\"V802\",\"V901\",\"V902\",\"GRANDE_REGIAO\",\n",
    "            \"C1\",\"C2\",\"C3\",\"C4\",\"C5\",\"C6\",\"C7\",\"RENDA_DISP_PC\",\n",
    "            \"RENDA_DISP_PC_SS\",\"PESO\",\"PESO_FINAL\"]\n",
    "\n",
    "# leitura dos dados\n",
    "MORADOR_QUALI_VIDA = pd.read_fwf(\n",
    "    os.path.join(diretorio, \"MORADOR_QUALI_VIDA.txt\"),\n",
    "    widths=larguras,\n",
    "    na_values=[\" \"],\n",
    "    names=colunas,\n",
    "    decimal=\".\"\n",
    ")\n",
    "\n",
    "\n",
    "#### MORADOR\n",
    "# largura do txt\n",
    "larguras = [2,4,1,9,2,1,2,2,1,2,2,4,3,1,1,\n",
    "            1,1,1,2,1,2,1,1,1,1,1,1,1,1,1,\n",
    "            1,1,1,1,1,2,1,1,2,1,1,2,1,1,1,\n",
    "            2,1,2,14,14,10,1,20,20,20,20]\n",
    "\n",
    "# nome das colunas\n",
    "colunas = [\"UF\", \"ESTRATO_POF\", \"TIPO_SITUACAO_REG\",\n",
    "            \"COD_UPA\", \"NUM_DOM\", \"NUM_UC\", \"COD_INFORMANTE\",\n",
    "            \"V0306\", \"V0401\", \"V04021\", \"V04022\", \"V04023\",\n",
    "            \"V0403\", \"V0404\", \"V0405\", \"V0406\", \"V0407\",\n",
    "            \"V0408\", \"V0409\", \"V0410\", \"V0411\", \"V0412\",\n",
    "            \"V0413\", \"V0414\", \"V0415\", \"V0416\",\n",
    "            \"V041711\", \"V041712\", \"V041721\", \"V041722\",\n",
    "            \"V041731\", \"V041732\", \"V041741\", \"V041742\",\n",
    "            \"V0418\", \"V0419\", \"V0420\", \"V0421\", \"V0422\",\n",
    "            \"V0423\", \"V0424\", \"V0425\", \"V0426\", \"V0427\",\n",
    "            \"V0428\", \"V0429\", \"V0430\", \"ANOS_ESTUDO\",\n",
    "            \"PESO\", \"PESO_FINAL\", \"RENDA_TOTAL\",\n",
    "            \"NIVEL_INSTRUCAO\", \"RENDA_DISP_PC\",\"RENDA_MONET_PC\",\n",
    "            \"RENDA_NAO_MONET_PC\",\"DEDUCAO_PC\" ]\n",
    "\n",
    "# leitura dos dados\n",
    "MORADOR = pd.read_fwf(\n",
    "    os.path.join(diretorio, \"MORADOR.txt\"),\n",
    "    widths=larguras,\n",
    "    na_values=[\" \"],\n",
    "    names=colunas,\n",
    "    decimal=\".\"\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Merges \n",
    "# pd.set_option('display.max_columns', 100)\n",
    "bigdata = pd.merge(DOMICILIO, MORADOR, on = ['UF', 'ESTRATO_POF',\"TIPO_SITUACAO_REG\",\"COD_UPA\", \"NUM_DOM\"], how='left')\n",
    "bigdata2 = pd.merge(CONDICOES_VIDA, bigdata, on = ['UF', 'ESTRATO_POF',\"TIPO_SITUACAO_REG\",\"COD_UPA\", \"NUM_DOM\"], how = 'right')\n",
    "base = pd.merge(MORADOR_QUALI_VIDA, bigdata2, on = ['UF', 'ESTRATO_POF',\"TIPO_SITUACAO_REG\",\"COD_UPA\", \"NUM_DOM\"],how = 'right')\n",
    "\n",
    "\n",
    "# removendo colunas duplicadas, ou seja, com sufixo '_x' e '_y'\n",
    "# '$' indica trecho no final da palavra\n",
    "colunas_del_x = base.filter(regex=f'_x$').columns\n",
    "base = base.drop(colunas_del_x, axis=1)\n",
    "\n",
    "colunas_del_y = base.filter(regex=f'_y$').columns\n",
    "base = base.drop(colunas_del_y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando 'na' nas colunas que serão utilizadas no decorrer do código\n",
    "# esse código é mais performático\n",
    "# passou de 693k linhas para 682k linhas\n",
    "base = base[['UF', 'ESTRATO_POF','TIPO_SITUACAO_REG','COD_UPA', 'NUM_DOM','RENDA_MONET_PC','V6199','V6101','V61041','V0212','V0213','V0220', 'C1','C2','C3','C4','GRANDE_REGIAO']]\n",
    "\n",
    "colunas_na = base.columns[base.isna().any()].tolist()\n",
    "print(colunas_na)\n",
    "\n",
    "base = base.dropna(subset=['RENDA_MONET_PC','V0212'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação variáveis dependentes - parte 1\n",
    "\n",
    "#rdpc\n",
    "# var_depend1\n",
    "# MORADOR['RENDA_MONET_PC']\n",
    "# menor ou igual a 1/4 de SM = pobre\n",
    "# acima de 1/4 de SM = não pobre\n",
    "# SM (2017) = 937 \n",
    "def get_rdpc(z):\n",
    "    if z <= 937/4:\n",
    "        return 1\n",
    "    return 0\n",
    "base['rdpc'] = base['RENDA_MONET_PC'].apply(lambda z: get_rdpc(z))\n",
    "\n",
    "# seg_alimentar\n",
    "# var_depend2 \n",
    "# DOMICILIO['V6199']\n",
    "# 1 – Segurança = não pobre\n",
    "# 2 – Insegurança leve = pobre\n",
    "# 3 – Insegurança moderada = pobre\n",
    "# 4 – Insegurança grave = pobre\n",
    "def get_seg_alimentar(z):\n",
    "    if z == 1:\n",
    "        return 0\n",
    "    return 1\n",
    "base['seg_alimentar'] = base['V6199'].apply( lambda z: get_seg_alimentar(z))\n",
    "\n",
    "\n",
    "# subjetividade 1\n",
    "# var_depend3.1_inicial\n",
    "# CONDICOES_VIDA['V6101']\n",
    "# 1 – Muita dificuldade = pobre\n",
    "# 2 – Dificuldade = pobre\n",
    "# 3 – Alguma dificuldade = não pobre\n",
    "# 4 – Alguma facilidade = não pobre\n",
    "# 5 – Facilidade = não pobre\n",
    "# 6 – Muita facilidade = não pobre\n",
    "def get_subjetividade_i(z):\n",
    "    if z == 1 or z==2:\n",
    "        return 1\n",
    "    return 0\n",
    "base['var_depend3.1_inicial'] = base['V6101'].apply(lambda z: get_subjetividade_i(z))\n",
    "\n",
    "\n",
    "# subjetividade 2\n",
    "# var_depend3.2_inicial\n",
    "# CONDICOES_VIDA['V61041']\n",
    "# 1 - Bom = não pobre\n",
    "# 2 - Satisfatório = não pobre\n",
    "# 3 - Ruim = pobre\n",
    "def get_subjetividade_i2(z):\n",
    "    if z == 3:\n",
    "        return 1\n",
    "    return 0\n",
    "base['var_depend3.2_inicial'] = base['V61041'].apply(lambda z: get_subjetividade_i2(z))\n",
    "\n",
    "\n",
    "# serv_essenciais1\n",
    "# var_depend4.1_inicial\n",
    "# DOMICILIO['V0212']\n",
    "# 1 – Rede geral, rede pluvial ou fossa ligada à rede = não pobre\n",
    "# 2 – Fossa não ligada à rede = pobre\n",
    "# 3 – Vala = pobre\n",
    "# 4 – Rio, lago ou mar = pobre\n",
    "# 5 – Outra forma = pobre\n",
    "def get_serv_essenciais1(z):\n",
    "    if z == 1:\n",
    "        return 0\n",
    "    return 1\n",
    "base['var_depend4.1_inicial'] = base['V0212'].apply(lambda z: get_serv_essenciais1(z))\n",
    "\n",
    "\n",
    "# serv_essenciais2\n",
    "# var_depend4.2_inicial\n",
    "# DOMICILIO['V0213']\n",
    "# 1 – Coletado diretamente por serviço de limpeza = não pobre\n",
    "# 2 – Coletado em caçamba de serviço de limpeza = não pobre\n",
    "# 3 – Queimado (na propriedade) = pobre\n",
    "# 4 – Enterrado (na propriedade) = pobre\n",
    "# 5 – Jogado em terreno baldio ou logradouro = pobre\n",
    "# 6 – Outro destino = pobre\n",
    "def get_serv_essenciais2(z):\n",
    "    if z == 1 or z==2:\n",
    "        return 0\n",
    "    return 1    \n",
    "base['var_depend4.2_inicial'] = base['V0213'].apply(lambda z: get_serv_essenciais2(z))\n",
    "\n",
    "\n",
    "\n",
    "# serv_essenciais3\n",
    "# var_depend4.3_inicial\n",
    "# DOMICILIO['V0220']\n",
    "# 1 – Sim = não pobre\n",
    "# 2 – Não = pobre\n",
    "def get_serv_essenciais3(z):\n",
    "    if z == 1:\n",
    "        return 0\n",
    "    return 1    \n",
    "base['var_depend4.3_inicial'] = base['V0220'].apply(lambda z: get_serv_essenciais3(z))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação váriaveis dependentes - parte 2\n",
    "\n",
    "# score variavel dependente do grupo 3\n",
    "# 3\n",
    "# Pontuação:\n",
    "# 0 - não pobre\n",
    "# 1 - pobre\n",
    "# 2 - pobre\n",
    "\n",
    "# gerando permutações 3\n",
    "lista = ['não pobre', 'pobre']\n",
    "permutas_3 = []\n",
    "\n",
    "for i in product(lista, repeat=2):\n",
    "    permutas_3.append(i)\n",
    "print(permutas_3)\n",
    "\n",
    "# [('não pobre', 'não pobre') = 0\n",
    "# ('não pobre', 'pobre') = 1\n",
    "# ('pobre', 'não pobre') = 1\n",
    "# ('pobre', 'pobre')] = 2\n",
    "\n",
    "def get_subjetividade_principal(z,w):\n",
    "    if z == 0  and w == 0:\n",
    "        return 0\n",
    "    return 1    \n",
    "base['subjetividade'] = base.apply(lambda row: get_subjetividade_principal(row['var_depend3.1_inicial'], row['var_depend3.2_inicial']), axis=1)\n",
    "\n",
    "\n",
    "# score variavel dependente do grupo 4\n",
    "# Pontuação:\n",
    "# 0 - não pobre\n",
    "# 1 - não pobre\n",
    "# 2 - pobre\n",
    "# 3 - pobre\n",
    "\n",
    "\n",
    "# gerando permutações 4    \n",
    "lista = ['não pobre', 'pobre']\n",
    "permutas_4 = []\n",
    "\n",
    "for i in product(lista, repeat=3):\n",
    "    permutas_4.append(i)\n",
    "print(permutas_4)\n",
    "    \n",
    "# ('não pobre', 'não pobre', 'não pobre') = não pobre\n",
    "# ('não pobre', 'não pobre', 'pobre') = não pobre\n",
    "# ('não pobre', 'pobre', 'não pobre') = não pobre\n",
    "# ('não pobre', 'pobre', 'pobre') = pobre\n",
    "# ('pobre', 'não pobre', 'não pobre') = não pobre\n",
    "# ('pobre', 'não pobre', 'pobre') = pobre\n",
    "# ('pobre', 'pobre', 'não pobre') = pobre\n",
    "# ('pobre', 'pobre', 'pobre') = pobre\n",
    "\n",
    "def get_serv_essenciais_principal(z,w,p):\n",
    "    if z == 0  and w == 0 and p==0:\n",
    "        return 0\n",
    "    elif z == 0  and w == 0 and p==1:\n",
    "        return 0\n",
    "    elif z == 0  and w == 1 and p==0:\n",
    "        return 0\n",
    "    elif z == 1  and w == 0 and p==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1       \n",
    "base['serv_essenciais'] = base.apply(lambda row: get_serv_essenciais_principal(row['var_depend4.1_inicial'], row['var_depend4.2_inicial'],row['var_depend4.3_inicial'] ), axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificacao NAs nas variaveis que participam do processo de criacao das variaveis dependentes 1,2,3,4\n",
    "var = ['rdpc','seg_alimentar','var_depend3.1_inicial','var_depend3.2_inicial','subjetividade','var_depend4.1_inicial','var_depend4.2_inicial','serv_essenciais' ]\n",
    "for i in var:\n",
    "    j = base[i].unique()\n",
    "    print(f'{i}:', j)\n",
    "    \n",
    "    \n",
    "# # deletando linhas que possuem 'nan' na variavel dependente\n",
    "# # linhas antes da remoção = 693760\n",
    "# # linhas depois da remoção = 682767\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid das 4 variaveis\n",
    "# plano\n",
    "fig, eixos = mplt.subplots (2, 2, figsize=(10,10) )\n",
    "\n",
    "# grafico1 = sn.countplot(MORADOR, x = 'var_depend1')\n",
    "sn.countplot(base, x='rdpc', ax=eixos[0,0])\n",
    "eixos[0,0].set_title('RENDA_MONET_PC')\n",
    "eixos[0,0].set_xlabel('')\n",
    "eixos[0,0].set_ylabel('')\n",
    "\n",
    "# grafico2 = sn.countplot(DOMICILIO, x = 'var_depend2')\n",
    "sn.countplot(base, x = 'seg_alimentar', ax=eixos[0,1])\n",
    "eixos[0,1].set_title('V6199')\n",
    "eixos[0,1].set_xlabel('')\n",
    "eixos[0,1].set_ylabel('')\n",
    "\n",
    "# grafico3 = sn.countplot(CONDICOES_VIDA, x = 'var_depend3')\n",
    "sn.countplot(base, x = 'subjetividade', ax= eixos[1,0])\n",
    "eixos[1,0].set_title('V6101 e V61041')\n",
    "eixos[1,0].set_xlabel('')\n",
    "eixos[1,0].set_ylabel('')\n",
    "\n",
    "# grafico4 = sn.countplot(DOMICILIO, x = 'var_depend4')\n",
    "sn.countplot(base, x = 'serv_essenciais', ax= eixos[1,1])\n",
    "eixos[1,1].set_title('V0212, V0213 e V0220')\n",
    "eixos[1,1].set_xlabel('')\n",
    "eixos[1,1].set_ylabel('')\n",
    "\n",
    "mplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Cruzamento Segurança Alimentar e TIPO_SITUACAO_REG\n",
      "\n",
      "V6199                   1       2      3      4\n",
      "TIPO_SITUACAO_REG                              \n",
      "1                  274802  157000  57821  34559\n",
      "2                   74272   47734  20998  15436\n",
      "\n",
      "\n",
      "\n",
      "Cruzamento Segurança Alimentar e rdpc\n",
      "\n",
      "V6199       1       2      3      4\n",
      "rdpc                               \n",
      "0      321354  164072  50279  25249\n",
      "1       27720   40662  28540  24746\n",
      "\n",
      "\n",
      "\n",
      "Cruzamento Segurança Alimentar e V6101\n",
      "\n",
      "V6199       1      2      3      4\n",
      "V6101                             \n",
      "1       18711  37182  28906  25731\n",
      "2       54794  63498  26349  14488\n",
      "3      137815  82468  20723   8362\n",
      "4       75371  12933   1806    898\n",
      "5       57694   7914    858    238\n",
      "6        4689    739    177    278\n",
      "\n",
      "\n",
      "\n",
      "Cruzamento Segurança Alimentar e V61041\n",
      "\n",
      "V6199        1      2      3      4\n",
      "V61041                             \n",
      "1       247126  95668  23307  12101\n",
      "2        98150  97362  41842  22311\n",
      "3         3798  11704  13670  15583\n",
      "\n",
      "\n",
      "\n",
      "Cruzamento Segurança Alimentar e V0212\n",
      "\n",
      "V6199       1       2      3      4\n",
      "V0212                              \n",
      "1.0    177562   82518  24516  13243\n",
      "2.0    158443  107076  45256  26505\n",
      "3.0      7511    9100   5844   6682\n",
      "4.0      4476    3629   1977   2246\n",
      "5.0      1082    2411   1226   1319\n",
      "\n",
      "\n",
      "\n",
      "Cruzamento Segurança Alimentar e V0213\n",
      "\n",
      "V6199       1       2      3      4\n",
      "V0213                              \n",
      "1      275270  154030  54708  31631\n",
      "2       25503   15746   6794   4350\n",
      "3       39898   30388  15340  12421\n",
      "4        2966    1482    351    420\n",
      "5        2648    1995   1440   1095\n",
      "6        2789    1093    186     78\n",
      "\n",
      "\n",
      "\n",
      "Cruzamento Segurança Alimentar e V0220\n",
      "\n",
      "V6199       1       2      3      4\n",
      "V0220                              \n",
      "1      245542  131448  44792  25621\n",
      "2      103532   73286  34027  24374\n",
      "\n",
      "\n",
      "\n",
      "Cruzamento Segurança Alimentar e C4\n",
      "\n",
      "V6199       1      2      3      4\n",
      "C4                                \n",
      "1       21654  19229  11693   9098\n",
      "2      129154  91500  39462  27348\n",
      "3       30148  19381   6172   3668\n",
      "4       17206  12065   4440   2498\n",
      "5       87974  44989  13170   6096\n",
      "6       11528   5099   1247    526\n",
      "7       51410  12471   2635    761\n",
      "\n",
      "\n",
      "\n",
      "Cruzamento Segurança Alimentar e C3\n",
      "\n",
      "V6199       1       2      3      4\n",
      "C3                                 \n",
      "1      223681  114629  40563  24561\n",
      "2      125393   90105  38256  25434\n",
      "\n",
      "\n",
      "\n",
      "Cruzamento Segurança Alimentar e C2\n",
      "\n",
      "V6199       1       2      3      4\n",
      "C2                                 \n",
      "1      145210   53621  15821   8235\n",
      "2      199249  149006  61650  40652\n",
      "3        4615    2107   1348   1108\n",
      "\n",
      "\n",
      "\n",
      "Cruzamento Segurança Alimentar e C1\n",
      "\n",
      "V6199       1       2      3      4\n",
      "C1                                 \n",
      "1        9072    6903   2707   1404\n",
      "2      182342  121199  45244  29803\n",
      "3      103458   52490  20844  13946\n",
      "4       54202   24142  10024   4842\n",
      "\n",
      "\n",
      "\n",
      "Cruzamento Segurança Alimentar e GRANDE_REGIAO\n",
      "\n",
      "V6199               1      2      3      4\n",
      "GRANDE_REGIAO                             \n",
      "1               45187  42510  24888  18863\n",
      "2              100845  79413  34024  19975\n",
      "3               96432  44130  10753   5714\n",
      "4               59339  16129   3210   2098\n",
      "5               47271  22552   5944   3345\n"
     ]
    }
   ],
   "source": [
    "# distribuição dos domicílios conforme o grau de (in)segurança\n",
    "# # Tabela cruzando a info de renda (usando os 2 extratos que criamos msm, <= ¼ de\n",
    "# # Salário Mínimo e > de ¼ de Salário Mínimo ) com a variável de insegurança\n",
    "# # alimentar\n",
    "# outros cruzamentos\n",
    "\n",
    "cruzamentos = ['TIPO_SITUACAO_REG','rdpc','V6101','V61041','V0212','V0213','V0220','C4','C3','C2','C1','GRANDE_REGIAO']\n",
    "for i in cruzamentos:\n",
    "    tabela = pd.crosstab(base[i], base['V6199'])\n",
    "    print('')\n",
    "    print('')\n",
    "    print('')\n",
    "    print(f'Cruzamento Segurança Alimentar e {i}')\n",
    "    print('')\n",
    "    print(tabela)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V de cramer como medida de associação entre variáveis categóricas não binárias\n",
    "def v_cramer(coluna_2):\n",
    "    matriz_confusao = pd.crosstab(base['V6199'], base[coluna_2]).to_numpy()\n",
    "    chi2 = ss.chi2_contingency(matriz_confusao)[0]\n",
    "    n = matriz_confusao.sum()\n",
    "    phi2 = chi2/n\n",
    "    r,k = matriz_confusao.shape\n",
    "    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))    \n",
    "    rcorr = r - ((r-1)**2)/(n-1)\n",
    "    kcorr = k - ((k-1)**2)/(n-1)\n",
    "    return np.sqrt(phi2corr / min( (kcorr-1), (rcorr-1)))\n",
    "\n",
    "var = ['V6101','V61041','V0212','V0213','V0220','C4','C3','C2','C1','GRANDE_REGIAO','TIPO_SITUACAO_REG']\n",
    "\n",
    "for i in var:\n",
    "    v_cramer(i)\n",
    "    print(f'V de Cramer utilizando a variável V6199 e {i}: ',v_cramer(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatistica descritiva de 'base'\n",
    "\n",
    "# variáveis numéricas\n",
    "base['RENDA_MONET_PC'].describe()\n",
    "\n",
    "# variáveis não numéricas\n",
    "# graficos de frequencia relativa das 5 maiores frequencias relativas de cada variavel\n",
    "base_auxiliar = base[['UF', 'ESTRATO_POF','TIPO_SITUACAO_REG','COD_UPA', 'NUM_DOM','RENDA_MONET_PC','V6199','V6101','V61041','V0212','V0213','V0220', 'C1','C2','C3','C4','GRANDE_REGIAO']]\n",
    "var = ['UF','V6199','V6101','V61041','V0212','V0213','V0220', 'C1','C2','C3','C4','GRANDE_REGIAO']\n",
    "\n",
    "\n",
    "#####################\n",
    "# mapeamento\n",
    "# UF\n",
    "base_auxiliar.loc[:, 'UF'] = base_auxiliar['UF'].map({11 : 'RO',12 : 'AC',13 : 'AM',14 : 'RR',15 : 'PR',16 : 'AM',17 : 'TO',21 : 'MA',22 : 'PI',23 : 'CE',\n",
    "                                24 : 'RN',25 : 'PB',26 : 'PE',27 : 'AL',28 : 'SE',29 : 'BA',31 : 'MG',32 : 'ES',33 : 'RJ',35 : 'SP',\n",
    "                                41 : 'PR',42 : 'SC',43 : 'RS',50 : 'MS',51 : 'MT',52 : 'GO',53 : 'DF'}) \n",
    "\n",
    "# V6199 - Segurança Alimentar\n",
    "base_auxiliar.loc[:, 'V6199'] = base_auxiliar['V6199'].map({1 : 'Segurança',2 : 'Inseg leve', 3 : 'Inseg moderada',4 : 'Inseg grave'})\n",
    "\n",
    "# V6101 - Rendimento total família\n",
    "base_auxiliar.loc[:, 'V6101'] = base_auxiliar['V6101'].map({1 : 'Muita dificuldade',2 : 'Dificuldade', 3 : 'Alguma dificuldade',4 : 'Alguma facilidade', 5:'Facilidade', 6:'Muita facilidade'})\n",
    "\n",
    "# V61041 - Padrão de vida família\n",
    "base_auxiliar.loc[:, 'V61041'] = base_auxiliar['V61041'].map({1 : 'Bom',2 : 'Satisfatório', 3 : 'Ruim'})\n",
    "\n",
    "# V0212 - Escoadouro\n",
    "base_auxiliar.loc[:, 'V0212'] = base_auxiliar['V0212'].map({1 : 'Geral, pluvial, fossa',2 : 'Fossa sem rede', 3 : 'Vala',4 : 'Rio, lago ou mar', 5:'Outra forma '})\n",
    "\n",
    "# V0213 - Destino lixo\n",
    "base_auxiliar.loc[:, 'V0213']  = base_auxiliar['V0213'].map({1 : 'Coletado 3°',2 : 'Coletado caçamba', 3 : 'Queimado',4 : 'Enterrado', 5:'Terreno baldio', 6:'Outro'})\n",
    "\n",
    "# V0220 - Pavimentação\n",
    "base_auxiliar.loc[:, 'V0220']  = base_auxiliar['V0220'].map({1 : 'Sim',2 : 'Não'})\n",
    "\n",
    "# C1 - Idade PR\n",
    "base_auxiliar.loc[:, 'C1']  = base_auxiliar['C1'].map({1 : 'Até 24 anos',2 : '25 a 49 anos', 3 : '50 a 64 anos',4 : '65 anos ou mais'})\n",
    "\n",
    "# C2 - Cor ou raça PR\n",
    "base_auxiliar.loc[:, 'C2']  = base_auxiliar['C2'].map({1 : 'Brancos',2 : 'Pretos e Pardos', 3 : 'Outros'})\n",
    "\n",
    "# C3 - Sexo PR\n",
    "base_auxiliar.loc[:, 'C3'] = base_auxiliar['C3'].map({1 : 'Homem',2 : 'Mulher'})\n",
    "\n",
    "# C4 - Instrução PR\n",
    "base_auxiliar.loc[:, 'C4'] = base_auxiliar['C4'].map({1 : 'Sem instrução',2 : 'EFI', 3 : 'EFC',4 : 'EMI', 5:'EMC',\n",
    "                                               6:'ESI', 7:'ESC'})\n",
    "\n",
    "# GRANDE_REGIAO - Região Geográfica \n",
    "base_auxiliar.loc[:, 'GRANDE_REGIAO'] = base_auxiliar['GRANDE_REGIAO'].map({1 : 'Norte',2 : 'Nordeste', 3 : 'Sudeste',4 : 'Sul', 5:'Centro Oeste'})\n",
    "#####################\n",
    "\n",
    "# mudando nome das colunas\n",
    "# colunas_novas = ['UF', 'ESTRATO_POF','TIPO_SITUACAO_REG','COD_UPA', 'NUM_DOM','RENDA_MONET_PC','Segurança Alimentar','Rendimento total família','Padrão de vida família','Escoadouro','Destino do lixo','Pavimentação','Idade PR','Cor ou raça PR','Sexo PR','Instrução PR','Região Geográfica']\n",
    "# base_auxiliar.columns = colunas_novas\n",
    "\n",
    "\n",
    "fig, eixo = fig, eixos = mplt.subplots (3, 4, figsize=(40,15))\n",
    "for i, z in zip(var, eixo.flatten()):\n",
    "        freq_relativa = base_auxiliar[i].value_counts(normalize = True).nlargest(5)\n",
    "        mplt.figure()\n",
    "        grafico = sn.barplot(x=freq_relativa.index, y = freq_relativa.values, palette='dark', ax=z)\n",
    "        grafico.set(xlabel = i)\n",
    "mplt.tight_layout()\n",
    "mplt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico renda media por estado\n",
    "media_renda_uf = base.groupby('UF')['RENDA_MONET_PC'].mean().sort_values()\n",
    "tabela = pd.DataFrame(media_renda_uf).reset_index()\n",
    "\n",
    "\n",
    "tabela['UF'] = tabela['UF'].map({11 : 'RO',\n",
    "                               12 : 'AC',\n",
    "                                13 : 'AM',\n",
    "                                14 : 'RR',\n",
    "                                15 : 'PR',\n",
    "                                16 : 'AM',\n",
    "                                17 : 'TO',\n",
    "                                21 : 'MA',\n",
    "                                22 : 'PI',\n",
    "                                23 : 'CE',\n",
    "                                24 : 'RN',\n",
    "                                25 : 'PB',\n",
    "                                26 : 'PE',\n",
    "                                27 : 'AL',\n",
    "                                28 : 'SE',\n",
    "                                29 : 'BA',\n",
    "                                31 : 'MG',\n",
    "                                32 : 'ES',\n",
    "                                33 : 'RJ',\n",
    "                                35 : 'SP',\n",
    "                                41 : 'PR',\n",
    "                                42 : 'SC',\n",
    "                                43 : 'RS',\n",
    "                                50 : 'MS',\n",
    "                                51 : 'MT',\n",
    "                                52 : 'GO',\n",
    "                                53 : 'DF'}) \n",
    "print(tabela)\n",
    "\n",
    "fig, ax = mplt.subplots(figsize = (10,10))\n",
    "sn.barplot(y='RENDA_MONET_PC', x='UF', data = tabela, ax=ax, palette='dark')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação das dummies\n",
    "# C4 - Nível de Instrução da pessoa (perfil do chefe)\n",
    "    # 1 – Sem instrução\n",
    "    # 2 – Ensino Fundamental Incompleto\n",
    "    # 3 – Ensino Fundamental Completo \n",
    "    # 4 – Ensino Médio Incompleto\n",
    "    # 5 – Ensino Médio Completo \n",
    "    # 6 – Ensino Superior Incompleto\n",
    "    # 7 – Ensino Superior Completo - dummy\n",
    "\n",
    "# C3 - Sexo (PERFIL DO CHEFE)\n",
    "    # 1- Masculino - dummy\n",
    "    # 2- Feminino\n",
    "\n",
    "# C2 - Cor ou raça (PERFI DO CHEFE)\n",
    "    # 1 – Brancos - dummy\n",
    "    # 2 – Pretos e Pardos\n",
    "    # 3 – Outros\n",
    "\n",
    "# C1 - IDADE - PERFIL DO CHEFE\n",
    "    # 1 – Até 24 anos\n",
    "    # 2 – 25 a 49 anos\n",
    "    # 3 – 50 a 64 anos - dummy \n",
    "    # 4 – 65 anos ou mais - dummy\n",
    "\n",
    "# GRANDE_REGIAO - REGIÃO (DUMY) - referência é o sudeste\n",
    "    # 1- Norte\n",
    "    # 2- Nordeste\n",
    "    # 3- Sudeste - dummy\n",
    "    # 4- Sul\n",
    "    # 5- Centro-Oeste\n",
    "    \n",
    "# TIPO_SITUACAO_REG urbano (1) x rural (2)\n",
    "    # 1 - Urbano - dummy\n",
    "    # 2 - Rural\n",
    "\n",
    "\n",
    "# VARIÁVEIS DEPENDENTES\n",
    "# rdpc\n",
    "# seg_alimentar\n",
    "# subjetividade\n",
    "# serv_essenciais\n",
    "\n",
    "# base = base[['rdpc','seg_alimentar','subjetividade','serv_essenciais', 'TIPO_SITUACAO_REG','GRANDE_REGIAO', 'C1', 'C2', 'C3', 'C4']]\n",
    "\n",
    "# # criacao de dummies\n",
    "base = pd.get_dummies(base, columns=['TIPO_SITUACAO_REG', 'GRANDE_REGIAO','C1', 'C2', 'C3', 'C4'])\n",
    "\n",
    "# # considerando apenas as dummies de referencia\n",
    "base = base[['UF','rdpc','seg_alimentar','subjetividade','serv_essenciais', 'C4_7', 'C3_1','C2_1', 'C1_3', 'C1_4', 'GRANDE_REGIAO_3', 'TIPO_SITUACAO_REG_1', 'RENDA_MONET_PC','V6199','V6101','V61041','V0212','V0213','V0220']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer associação qui² entre V6199 e as variaveis dependentes\n",
    "\n",
    "# def get_chi2 (z):\n",
    "#     tabela_dinamica = base.pivot_table(index = z, columns='V6199', aggfunc = 'size')\n",
    "#     chi2, p_valor, gl, predict = chi2_contingency(tabela_dinamica)\n",
    "#     return print(f'Variavel {z} com V6199' , 'chi2:' ,round(chi2,2), ' | p_valor: ',round(p_valor,4), ' | graus de liberdade: ',gl )\n",
    "   \n",
    "\n",
    "# get_chi2('V6101')\n",
    "# get_chi2('V61041')\n",
    "# get_chi2('V0212')\n",
    "# get_chi2('V0213')\n",
    "# get_chi2('V0220')    \n",
    "# get_chi2('C4_7')\n",
    "# get_chi2('C3_1')\n",
    "# get_chi2('C2_1')\n",
    "# get_chi2('C1_3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Correlacao de pearson entre variaveis dependentes e RENDA_MONET_PC\n",
    "\n",
    "# # rdpc e RENDA_MONET_PC\n",
    "# # Removendo valores infinitos e ausentes\n",
    "# # valid_indexes1 = np.isfinite(base['rdpc']) & np.isfinite(base['RENDA_MONET_PC'])\n",
    "# # filtered_rdpc = base['rdpc'][valid_indexes1]\n",
    "# # filtered_renda1 = base['RENDA_MONET_PC'][valid_indexes1]\n",
    "\n",
    "# # # Cálculo da correlação de Pearson\n",
    "# # correlacao1, p_valor1 = stats.pearsonr(filtered_rdpc, filtered_renda1)\n",
    "# # print('rdpc: ',correlacao1)\n",
    "\n",
    "\n",
    "# # seg_alimentar e RENDA_MONET_PC\n",
    "# # Removendo valores infinitos e ausentes\n",
    "# valid_indexes2 = np.isfinite(base['seg_alimentar']) & np.isfinite(base['RENDA_MONET_PC'])\n",
    "# filtered_seg_alimentar = base['seg_alimentar'][valid_indexes2]\n",
    "# filtered_renda2 = base['RENDA_MONET_PC'][valid_indexes2]\n",
    "\n",
    "# # Cálculo da correlação de Pearson\n",
    "# correlacao2, p_valor2 = stats.pearsonr(filtered_seg_alimentar, filtered_renda2)\n",
    "# print('seg_alimentar: ',correlacao2)\n",
    "\n",
    "\n",
    "# # subjetividade e RENDA_MONET_PC\n",
    "# # Removendo valores infinitos e ausentes\n",
    "# valid_indexes3 = np.isfinite(base['subjetividade']) & np.isfinite(base['RENDA_MONET_PC'])\n",
    "# filtered_subjetividade = base['subjetividade'][valid_indexes3]\n",
    "# filtered_renda3 = base['RENDA_MONET_PC'][valid_indexes3]\n",
    "\n",
    "# # Cálculo da correlação de Pearson\n",
    "# correlacao3, p_valor3 = stats.pearsonr(filtered_subjetividade, filtered_renda3)\n",
    "# print('subjetividade: ',correlacao3)\n",
    "\n",
    "\n",
    "# # serv_essenciais e RENDA_MONET_PC\n",
    "# # Removendo valores infinitos e serv_essenciais\n",
    "# valid_indexes4 = np.isfinite(base['serv_essenciais']) & np.isfinite(base['RENDA_MONET_PC'])\n",
    "# filtered_serv_essenciais = base['serv_essenciais'][valid_indexes4]\n",
    "# filtered_renda4 = base['RENDA_MONET_PC'][valid_indexes4]\n",
    "\n",
    "# # Cálculo da correlação de Pearson\n",
    "# correlacao4, p_valor4 = stats.pearsonr(filtered_serv_essenciais, filtered_renda4)\n",
    "# print('serv_essenciais: ',correlacao4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variaveis dependentes segregada e var independente geral\n",
    "# base_rdpc_0 = base.loc[base['rdpc']==1]\n",
    "# var_y = base_rdpc_0['rdpc']\n",
    "# var_x = base_rdpc_0[['C4_7', 'C3_1','C2_1', 'C1_3', 'C1_4', 'GRANDE_REGIAO_3', 'TIPO_SITUACAO_REG_1']]\n",
    "\n",
    "# # var independente geral\n",
    "var_x = base[['C4_7', 'C3_1','C2_1', 'C1_3', 'C1_4', 'GRANDE_REGIAO_3', 'TIPO_SITUACAO_REG_1']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MQO - rdpc\n",
    "# https://nathaliatito.medium.com/scikit-learn-ou-statsmodels-avaliando-meu-modelo-de-regressão-f4c04b361fa7\n",
    "\n",
    "# rdpc\n",
    "var_y = base['rdpc']\n",
    "var_x = sm.add_constant(var_x)\n",
    "modelo = sm.OLS(var_y, var_x ).fit()\n",
    "print(modelo.summary())# Teste t de significância individual = H0 indica irrelevância da variavel, portanto :. p_valor < 0.05 aceita H1 e mantém a variavel\n",
    "\n",
    "\n",
    "# teste homocedasticidade\n",
    "teste_homo_rdpc = sms.het_goldfeldquandt(modelo.resid, modelo.model.exog)  # exog indica variaveis exógenas, ou seja, faz uma matriz das variaveis independentes do modelo\n",
    "print(teste_homo_rdpc)\n",
    "\n",
    "# vif - rdpc\n",
    "# teste de multicolinearidade, usando VIF (Variance Inflation Factor)\n",
    "# caso o valor seja maior que 10, indica multicolinearidade, é preciso excluir essas variáveis\n",
    "vif= [ variance_inflation_factor(var_x.values, i ) for i in range(var_x.shape[1])]\n",
    "tabela_vif = pd.DataFrame({'vif':vif[1:]}, index = var_x.columns.drop('const'))\n",
    "print(tabela_vif)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MQO - seg_alimentar\n",
    "var_y = base[['seg_alimentar']]\n",
    "var_x = sm.add_constant(var_x)\n",
    "modelo = sm.OLS(var_y, var_x ).fit()\n",
    "print(modelo.summary()) # Teste t de significância individual = H0 indica irrelevância da variavel, portanto :. p_valor < 0.05 aceita H1 e mantém a variavel\n",
    "\n",
    "\n",
    "# teste homocedasticidade\n",
    "teste_homo_seg_alimentar = sms.het_goldfeldquandt(modelo.resid, modelo.model.exog)  # exog indica variaveis exógenas, ou seja, faz uma matriz das variaveis independentes do modelo\n",
    "print(teste_homo_seg_alimentar) \n",
    "\n",
    "# vif - rdpc\n",
    "# teste de multicolinearidade, usando VIF (Variance Inflation Factor)\n",
    "# caso o valor seja maior que 10, indica multicolinearidade, é preciso excluir essas variáveis\n",
    "vif= [ variance_inflation_factor(var_x.values, i ) for i in range(var_x.shape[1])]\n",
    "tabela_vif = pd.DataFrame({'vif':vif[1:]}, index = var_x.columns.drop('const'))\n",
    "print(tabela_vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MQO - subjetividade\n",
    "var_y = base[['subjetividade']]\n",
    "var_x = sm.add_constant(var_x)\n",
    "modelo = sm.OLS(var_y, var_x ).fit()\n",
    "print(modelo.summary()) # Teste t de significância individual = H0 indica irrelevância da variavel, portanto :. p_valor < 0.05 aceita H1 e mantém a variavel\n",
    "\n",
    "\n",
    "# teste homocedasticidade\n",
    "# o primeiro numero precisa ser próximo de 1 para os dados serem homocedásticos\n",
    "teste_homo_subjetividade = sms.het_goldfeldquandt(modelo.resid, modelo.model.exog)  # exog indica variaveis exógenas, ou seja, faz uma matriz das variaveis independentes do modelo\n",
    "print(teste_homo_subjetividade)\n",
    "\n",
    "# vif - rdpc\n",
    "# teste de multicolinearidade, usando VIF (Variance Inflation Factor)\n",
    "# caso o valor seja maior que 10, indica multicolinearidade, é preciso excluir essas variáveis\n",
    "vif= [ variance_inflation_factor(var_x.values, i ) for i in range(var_x.shape[1])]\n",
    "tabela_vif = pd.DataFrame({'vif':vif[1:]}, index = var_x.columns.drop('const'))\n",
    "print(tabela_vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MQO - serv_essenciais\n",
    "var_y = base[['serv_essenciais']]\n",
    "var_x = sm.add_constant(var_x)\n",
    "modelo = sm.OLS(var_y, var_x ).fit()\n",
    "print(modelo.summary()) # Teste t de significância individual = H0 indica irrelevância da variavel, portanto :. p_valor < 0.05 aceita H1 e mantém a variavel\n",
    "\n",
    "\n",
    "# teste homocedasticidade\n",
    "teste_homo_serv_essenciais = sms.het_goldfeldquandt(modelo.resid, modelo.model.exog)  # exog indica variaveis exógenas, ou seja, faz uma matriz das variaveis independentes do modelo\n",
    "print(teste_homo_subjetividade)\n",
    "\n",
    "# vif - rdpc\n",
    "# teste de multicolinearidade, usando VIF (Variance Inflation Factor)\n",
    "# caso o valor seja maior que 10, indica multicolinearidade, é preciso excluir essas variáveis\n",
    "vif= [ variance_inflation_factor(var_x.values, i ) for i in range(var_x.shape[1])]\n",
    "tabela_vif = pd.DataFrame({'vif':vif[1:]}, index = var_x.columns.drop('const'))\n",
    "print(tabela_vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regressão logistica - teste rdpc\n",
    "var_y = base[['rdpc']]\n",
    "var_y = np.ravel(var_y)\n",
    "var_x = base[['C4_7', 'C3_1','C2_1', 'C1_3', 'C1_4', 'GRANDE_REGIAO_3', 'TIPO_SITUACAO_REG_1']]\n",
    "\n",
    "treino_x, teste_x, treino_y, teste_y = train_test_split(var_x, var_y, test_size=0.3, random_state=1237)\n",
    "\n",
    "modelo = LogisticRegression()\n",
    "modelo.fit(treino_x, treino_y)\n",
    "predict_y = modelo.predict(teste_x)\n",
    "\n",
    "matriz_rdpc = confusion_matrix(teste_y, predict_y)\n",
    "print(matriz_rdpc)\n",
    "\n",
    "acuracia = accuracy_score(teste_y, predict_y)\n",
    "print(acuracia)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regressão logistica - teste seg_alimentar\n",
    "var_y = base[['seg_alimentar']]\n",
    "var_y = np.ravel(var_y)\n",
    "var_x = base[['C4_7', 'C3_1','C2_1', 'C1_3', 'C1_4', 'GRANDE_REGIAO_3', 'TIPO_SITUACAO_REG_1']]\n",
    "\n",
    "treino_x, teste_x, treino_y, teste_y = train_test_split(var_x, var_y, test_size=0.3, random_state=123)\n",
    "\n",
    "modelo = LogisticRegression()\n",
    "modelo.fit(treino_x, treino_y)\n",
    "predict_y = modelo.predict(teste_x)\n",
    "\n",
    "matriz_rdpc = confusion_matrix(teste_y, predict_y)\n",
    "print(matriz_rdpc)\n",
    "\n",
    "acuracia = accuracy_score(teste_y, predict_y)\n",
    "print(acuracia)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regressão logistica - teste subjetividade\n",
    "var_y = base[['subjetividade']]\n",
    "var_y = np.ravel(var_y)\n",
    "var_x = base[['C4_7', 'C3_1','C2_1', 'C1_3', 'C1_4', 'GRANDE_REGIAO_3', 'TIPO_SITUACAO_REG_1']]\n",
    "\n",
    "treino_x, teste_x, treino_y, teste_y = train_test_split(var_x, var_y, test_size=0.3, random_state=123)\n",
    "\n",
    "modelo = LogisticRegression()\n",
    "modelo.fit(treino_x, treino_y)\n",
    "predict_y = modelo.predict(teste_x)\n",
    "\n",
    "matriz_rdpc = confusion_matrix(teste_y, predict_y)\n",
    "print(matriz_rdpc)\n",
    "\n",
    "acuracia = accuracy_score(teste_y, predict_y)\n",
    "print(acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regressão logistica - teste serv_essenciais\n",
    "var_y = base[['serv_essenciais']]\n",
    "var_y = np.ravel(var_y)\n",
    "var_x = base[['C4_7', 'C3_1','C2_1', 'C1_3', 'C1_4', 'GRANDE_REGIAO_3', 'TIPO_SITUACAO_REG_1']]\n",
    "\n",
    "treino_x, teste_x, treino_y, teste_y = train_test_split(var_x, var_y, test_size=0.3, random_state=123)\n",
    "\n",
    "modelo = LogisticRegression()\n",
    "modelo.fit(treino_x, treino_y)\n",
    "predict_y = modelo.predict(teste_x)\n",
    "\n",
    "matriz_rdpc = confusion_matrix(teste_y, predict_y)\n",
    "print(matriz_rdpc)\n",
    "\n",
    "acuracia = accuracy_score(teste_y, predict_y)\n",
    "print(acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC\n",
    "# modelo = SVC()\n",
    "# modelo.fit(treino_x, treino_y)\n",
    "\n",
    "\n",
    "# predict_y = modelo.predict(teste_x)\n",
    "\n",
    "# matriz_rdpc = confusion_matrix(teste_y, predict_y)\n",
    "# print(matriz_rdpc)\n",
    "\n",
    "# acuracia = accuracy_score(teste_y, predict_y)\n",
    "# print(acuracia)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
