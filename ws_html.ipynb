{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escolha de site para o web scrapping\n",
    "wikipedia = 'https://en.wikipedia.org/wiki/Web_scraping'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtencao do html, ou json, ou xml do url\n",
    "# status_code: código de status da resposta;\n",
    "# headers: cabeçalhos da resposta;\n",
    "# content: conteúdo da resposta em bytes, coleta os dados;\n",
    "# json(): conteúdo da resposta em formato JSON(se a resposta não for um JSON, uma exceção será lançada);\n",
    "# cookies: cookies da resposta;\n",
    "# next: retorna a próxima página de uma resposta paginada.\n",
    "html = requests.get(wikipedia)\n",
    "print(html.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# saber status\n",
    "# 200 significa 'sucesso' - olhar código de status (https://ayltoninacio.com.br/blog/codigos-http-status)\n",
    "print(wikipedia.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coletas dados do site\n",
    "html = requests.get(wikipedia).content\n",
    "\n",
    "# formatando os dados, ou seja, transformando-os de não-estruturados para estruturados\n",
    "dados = BeautifulSoup(html, 'html.parser')\n",
    "print(dados.prettify()) # é realmente necessário inserir o print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web scraping - Wikipedia\n"
     ]
    }
   ],
   "source": [
    "# uma vez estruturados, consigo extrair informações dos dados\n",
    "titulo = dados.find('title')\n",
    "print(titulo.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web scraping\n"
     ]
    }
   ],
   "source": [
    "# buscar h1, heading 1\n",
    "h1 = dados.find('h1')\n",
    "print(h1.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents\n",
      "History[edit]\n",
      "Techniques[edit]\n",
      "Software[edit]\n",
      "Legal issues[edit]\n",
      "Methods to prevent web scraping[edit]\n",
      "See also[edit]\n",
      "References[edit]\n"
     ]
    }
   ],
   "source": [
    "# buscar todos h2, heading 2\n",
    "h2 = dados.find_all('h2')\n",
    "\n",
    "for i in h2:\n",
    "    print(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping a web page involves fetching it and extracting from it. Fetching is the downloading of a page (which a browser does when a user views a page). Therefore, web crawling is a main component of web scraping, to fetch pages for later processing. Once fetched, extraction can take place. The content of a page may be parsed, searched and reformatted, and its data copied into a spreadsheet or loaded into a database. Web scrapers typically take something out of a page, to make use of it for another purpose somewhere else. An example would be finding and copying names and telephone numbers, companies and their URLs, or e-mail addresses to a list (contact scraping).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# buscar paragrafos, p\n",
    "paragrafos = dados.find_all('p')\n",
    "\n",
    "# for i in paragrafos:\n",
    "#     print(i.text)\n",
    "   \n",
    "print(paragrafos[1].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "futebol = 'https://ge.globo.com/rj/futebol/copa-sul-americana/noticia/2023/07/05/copa-sul-americana-2023-veja-o-chaveamento-das-oitavas-ate-a-final.ghtml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraindo html\n",
    "html_futebol = requests.get(futebol)\n",
    "print(html_futebol.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# status\n",
    "html_futebol.status_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estruturar os dados de futebol\n",
    "dados_futebol = BeautifulSoup(html_futebol.content, 'html.parser')\n",
    "print(dados_futebol.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titulo\n",
    "titulo_futebol = dados_futebol.find('title')\n",
    "print(titulo_futebol.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h2\n",
    "h2_futebol = dados_futebol.find_all('h2')\n",
    "\n",
    "for i in h2_futebol:\n",
    "    print(i.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p \n",
    "p_futebol = dados_futebol.find_all('p')\n",
    "\n",
    "for i in p_futebol:\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
